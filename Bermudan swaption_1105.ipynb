{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 1 Generate sim_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "using swap rate to construct DFT curve\n",
    "\"\"\"\n",
    "corr=pd.read_excel(\"fwd_rates_correl.xlsx\", sheet_name =\"change_corr\").to_numpy()[1:,1:]\n",
    "curve = pd.read_excel(\"values of swaptions_and_bermudan_v4.xlsx\", sheet_name =\"cms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenor</th>\n",
       "      <th>swap rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.1511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.1630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.1609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.1582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.2519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.2568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.2411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.2297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.2334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.3287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.4049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.4827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.6284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.6912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.7463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.7949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.8349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.8692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.8992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tenor  swap rate\n",
       "0    0.019231     0.1511\n",
       "1    0.038462     0.1630\n",
       "2    0.057692     0.1609\n",
       "3    0.083333     0.1582\n",
       "4    0.166667     0.2029\n",
       "5    0.250000     0.2519\n",
       "6    0.500000     0.2776\n",
       "7    0.750000     0.2568\n",
       "8    1.000000     0.2411\n",
       "9    1.750000     0.2297\n",
       "10   2.000000     0.2232\n",
       "11   3.000000     0.2334\n",
       "12   4.000000     0.2700\n",
       "13   5.000000     0.3287\n",
       "14   6.000000     0.4049\n",
       "15   7.000000     0.4827\n",
       "16   8.000000     0.5572\n",
       "17   9.000000     0.6284\n",
       "18  10.000000     0.6912\n",
       "19  11.000000     0.7463\n",
       "20  12.000000     0.7949\n",
       "21  13.000000     0.8349\n",
       "22  14.000000     0.8692\n",
       "23  15.000000     0.8992"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate, stats, optimize\n",
    "#fit cubic spline to curve to get other maturities\n",
    "maturities = np.arange(1, 21)*0.5\n",
    "cs = interpolate.CubicSpline(curve[\"tenor\"], curve[\"swap rate\"])\n",
    "cms = np.array(pd.DataFrame({\"maturity\" : maturities,\"rate\" : cs(maturities)/100}))\n",
    "par=cms[:,1]\n",
    "\n",
    "# boostrap discount prices from par rate\n",
    "DFT=np.zeros(cms.shape[0])\n",
    "DFT[0]=1/(1+par[0]/2)\n",
    "for i in range(1,20):\n",
    "    DFT[i]=(1-par[i]/2 * np.sum(DFT))/(par[i]/2+1) \n",
    "\n",
    "\n",
    "#decompose historical correlation matrix\n",
    "eig_vec = np.linalg.eig(corr)[1]\n",
    "eig_inv = np.linalg.inv(eig_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_from_covariance(covariance):\n",
    "    v = np.sqrt(np.diag(covariance))\n",
    "    outer_v = np.outer(v, v)\n",
    "    correlation = covariance / outer_v\n",
    "    correlation[covariance == 0] = 0\n",
    "    return correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smm(initial_curve, corr, paths, factors, eig):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "     initial_curve :the initial discount curve bootstrapped from cms\n",
    "     corr : historical correlation matrix (19x19) (1 less than # of semi-annual discount bonds available)\n",
    "     paths : number of simulated rate paths\n",
    "     factors : number of factors affecting the correlation\n",
    "     eig : new eigen values that generates the correlation\n",
    "    \"\"\"\n",
    "    N = 20\n",
    "    step = 21\n",
    "    paths = int(paths)\n",
    "    rates = np.zeros((N, step, paths))\n",
    "    rates[:,0,:] = initial_curve.reshape(N, 1) #initial discount vector\n",
    "    np.random.seed(345)\n",
    "    \n",
    "    for i in range(1,step):\n",
    "        row = i-1 #matured row (as next time step shortest dated bond matures)\n",
    "        rates[row,i,:] = 1 #worth par when they mature\n",
    "        \n",
    "        #find r\n",
    "        #shortest dated rate\n",
    "        r = (rates[row,i-1,:]**(-1) - 1)*2\n",
    "        \n",
    "        #new eigen values:\n",
    "        new_eig = np.zeros((N-1,N-1))\n",
    "        factors = factors #number of factors\n",
    "        new_eig_val = np.concatenate((eig, np.repeat(1e-10, N-1-factors)), axis = 0) #to make sure it's positive definite\n",
    "        new_eig[np.diag_indices(N-1)] = new_eig_val\n",
    "        \n",
    "        #create new covariance matrix\n",
    "        \n",
    "        cov_mat = np.dot(np.dot(eig_vec, new_eig), eig_inv)        \n",
    "        #cholesky decomposition for correlated variables\n",
    "        # cor_mat=correlation_from_covariance(cov_mat)\n",
    "        # chol=np.linalg.cholesky(cor_mat)\n",
    "        \n",
    "        # #cholesky decomposition for correlated variables\n",
    "        chol = np.linalg.cholesky(cov_mat) #lower triangular L\n",
    "        \n",
    "        #vol of forward curves\n",
    "        vol = np.sqrt(np.diag(cov_mat))\n",
    "#        vol=vol_test/100\n",
    "        #Time-Homogeneous (TH)\n",
    "        vol = vol[0:(N-i)].reshape(-1,1) #first 19, 18, 17, ...\n",
    "        \n",
    "        #simulate correlated brownian paths\n",
    "        #w/ anti thetic variates\n",
    "        z = np.random.normal(size = (int(np.ceil(paths/2)), (N-1) ))\n",
    "        z = np.r_[z, -z][0:paths,:] #anti-thetic\n",
    "        \n",
    "        #grab relevant dwt (cut down last vectors)\n",
    "        dwt = chol @ z.T #result: dwt = (N x simulated paths)\n",
    "        dwt = dwt[0:(N-i),:] #first 19, 18, 17, ...\n",
    "        \n",
    "        #calculate forward rates from previous vector of discount rates:\n",
    "        forward = 2 * ((rates[row:-1, i-1 ,:] / rates[(row+1):, i-1 ,:]) - 1)\n",
    "        \n",
    "        #get jacobian matrix\n",
    "        di = np.diag_indices(N-i)\n",
    "        jacobian = np.zeros((N-i, N-i, paths))\n",
    "        #fill main diagonal\n",
    "        diags = (rates[row:-1, i-1 ,:]) / -(rates[(row+1):, i-1 ,:])**2\n",
    "        jacobian[di] = diags\n",
    "        \n",
    "        #fill offset diagonal\n",
    "        di = (di[0][1:], di[1][:-1])\n",
    "        diags = 1/(rates[(row + 2):, i-1 ,:]) #row+2\n",
    "        jacobian[di] = diags\n",
    "        \n",
    "        #inverse\n",
    "        inv_jacobian = np.linalg.inv(jacobian.T).T\n",
    "        \n",
    "        # =============================================================================\n",
    "        # evolve\n",
    "        # dD = rD(i-1) * (1/2) + J**-1 * F * vol * dwt * sqrt(0.5)\n",
    "        # =============================================================================  \n",
    "        #diffusion\n",
    "        diffusion = np.einsum('ijk,jk->ik', inv_jacobian, forward*vol)\n",
    "        # check \n",
    "        all(np.allclose( diffusion[:, j].reshape(-1,1) , inv_jacobian[:,:,j] @ (forward[:,j].reshape(-1,1) * vol) ) for j in range(paths) )\n",
    "                                              \n",
    "        rates[(row+1):,i,:] = (rates[(row+1):,i-1,:] + r * rates[(row+1):,i-1,:] * 0.5 +\n",
    "                                diffusion * dwt * np.sqrt(0.5))        \n",
    "    return rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "para=np.array([1.24445565e+00, 1.03384821e-01, 7.25724878e-02, 7.00277649e-03]) \n",
    "\n",
    "sim_rates=smm(DFT, corr, 5000, len(para),para)\n",
    "sim_rates_10k=smm(DFT, corr, 10000, len(para),para)\n",
    "sim_rates_50k=smm(DFT, corr, 50000, len(para),para)\n",
    "sim_rates_100k=smm(DFT, corr, 100000, len(para),para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99861392, 1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.99759357, 0.99896366, 1.        , 0.        , 0.        ],\n",
       "       [0.99652022, 0.99785927, 0.99904042, 1.        , 0.        ],\n",
       "       [0.99554908, 0.99682642, 0.99812227, 0.99897508, 1.        ],\n",
       "       [0.99447329, 0.99565606, 0.99709571, 0.99783977, 0.99916139]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_rates[:5,:5,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To make sure that we  can use the same data to generate our result, I used the saved sim_rates in the following steps, which may not be the best one to calibrate the market. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved data\n",
    "#load_rates=np.loadtxt('sim_rates.txt')\n",
    "# original sim_rates.shape=(20,20,5000)\n",
    "#sim_rates=load_rates.reshape(load_rates.shape[0],load_rates.shape[1]//5000,5000) # depends on the simulation paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 2 Price a swaption using LSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ContinuationValue(x,method,k,y):\n",
    "    L=np.zeros(shape=(k,len(x)))\n",
    "    b=np.zeros(k)\n",
    "    if method==\"Hermite\":\n",
    "        L[0,:]=np.ones_like(x)\n",
    "        L[1,:]= 2*x\n",
    "        for i in range(2,k):\n",
    "            L[i,:]=2*x*L[i-1,:]-2*(i-1)*L[i-2,:]\n",
    "    if method==\"Laguerre\":\n",
    "        if k==2:\n",
    "            L[0,:]=np.exp(-x/2)\n",
    "            L[1,:]=np.exp(-x/2)*(1-x)\n",
    "        if k==3:\n",
    "            L[0,:]=np.exp(-x/2)\n",
    "            L[1,:]=np.exp(-x/2)*(1-x)\n",
    "            L[2,:]=np.exp(-x/2)*(1-2*x+1/2*np.power(x,2))\n",
    "        if k==4:\n",
    "            L[0,:]=np.exp(-x/2)\n",
    "            L[1,:]=np.exp(-x/2)*(1-x)\n",
    "            L[2,:]=np.exp(-x/2)*(1-2*x+1/2*np.power(x,2))\n",
    "            L[3,:]=np.exp(-x/2)*(1-3*x+3/2*np.power(x,2)-1/6*np.power(x,3))\n",
    "    if method==\"Monomials\":\n",
    "        for i in range(0,k):\n",
    "            L[i,:]=np.power(x,i)\n",
    "    A=np.zeros(shape=(k,k))\n",
    "    for i in range(0,k):\n",
    "        b[i]=np.sum(y*L[i,:])\n",
    "        for j in range(0,k):\n",
    "            A[j,i]=np.sum(L[i,:]*L[j,:])\n",
    "    a= np.dot(np.linalg.inv(A),b)\n",
    "    V=np.sum(L*a[:,np.newaxis],axis=0)# sum cols\n",
    "    return  V.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Laguerre_feature(x,k):\n",
    "#    x=ev.ravel()\n",
    "#    k=3\n",
    "    L=np.zeros(shape=(k,len(x)))\n",
    "    if k==2:\n",
    "        L[0,:]=np.exp(-x/2)\n",
    "        L[1,:]=np.exp(-x/2)*(1-x)\n",
    "    if k==3:\n",
    "        L[0,:]=np.exp(-x/2)\n",
    "        L[1,:]=np.exp(-x/2)*(1-x)\n",
    "        L[2,:]=np.exp(-x/2)*(1-2*x+1/2*np.power(x,2))\n",
    "    if k==4:\n",
    "        L[0,:]=np.exp(-x/2)\n",
    "        L[1,:]=np.exp(-x/2)*(1-x)\n",
    "        L[2,:]=np.exp(-x/2)*(1-2*x+1/2*np.power(x,2))\n",
    "        L[3,:]=np.exp(-x/2)*(1-3*x+3/2*np.power(x,2)-1/6*np.power(x,3))\n",
    "    return L.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "def lasso_regressor(x,y,alpha):\n",
    "    lassoreg = Lasso(fit_intercept=False,alpha=alpha,normalize=True, max_iter=1e3)\n",
    "    lassoreg.fit(x,y)\n",
    "    y_pred = lassoreg.predict(x)\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bermudan_swaption_lsm_full(lockout,maturity,sim_rates,strike,alpha):    \n",
    "    expiry=int(2*lockout)\n",
    "    tenor=int(2*maturity)\n",
    "    \n",
    "    step=tenor-expiry  # 18\n",
    "    paths=sim_rates.shape[2] # 5000\n",
    "    di = np.diag_indices(expiry) # 1y 2 dis\n",
    "    \n",
    "# discount factor for calculate the final prc\n",
    "    cmmf = np.prod(sim_rates[di], axis = 0) # (5000,1)\n",
    "    \n",
    "    rates=sim_rates[expiry:tenor,expiry:tenor,:] #18*18*5000\n",
    "    \n",
    "    di=np.diag_indices(int(tenor-expiry-1))\n",
    "    di=(di[0]+expiry,di[1]+expiry)\n",
    "    disc_mat=sim_rates[di]\n",
    "    \n",
    "# discount map for each related time step \n",
    "    discount_mat=np.hstack((np.ones((paths,1)),np.cumprod(sim_rates[di],axis=0).T)) #5000 * 18\n",
    "\n",
    "# initial matrix\n",
    "    value_mat=np.zeros((paths,step)) # value_mat 5000*18\n",
    "    index_mat=np.zeros((paths,step)) # value_mat 5000*18\n",
    "    payoff_mat=np.zeros_like(value_mat) # value_mat 5000*18\n",
    "       \n",
    "# calculate the par rate at 18 possible excercise date\n",
    "    denominator=np.sum(sim_rates[expiry-1:tenor,expiry:tenor,:],axis=0)-1 # 18*5000 3D to 2D\n",
    "    \n",
    "    numerator=2*(1-sim_rates[int(tenor-1),expiry:tenor,:]) # 18*5000\n",
    "    par=numerator/denominator # 19*5000\n",
    "    payoff_mat = 0.5 * np.maximum(strike-par.T, 0) * denominator.T #5000 *100\n",
    "    \n",
    "    index_mat[:,-1]=np.where(payoff_mat[:,-1]>0,1,0) #5000*1\n",
    "    value_mat[:,-1]=payoff_mat[:,-1] # 5000*1\n",
    "# European swaption price and ex prob\n",
    "    Euro_prc=np.mean(payoff_mat[:,0]*cmmf)\n",
    "    ex_prob=np.sum(np.where(payoff_mat[:,0]>0,1,0))/paths    \n",
    "            \n",
    "    for i in range(step-2,-1,-1):\n",
    "        y=value_mat[:,i+1].reshape((paths,1)) # 5000*1\n",
    "        bond_prc=rates[i:int(tenor-expiry),i,:].T # 5000*n\n",
    "        cv=disc_mat[i].reshape((paths,1))*y # 5000*1\n",
    "        ev=payoff_mat[:,i].reshape((paths,1)) # 5000*1        \n",
    "# construct the basis functions        \n",
    "#        swap_value = np.repeat(ev, 3, axis = 1) ** np.arange(1, 4) # 5000*3\n",
    "        swap_value = Laguerre_feature(ev.ravel(),3)\n",
    "        constant=np.ones((paths,1))\n",
    "#        basis=np.hstack((np.hstack((constant,bond_prc)),swap_value))\n",
    "        bond_prc_laguerre=np.apply_along_axis(Laguerre_feature,0,bond_prc,k=4).reshape((paths,-1))\n",
    "        basis=np.hstack((np.hstack((constant,bond_prc_laguerre)),swap_value))\n",
    "#        \n",
    "        # linear regression\n",
    "        cv_hat=lasso_regressor(basis,cv,alpha).reshape((paths,1))\n",
    "        value_mat[:,i]=np.where(ev>cv_hat,ev,cv).ravel()\n",
    "        index_mat[:,i]=np.where(ev>cv_hat,1,0).ravel()\n",
    "        \n",
    "        for j in range(i+1,index_mat.shape[1]):\n",
    "            index_mat[:,j][index_mat[:,int(i)]==1]=0\n",
    "        \n",
    "             \n",
    "    prob=pd.DataFrame({'Time_step': np.arange(expiry,tenor),\n",
    "                       'ex_prob_Euro':np.append(ex_prob,np.repeat(0,step-1)),\n",
    "                       'ex_prob_LSM':np.sum(index_mat,axis=0)/paths})\n",
    "             \n",
    "\n",
    "    price_lsm=np.mean(np.sum(np.multiply(discount_mat,np.multiply(index_mat,payoff_mat)),axis=1)*cmmf)    \n",
    "    return Euro_prc,price_lsm,prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bermudan_swaption_lsm(lockout,maturity,sim_rates,strike,alpha):   \n",
    "    expiry=int(2*lockout)\n",
    "    tenor=int(2*maturity)\n",
    "    \n",
    "    step=tenor-expiry  # 18\n",
    "    paths=sim_rates.shape[2] # 5000\n",
    "    di = np.diag_indices(expiry) # 1y 2 dis\n",
    "    \n",
    "# discount factor for calculate the final prc\n",
    "    cmmf = np.prod(sim_rates[di], axis = 0) # (5000,1)\n",
    "    \n",
    "    rates=sim_rates[expiry:tenor,expiry:tenor,:] #18*18*5000\n",
    "    \n",
    "    di=np.diag_indices(int(tenor-expiry-1))\n",
    "    di=(di[0]+expiry,di[1]+expiry)\n",
    "    disc_mat=sim_rates[di]\n",
    "    \n",
    "# discount map for each related time step \n",
    "    discount_mat=np.hstack((np.ones((paths,1)),np.cumprod(sim_rates[di],axis=0).T)) #5000 * 18\n",
    "\n",
    "# initial matrix\n",
    "    value_mat=np.zeros((paths,step)) # value_mat 5000*18\n",
    "    index_mat=np.zeros((paths,step)) # value_mat 5000*18\n",
    "    payoff_mat=np.zeros_like(value_mat) # value_mat 5000*18\n",
    "       \n",
    "# calculate the par rate at 18 possible excercise date\n",
    "    denominator=np.sum(sim_rates[expiry-1:tenor,expiry:tenor,:],axis=0)-1 # 18*5000 3D to 2D\n",
    "    \n",
    "    numerator=2*(1-sim_rates[int(tenor-1),expiry:tenor,:]) # 18*5000\n",
    "    par=numerator/denominator # 19*5000\n",
    "    payoff_mat = 0.5 * np.maximum(strike-par.T, 0) * denominator.T #5000 *100\n",
    "    \n",
    "    index_mat[:,-1]=np.where(payoff_mat[:,-1]>0,1,0) #5000*1\n",
    "    value_mat[:,-1]=payoff_mat[:,-1] # 5000*1\n",
    "# European swaption price and ex prob\n",
    "    Euro_prc=np.mean(payoff_mat[:,0]*cmmf)\n",
    "    ex_prob=np.sum(np.where(payoff_mat[:,0]>0,1,0))/paths    \n",
    "            \n",
    "    for i in range(step-2,-1,-1):\n",
    "        y=value_mat[:,i+1].reshape((paths,1)) # 5000*1\n",
    "        bond_prc=rates[i:int(tenor-expiry),i,:].T # 5000*n\n",
    "        cv=disc_mat[i].reshape((paths,1))*y # 5000*1\n",
    "        ev=payoff_mat[:,i].reshape((paths,1)) # 5000*1\n",
    "        \n",
    "# construct the basis functions        \n",
    "#        swap_value = np.repeat(ev, 3, axis = 1) ** np.arange(1, 4) # 5000*3\n",
    "        swap_value = Laguerre_feature(ev.ravel(),3)\n",
    "        constant=np.ones((paths,1))\n",
    "#        basis=np.hstack((np.hstack((constant,bond_prc)),swap_value))\n",
    "        bond_prc_laguerre=np.apply_along_axis(Laguerre_feature,0,bond_prc,k=4).reshape((paths,-1))\n",
    "        basis=np.hstack((np.hstack((constant,bond_prc_laguerre)),swap_value))\n",
    "        \n",
    "#        \n",
    "        # linear regression  for ITM options\n",
    "        mask=ev.ravel()>0\n",
    "        ev=ev[mask]\n",
    "        cv=cv[mask]\n",
    "        basis=basis[mask]\n",
    "        \n",
    "        cv_hat=lasso_regressor(basis,cv,alpha).reshape((len(cv),1))\n",
    "        value_mat[mask,i]=np.where(ev>cv_hat,ev,cv).ravel()\n",
    "        index_mat[mask,i]=np.where(ev>cv_hat,1,0).ravel()\n",
    "        \n",
    "        for j in range(i+1,index_mat.shape[1]):\n",
    "            index_mat[:,j][index_mat[:,int(i)]==1]=0\n",
    "        \n",
    "             \n",
    "    prob=pd.DataFrame({'Time_step': np.arange(expiry,tenor),\n",
    "                       'ex_prob_Euro':np.append(ex_prob,np.repeat(0,step-1)),\n",
    "                       'ex_prob_LSM':np.sum(index_mat,axis=0)/paths})\n",
    "             \n",
    "\n",
    "    price_lsm=np.mean(np.sum(np.multiply(discount_mat,np.multiply(index_mat,payoff_mat)),axis=1)*cmmf)    \n",
    "    return Euro_prc,price_lsm,prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for test 10 nc 1    \n",
    "lockout=1\n",
    "maturity=10\n",
    "strike=0.008\n",
    "alpha=0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 248 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prc_lsm_full=Bermudan_swaption_lsm_full(lockout,maturity,sim_rates,strike,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European swaption pirce: 0.006939140046653583\n",
      "American swaption pirce: 0.007624504483292219\n"
     ]
    }
   ],
   "source": [
    "print('European swaption pirce: {}'.format(prc_lsm_full[0]))\n",
    "print('American swaption pirce: {}'.format(prc_lsm_full[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 237 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prc_lsm=Bermudan_swaption_lsm(lockout,maturity,sim_rates,strike,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European swaption pirce: 0.006939140046653583\n",
      "American swaption pirce: 0.007562926519406778\n"
     ]
    }
   ],
   "source": [
    "print('European swaption pirce: {}'.format(prc_lsm[0]))\n",
    "print('American swaption pirce: {}'.format(prc_lsm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excercise Probability Table\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_step</th>\n",
       "      <th>ex_prob_Euro</th>\n",
       "      <th>ex_prob_LSM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.4452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Time_step  ex_prob_Euro  ex_prob_LSM\n",
       "0           2         0.708       0.4452\n",
       "1           3         0.000       0.0638\n",
       "2           4         0.000       0.0312\n",
       "3           5         0.000       0.0138\n",
       "4           6         0.000       0.0094\n",
       "5           7         0.000       0.0088\n",
       "6           8         0.000       0.0070\n",
       "7           9         0.000       0.0060\n",
       "8          10         0.000       0.0042\n",
       "9          11         0.000       0.0048\n",
       "10         12         0.000       0.0042\n",
       "11         13         0.000       0.0030\n",
       "12         14         0.000       0.0066\n",
       "13         15         0.000       0.0054\n",
       "14         16         0.000       0.0070\n",
       "15         17         0.000       0.0092\n",
       "16         18         0.000       0.0166\n",
       "17         19         0.000       0.0094"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Excercise Probability Table')\n",
    "prc_lsm[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 3 Train NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataset import random_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTMinMaxScalerVectorized(object):\n",
    "    \"\"\"\n",
    "    Transforms each channel to the range [0, 1].\n",
    "    \"\"\"\n",
    "    def __call__(self, tensor):\n",
    "        dist = (tensor.max(dim=1, keepdim=True)[0] - tensor.min(dim=1, keepdim=True)[0])\n",
    "        dist[dist==0.] = 1.\n",
    "        scale = 1.0 /  dist\n",
    "        tensor.mul_(scale).sub_(tensor.min(dim=1, keepdim=True)[0])\n",
    "        return tensor\n",
    "    \n",
    "scaler=PyTMinMaxScalerVectorized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNN(basis,cv,n_epochs,batch_size,learningrate):    \n",
    "    x_train=torch.tensor(basis,dtype=torch.float)\n",
    "    scaler(x_train)\n",
    "    y_train=torch.tensor(cv,dtype=torch.float)\n",
    "    features_num=int(basis.shape[1])\n",
    "    dataset = torch.utils.data.TensorDataset(x_train, y_train.view(-1,1))\n",
    "    train_len=int(basis.shape[0]*0.9)\n",
    "    valid_len=basis.shape[0]-train_len\n",
    "    train_dataset,valid_dataset=random_split(dataset,[train_len,valid_len])\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset = train_dataset, \n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=True)\n",
    "    valid_loader=torch.utils.data.DataLoader(dataset=valid_dataset,\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True)    \n",
    "    \n",
    "# define a model    \n",
    "    model=torch.nn.Sequential(\n",
    "            torch.nn.Linear(features_num,128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128,64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64,1))# n values\n",
    "    \n",
    "    optimizer=optim.Adam(model.parameters(),lr=learningrate)\n",
    "\n",
    "    train_loss=[]\n",
    "    valid_loss=[]\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for i, (features, cv_value) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(features.float())\n",
    "            loss = torch.nn.functional.mse_loss(output,cv_value)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())            \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for j, (features_val, cv_val) in enumerate(valid_loader):\n",
    "                model.eval()\n",
    "                output_val = model(features_val.float())\n",
    "                loss_val = torch.nn.functional.mse_loss(output_val,cv_val)\n",
    "                valid_loss.append(loss_val.item())\n",
    "                \n",
    "        loss_avg=np.sqrt(np.array(train_loss).mean())\n",
    "        val_loss_avg=np.sqrt(np.array(valid_loss).mean())\n",
    "        \n",
    "        print(\"Epoch {}/{}, train_loss: {:.5f}, valid_loss: {:.5f}\".format(epoch+1,n_epochs, loss_avg,  val_loss_avg))\n",
    "        \n",
    "    y_hat =np.squeeze(model(x_train)).detach().numpy().reshape((cv.shape[0],-1))\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bermudan_swaption_nn(lockout,maturity,sim_rates,strike,n_epochs,batch_size,learningrate):\n",
    "       \n",
    "    expiry=int(2*lockout)\n",
    "    tenor=int(2*maturity)\n",
    "    \n",
    "    step=tenor-expiry  # 18\n",
    "    paths=sim_rates.shape[2] # 5000\n",
    "    di = np.diag_indices(expiry) # 1y 2 dis\n",
    "    \n",
    "# discount factor for calculate the final prc\n",
    "    cmmf = np.prod(sim_rates[di], axis = 0) # (5000,1)\n",
    "    \n",
    "    rates=sim_rates[expiry:tenor,expiry:tenor,:] #18*18*5000\n",
    "    \n",
    "    di=np.diag_indices(int(tenor-expiry-1))\n",
    "    di=(di[0]+expiry,di[1]+expiry)\n",
    "    disc_mat=sim_rates[di]\n",
    "    \n",
    "# discount map for each related time step \n",
    "    discount_mat=np.hstack((np.ones((paths,1)),np.cumprod(sim_rates[di],axis=0).T)) #5000 * 18\n",
    "\n",
    "# initial matrix\n",
    "\n",
    "    value_rlnn,index_rlnn=np.zeros((paths,step)),np.zeros((paths,step))\n",
    "    \n",
    "# calculate the par rate at 18 possible excercise date\n",
    "    denominator=np.sum(sim_rates[expiry-1:tenor,expiry:tenor,:],axis=0)-1 # 18*5000 3D to 2D\n",
    "    \n",
    "    numerator=2*(1-sim_rates[int(tenor-1),expiry:tenor,:]) # 18*5000\n",
    "    par=numerator/denominator # 19*5000\n",
    "    payoff_mat = 0.5 * np.maximum(strike-par.T, 0) * denominator.T #5000 *100\n",
    "\n",
    "    \n",
    "    index_rlnn[:,-1]=np.where(payoff_mat[:,-1]>0,1,0)\n",
    "    value_rlnn[:,-1]=payoff_mat[:,-1]\n",
    "    \n",
    "# European swaption price and ex prob\n",
    "    Euro_prc=np.mean(payoff_mat[:,0]*cmmf)\n",
    "    ex_prob=np.sum(np.where(payoff_mat[:,0]>0,1,0))/paths    \n",
    "            \n",
    "    for i in range(step-2,-1,-1):\n",
    "        y=value_rlnn[:,i+1].reshape((paths,1)) # 5000*1\n",
    "        bond_prc=rates[i:int(tenor-expiry),i,:].T # 5000*n\n",
    "        cv=disc_mat[i].T.reshape((paths,1))*y # 5000*1\n",
    "        ev=payoff_mat[:,i].reshape((paths,1)) # 5000*1 \n",
    "        \n",
    "# construct the basis functions        \n",
    "#        swap_value = np.repeat(ev, 3, axis = 1) ** np.arange(1, 4) # 5000*3\n",
    "        swap_value = Laguerre_feature(ev.ravel(),3)\n",
    "        constant=np.ones((paths,1))\n",
    "#        basis=np.hstack((np.hstack((constant,bond_prc)),swap_value))\n",
    "        bond_prc_laguerre=np.apply_along_axis(Laguerre_feature,0,bond_prc,k=4).reshape((paths,-1))\n",
    "        basis=np.hstack((np.hstack((constant,bond_prc_laguerre)),swap_value))\n",
    "        \n",
    "\n",
    "        # Regress now NN\n",
    "        mask=ev.ravel()>0\n",
    "        ev=ev[mask]\n",
    "        cv=cv[mask] #(1327, 1)\n",
    "        basis=basis[mask] # (1327, 10)\n",
    "        \n",
    "        \n",
    "        print('At step {}'.format(i+2))\n",
    "        cv_rlnn=trainNN(basis,cv,n_epochs,batch_size,learningrate)\n",
    "        value_rlnn[mask,i]=np.where(ev>cv_rlnn,ev,cv).ravel() # cv instead of cv_rlnn\n",
    "        index_rlnn[mask,i]=np.where(ev>cv,1,0).ravel()\n",
    "        \n",
    "        for j in range(i+1,index_rlnn.shape[1]):            \n",
    "             index_rlnn[:,j][index_rlnn[:,int(i)]==1]=0\n",
    "             \n",
    "    prob=pd.DataFrame({'Time_step': np.arange(expiry,tenor),\n",
    "                       'ex_prob_Euro':np.append(ex_prob,np.repeat(0,step-1)),\n",
    "                       'ex_prob_RLNN':np.sum(index_rlnn,axis=0)/paths})\n",
    "\n",
    "    price_rlnn=np.mean(np.sum(np.multiply(discount_mat,np.multiply(index_rlnn,payoff_mat)),axis=1)*cmmf)\n",
    "    \n",
    "    return Euro_prc,price_rlnn,prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for test 10 nc 1\n",
    "\n",
    "lockout=1\n",
    "maturity=10\n",
    "strike=0.008\n",
    "learningrate=0.01\n",
    "n_epochs=30\n",
    "batch_size=64\n",
    "seed=123\n",
    "learningrate=0.001\n",
    "sim_rates=sim_rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 18\n",
      "Epoch 1/30, train_loss: 0.01122, valid_loss: 0.00223\n",
      "Epoch 2/30, train_loss: 0.00841, valid_loss: 0.00271\n",
      "Epoch 3/30, train_loss: 0.00694, valid_loss: 0.00224\n",
      "Epoch 4/30, train_loss: 0.00603, valid_loss: 0.00197\n",
      "Epoch 5/30, train_loss: 0.00540, valid_loss: 0.00179\n",
      "Epoch 6/30, train_loss: 0.00494, valid_loss: 0.00165\n",
      "Epoch 7/30, train_loss: 0.00458, valid_loss: 0.00155\n",
      "Epoch 8/30, train_loss: 0.00429, valid_loss: 0.00147\n",
      "Epoch 9/30, train_loss: 0.00405, valid_loss: 0.00140\n",
      "Epoch 10/30, train_loss: 0.00385, valid_loss: 0.00135\n",
      "Epoch 11/30, train_loss: 0.00368, valid_loss: 0.00130\n",
      "Epoch 12/30, train_loss: 0.00353, valid_loss: 0.00127\n",
      "Epoch 13/30, train_loss: 0.00339, valid_loss: 0.00123\n",
      "Epoch 14/30, train_loss: 0.00327, valid_loss: 0.00120\n",
      "Epoch 15/30, train_loss: 0.00317, valid_loss: 0.00118\n",
      "Epoch 16/30, train_loss: 0.00307, valid_loss: 0.00116\n",
      "Epoch 17/30, train_loss: 0.00299, valid_loss: 0.00114\n",
      "Epoch 18/30, train_loss: 0.00291, valid_loss: 0.00112\n",
      "Epoch 19/30, train_loss: 0.00284, valid_loss: 0.00110\n",
      "Epoch 20/30, train_loss: 0.00277, valid_loss: 0.00108\n",
      "Epoch 21/30, train_loss: 0.00270, valid_loss: 0.00107\n",
      "Epoch 22/30, train_loss: 0.00265, valid_loss: 0.00105\n",
      "Epoch 23/30, train_loss: 0.00259, valid_loss: 0.00104\n",
      "Epoch 24/30, train_loss: 0.00254, valid_loss: 0.00102\n",
      "Epoch 25/30, train_loss: 0.00249, valid_loss: 0.00101\n",
      "Epoch 26/30, train_loss: 0.00245, valid_loss: 0.00101\n",
      "Epoch 27/30, train_loss: 0.00241, valid_loss: 0.00100\n",
      "Epoch 28/30, train_loss: 0.00237, valid_loss: 0.00099\n",
      "Epoch 29/30, train_loss: 0.00233, valid_loss: 0.00098\n",
      "Epoch 30/30, train_loss: 0.00230, valid_loss: 0.00097\n",
      "At step 17\n",
      "Epoch 1/30, train_loss: 0.02066, valid_loss: 0.00300\n",
      "Epoch 2/30, train_loss: 0.01534, valid_loss: 0.00335\n",
      "Epoch 3/30, train_loss: 0.01265, valid_loss: 0.00290\n",
      "Epoch 4/30, train_loss: 0.01099, valid_loss: 0.00269\n",
      "Epoch 5/30, train_loss: 0.00986, valid_loss: 0.00250\n",
      "Epoch 6/30, train_loss: 0.00902, valid_loss: 0.00237\n",
      "Epoch 7/30, train_loss: 0.00837, valid_loss: 0.00227\n",
      "Epoch 8/30, train_loss: 0.00785, valid_loss: 0.00219\n",
      "Epoch 9/30, train_loss: 0.00742, valid_loss: 0.00213\n",
      "Epoch 10/30, train_loss: 0.00706, valid_loss: 0.00208\n",
      "Epoch 11/30, train_loss: 0.00675, valid_loss: 0.00204\n",
      "Epoch 12/30, train_loss: 0.00647, valid_loss: 0.00200\n",
      "Epoch 13/30, train_loss: 0.00623, valid_loss: 0.00197\n",
      "Epoch 14/30, train_loss: 0.00602, valid_loss: 0.00194\n",
      "Epoch 15/30, train_loss: 0.00583, valid_loss: 0.00192\n",
      "Epoch 16/30, train_loss: 0.00566, valid_loss: 0.00190\n",
      "Epoch 17/30, train_loss: 0.00550, valid_loss: 0.00188\n",
      "Epoch 18/30, train_loss: 0.00536, valid_loss: 0.00188\n",
      "Epoch 19/30, train_loss: 0.00523, valid_loss: 0.00191\n",
      "Epoch 20/30, train_loss: 0.00511, valid_loss: 0.00190\n",
      "Epoch 21/30, train_loss: 0.00500, valid_loss: 0.00189\n",
      "Epoch 22/30, train_loss: 0.00490, valid_loss: 0.00188\n",
      "Epoch 23/30, train_loss: 0.00480, valid_loss: 0.00186\n",
      "Epoch 24/30, train_loss: 0.00471, valid_loss: 0.00185\n",
      "Epoch 25/30, train_loss: 0.00462, valid_loss: 0.00184\n",
      "Epoch 26/30, train_loss: 0.00454, valid_loss: 0.00183\n",
      "Epoch 27/30, train_loss: 0.00447, valid_loss: 0.00182\n",
      "Epoch 28/30, train_loss: 0.00440, valid_loss: 0.00181\n",
      "Epoch 29/30, train_loss: 0.00433, valid_loss: 0.00181\n",
      "Epoch 30/30, train_loss: 0.00427, valid_loss: 0.00181\n",
      "At step 16\n",
      "Epoch 1/30, train_loss: 0.02080, valid_loss: 0.01414\n",
      "Epoch 2/30, train_loss: 0.01577, valid_loss: 0.01119\n",
      "Epoch 3/30, train_loss: 0.01308, valid_loss: 0.00923\n",
      "Epoch 4/30, train_loss: 0.01140, valid_loss: 0.00809\n",
      "Epoch 5/30, train_loss: 0.01026, valid_loss: 0.00731\n",
      "Epoch 6/30, train_loss: 0.00941, valid_loss: 0.00675\n",
      "Epoch 7/30, train_loss: 0.00876, valid_loss: 0.00630\n",
      "Epoch 8/30, train_loss: 0.00824, valid_loss: 0.00595\n",
      "Epoch 9/30, train_loss: 0.00781, valid_loss: 0.00566\n",
      "Epoch 10/30, train_loss: 0.00744, valid_loss: 0.00541\n",
      "Epoch 11/30, train_loss: 0.00713, valid_loss: 0.00522\n",
      "Epoch 12/30, train_loss: 0.00687, valid_loss: 0.00504\n",
      "Epoch 13/30, train_loss: 0.00663, valid_loss: 0.00488\n",
      "Epoch 14/30, train_loss: 0.00643, valid_loss: 0.00479\n",
      "Epoch 15/30, train_loss: 0.00625, valid_loss: 0.00466\n",
      "Epoch 16/30, train_loss: 0.00608, valid_loss: 0.00456\n",
      "Epoch 17/30, train_loss: 0.00592, valid_loss: 0.00446\n",
      "Epoch 18/30, train_loss: 0.00578, valid_loss: 0.00438\n",
      "Epoch 19/30, train_loss: 0.00566, valid_loss: 0.00430\n",
      "Epoch 20/30, train_loss: 0.00555, valid_loss: 0.00422\n",
      "Epoch 21/30, train_loss: 0.00544, valid_loss: 0.00417\n",
      "Epoch 22/30, train_loss: 0.00535, valid_loss: 0.00411\n",
      "Epoch 23/30, train_loss: 0.00525, valid_loss: 0.00405\n",
      "Epoch 24/30, train_loss: 0.00517, valid_loss: 0.00399\n",
      "Epoch 25/30, train_loss: 0.00509, valid_loss: 0.00396\n",
      "Epoch 26/30, train_loss: 0.00502, valid_loss: 0.00391\n",
      "Epoch 27/30, train_loss: 0.00495, valid_loss: 0.00386\n",
      "Epoch 28/30, train_loss: 0.00488, valid_loss: 0.00382\n",
      "Epoch 29/30, train_loss: 0.00482, valid_loss: 0.00377\n",
      "Epoch 30/30, train_loss: 0.00475, valid_loss: 0.00375\n",
      "At step 15\n",
      "Epoch 1/30, train_loss: 0.01816, valid_loss: 0.01027\n",
      "Epoch 2/30, train_loss: 0.01370, valid_loss: 0.00854\n",
      "Epoch 3/30, train_loss: 0.01144, valid_loss: 0.00724\n",
      "Epoch 4/30, train_loss: 0.01002, valid_loss: 0.00637\n",
      "Epoch 5/30, train_loss: 0.00904, valid_loss: 0.00579\n",
      "Epoch 6/30, train_loss: 0.00833, valid_loss: 0.00537\n",
      "Epoch 7/30, train_loss: 0.00778, valid_loss: 0.00504\n",
      "Epoch 8/30, train_loss: 0.00734, valid_loss: 0.00479\n",
      "Epoch 9/30, train_loss: 0.00698, valid_loss: 0.00458\n",
      "Epoch 10/30, train_loss: 0.00667, valid_loss: 0.00441\n",
      "Epoch 11/30, train_loss: 0.00642, valid_loss: 0.00427\n",
      "Epoch 12/30, train_loss: 0.00620, valid_loss: 0.00414\n",
      "Epoch 13/30, train_loss: 0.00600, valid_loss: 0.00403\n",
      "Epoch 14/30, train_loss: 0.00583, valid_loss: 0.00393\n",
      "Epoch 15/30, train_loss: 0.00568, valid_loss: 0.00384\n",
      "Epoch 16/30, train_loss: 0.00554, valid_loss: 0.00377\n",
      "Epoch 17/30, train_loss: 0.00542, valid_loss: 0.00370\n",
      "Epoch 18/30, train_loss: 0.00531, valid_loss: 0.00364\n",
      "Epoch 19/30, train_loss: 0.00520, valid_loss: 0.00358\n",
      "Epoch 20/30, train_loss: 0.00511, valid_loss: 0.00353\n",
      "Epoch 21/30, train_loss: 0.00502, valid_loss: 0.00348\n",
      "Epoch 22/30, train_loss: 0.00493, valid_loss: 0.00345\n",
      "Epoch 23/30, train_loss: 0.00486, valid_loss: 0.00340\n",
      "Epoch 24/30, train_loss: 0.00479, valid_loss: 0.00336\n",
      "Epoch 25/30, train_loss: 0.00472, valid_loss: 0.00333\n",
      "Epoch 26/30, train_loss: 0.00466, valid_loss: 0.00329\n",
      "Epoch 27/30, train_loss: 0.00460, valid_loss: 0.00327\n",
      "Epoch 28/30, train_loss: 0.00455, valid_loss: 0.00324\n",
      "Epoch 29/30, train_loss: 0.00450, valid_loss: 0.00322\n",
      "Epoch 30/30, train_loss: 0.00445, valid_loss: 0.00319\n",
      "At step 14\n",
      "Epoch 1/30, train_loss: 0.05470, valid_loss: 0.01580\n",
      "Epoch 2/30, train_loss: 0.04031, valid_loss: 0.01385\n",
      "Epoch 3/30, train_loss: 0.03317, valid_loss: 0.01181\n",
      "Epoch 4/30, train_loss: 0.02881, valid_loss: 0.01037\n",
      "Epoch 5/30, train_loss: 0.02581, valid_loss: 0.00938\n",
      "Epoch 6/30, train_loss: 0.02360, valid_loss: 0.00866\n",
      "Epoch 7/30, train_loss: 0.02188, valid_loss: 0.00811\n",
      "Epoch 8/30, train_loss: 0.02050, valid_loss: 0.00766\n",
      "Epoch 9/30, train_loss: 0.01935, valid_loss: 0.00730\n",
      "Epoch 10/30, train_loss: 0.01839, valid_loss: 0.00699\n",
      "Epoch 11/30, train_loss: 0.01756, valid_loss: 0.00673\n",
      "Epoch 12/30, train_loss: 0.01684, valid_loss: 0.00651\n",
      "Epoch 13/30, train_loss: 0.01620, valid_loss: 0.00631\n",
      "Epoch 14/30, train_loss: 0.01563, valid_loss: 0.00614\n",
      "Epoch 15/30, train_loss: 0.01512, valid_loss: 0.00599\n",
      "Epoch 16/30, train_loss: 0.01467, valid_loss: 0.00585\n",
      "Epoch 17/30, train_loss: 0.01425, valid_loss: 0.00572\n",
      "Epoch 18/30, train_loss: 0.01387, valid_loss: 0.00561\n",
      "Epoch 19/30, train_loss: 0.01352, valid_loss: 0.00551\n",
      "Epoch 20/30, train_loss: 0.01319, valid_loss: 0.00542\n",
      "Epoch 21/30, train_loss: 0.01289, valid_loss: 0.00533\n",
      "Epoch 22/30, train_loss: 0.01261, valid_loss: 0.00525\n",
      "Epoch 23/30, train_loss: 0.01235, valid_loss: 0.00517\n",
      "Epoch 24/30, train_loss: 0.01211, valid_loss: 0.00510\n",
      "Epoch 25/30, train_loss: 0.01188, valid_loss: 0.00504\n",
      "Epoch 26/30, train_loss: 0.01167, valid_loss: 0.00498\n",
      "Epoch 27/30, train_loss: 0.01147, valid_loss: 0.00492\n",
      "Epoch 28/30, train_loss: 0.01127, valid_loss: 0.00487\n",
      "Epoch 29/30, train_loss: 0.01109, valid_loss: 0.00482\n",
      "Epoch 30/30, train_loss: 0.01092, valid_loss: 0.00477\n",
      "At step 13\n",
      "Epoch 1/30, train_loss: 0.05650, valid_loss: 0.03477\n",
      "Epoch 2/30, train_loss: 0.04192, valid_loss: 0.02513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, train_loss: 0.03455, valid_loss: 0.02068\n",
      "Epoch 4/30, train_loss: 0.03000, valid_loss: 0.01803\n",
      "Epoch 5/30, train_loss: 0.02689, valid_loss: 0.01621\n",
      "Epoch 6/30, train_loss: 0.02459, valid_loss: 0.01488\n",
      "Epoch 7/30, train_loss: 0.02281, valid_loss: 0.01385\n",
      "Epoch 8/30, train_loss: 0.02138, valid_loss: 0.01302\n",
      "Epoch 9/30, train_loss: 0.02019, valid_loss: 0.01234\n",
      "Epoch 10/30, train_loss: 0.01920, valid_loss: 0.01177\n",
      "Epoch 11/30, train_loss: 0.01834, valid_loss: 0.01128\n",
      "Epoch 12/30, train_loss: 0.01759, valid_loss: 0.01085\n",
      "Epoch 13/30, train_loss: 0.01694, valid_loss: 0.01049\n",
      "Epoch 14/30, train_loss: 0.01635, valid_loss: 0.01016\n",
      "Epoch 15/30, train_loss: 0.01583, valid_loss: 0.00986\n",
      "Epoch 16/30, train_loss: 0.01535, valid_loss: 0.00959\n",
      "Epoch 17/30, train_loss: 0.01492, valid_loss: 0.00936\n",
      "Epoch 18/30, train_loss: 0.01453, valid_loss: 0.00913\n",
      "Epoch 19/30, train_loss: 0.01417, valid_loss: 0.00894\n",
      "Epoch 20/30, train_loss: 0.01383, valid_loss: 0.00876\n",
      "Epoch 21/30, train_loss: 0.01353, valid_loss: 0.00859\n",
      "Epoch 22/30, train_loss: 0.01324, valid_loss: 0.00843\n",
      "Epoch 23/30, train_loss: 0.01297, valid_loss: 0.00828\n",
      "Epoch 24/30, train_loss: 0.01273, valid_loss: 0.00815\n",
      "Epoch 25/30, train_loss: 0.01249, valid_loss: 0.00802\n",
      "Epoch 26/30, train_loss: 0.01227, valid_loss: 0.00790\n",
      "Epoch 27/30, train_loss: 0.01206, valid_loss: 0.00779\n",
      "Epoch 28/30, train_loss: 0.01187, valid_loss: 0.00768\n",
      "Epoch 29/30, train_loss: 0.01168, valid_loss: 0.00758\n",
      "Epoch 30/30, train_loss: 0.01151, valid_loss: 0.00748\n",
      "At step 12\n",
      "Epoch 1/30, train_loss: 0.01783, valid_loss: 0.00627\n",
      "Epoch 2/30, train_loss: 0.01358, valid_loss: 0.00546\n",
      "Epoch 3/30, train_loss: 0.01140, valid_loss: 0.00509\n",
      "Epoch 4/30, train_loss: 0.01012, valid_loss: 0.00485\n",
      "Epoch 5/30, train_loss: 0.00925, valid_loss: 0.00469\n",
      "Epoch 6/30, train_loss: 0.00862, valid_loss: 0.00459\n",
      "Epoch 7/30, train_loss: 0.00815, valid_loss: 0.00453\n",
      "Epoch 8/30, train_loss: 0.00778, valid_loss: 0.00451\n",
      "Epoch 9/30, train_loss: 0.00747, valid_loss: 0.00445\n",
      "Epoch 10/30, train_loss: 0.00721, valid_loss: 0.00441\n",
      "Epoch 11/30, train_loss: 0.00701, valid_loss: 0.00441\n",
      "Epoch 12/30, train_loss: 0.00683, valid_loss: 0.00439\n",
      "Epoch 13/30, train_loss: 0.00666, valid_loss: 0.00436\n",
      "Epoch 14/30, train_loss: 0.00651, valid_loss: 0.00437\n",
      "Epoch 15/30, train_loss: 0.00639, valid_loss: 0.00434\n",
      "Epoch 16/30, train_loss: 0.00629, valid_loss: 0.00432\n",
      "Epoch 17/30, train_loss: 0.00619, valid_loss: 0.00431\n",
      "Epoch 18/30, train_loss: 0.00609, valid_loss: 0.00429\n",
      "Epoch 19/30, train_loss: 0.00600, valid_loss: 0.00430\n",
      "Epoch 20/30, train_loss: 0.00593, valid_loss: 0.00429\n",
      "Epoch 21/30, train_loss: 0.00585, valid_loss: 0.00427\n",
      "Epoch 22/30, train_loss: 0.00578, valid_loss: 0.00426\n",
      "Epoch 23/30, train_loss: 0.00572, valid_loss: 0.00425\n",
      "Epoch 24/30, train_loss: 0.00567, valid_loss: 0.00424\n",
      "Epoch 25/30, train_loss: 0.00562, valid_loss: 0.00425\n",
      "Epoch 26/30, train_loss: 0.00557, valid_loss: 0.00423\n",
      "Epoch 27/30, train_loss: 0.00552, valid_loss: 0.00423\n",
      "Epoch 28/30, train_loss: 0.00548, valid_loss: 0.00424\n",
      "Epoch 29/30, train_loss: 0.00544, valid_loss: 0.00423\n",
      "Epoch 30/30, train_loss: 0.00540, valid_loss: 0.00423\n",
      "At step 11\n",
      "Epoch 1/30, train_loss: 0.04046, valid_loss: 0.01818\n",
      "Epoch 2/30, train_loss: 0.03020, valid_loss: 0.01522\n",
      "Epoch 3/30, train_loss: 0.02505, valid_loss: 0.01285\n",
      "Epoch 4/30, train_loss: 0.02186, valid_loss: 0.01139\n",
      "Epoch 5/30, train_loss: 0.01970, valid_loss: 0.01040\n",
      "Epoch 6/30, train_loss: 0.01811, valid_loss: 0.00970\n",
      "Epoch 7/30, train_loss: 0.01687, valid_loss: 0.00915\n",
      "Epoch 8/30, train_loss: 0.01588, valid_loss: 0.00873\n",
      "Epoch 9/30, train_loss: 0.01506, valid_loss: 0.00838\n",
      "Epoch 10/30, train_loss: 0.01437, valid_loss: 0.00810\n",
      "Epoch 11/30, train_loss: 0.01379, valid_loss: 0.00785\n",
      "Epoch 12/30, train_loss: 0.01329, valid_loss: 0.00764\n",
      "Epoch 13/30, train_loss: 0.01285, valid_loss: 0.00749\n",
      "Epoch 14/30, train_loss: 0.01246, valid_loss: 0.00733\n",
      "Epoch 15/30, train_loss: 0.01210, valid_loss: 0.00719\n",
      "Epoch 16/30, train_loss: 0.01178, valid_loss: 0.00707\n",
      "Epoch 17/30, train_loss: 0.01150, valid_loss: 0.00696\n",
      "Epoch 18/30, train_loss: 0.01124, valid_loss: 0.00686\n",
      "Epoch 19/30, train_loss: 0.01099, valid_loss: 0.00677\n",
      "Epoch 20/30, train_loss: 0.01077, valid_loss: 0.00669\n",
      "Epoch 21/30, train_loss: 0.01057, valid_loss: 0.00662\n",
      "Epoch 22/30, train_loss: 0.01038, valid_loss: 0.00655\n",
      "Epoch 23/30, train_loss: 0.01021, valid_loss: 0.00648\n",
      "Epoch 24/30, train_loss: 0.01005, valid_loss: 0.00641\n",
      "Epoch 25/30, train_loss: 0.00989, valid_loss: 0.00636\n",
      "Epoch 26/30, train_loss: 0.00975, valid_loss: 0.00630\n",
      "Epoch 27/30, train_loss: 0.00962, valid_loss: 0.00625\n",
      "Epoch 28/30, train_loss: 0.00950, valid_loss: 0.00622\n",
      "Epoch 29/30, train_loss: 0.00938, valid_loss: 0.00618\n",
      "Epoch 30/30, train_loss: 0.00927, valid_loss: 0.00614\n",
      "At step 10\n",
      "Epoch 1/30, train_loss: 0.01156, valid_loss: 0.00635\n",
      "Epoch 2/30, train_loss: 0.00914, valid_loss: 0.00614\n",
      "Epoch 3/30, train_loss: 0.00809, valid_loss: 0.00580\n",
      "Epoch 4/30, train_loss: 0.00746, valid_loss: 0.00562\n",
      "Epoch 5/30, train_loss: 0.00706, valid_loss: 0.00553\n",
      "Epoch 6/30, train_loss: 0.00680, valid_loss: 0.00546\n",
      "Epoch 7/30, train_loss: 0.00659, valid_loss: 0.00540\n",
      "Epoch 8/30, train_loss: 0.00643, valid_loss: 0.00543\n",
      "Epoch 9/30, train_loss: 0.00631, valid_loss: 0.00542\n",
      "Epoch 10/30, train_loss: 0.00622, valid_loss: 0.00540\n",
      "Epoch 11/30, train_loss: 0.00615, valid_loss: 0.00537\n",
      "Epoch 12/30, train_loss: 0.00608, valid_loss: 0.00533\n",
      "Epoch 13/30, train_loss: 0.00602, valid_loss: 0.00531\n",
      "Epoch 14/30, train_loss: 0.00596, valid_loss: 0.00530\n",
      "Epoch 15/30, train_loss: 0.00591, valid_loss: 0.00528\n",
      "Epoch 16/30, train_loss: 0.00586, valid_loss: 0.00526\n",
      "Epoch 17/30, train_loss: 0.00582, valid_loss: 0.00525\n",
      "Epoch 18/30, train_loss: 0.00580, valid_loss: 0.00526\n",
      "Epoch 19/30, train_loss: 0.00576, valid_loss: 0.00524\n",
      "Epoch 20/30, train_loss: 0.00573, valid_loss: 0.00527\n",
      "Epoch 21/30, train_loss: 0.00570, valid_loss: 0.00526\n",
      "Epoch 22/30, train_loss: 0.00568, valid_loss: 0.00527\n",
      "Epoch 23/30, train_loss: 0.00566, valid_loss: 0.00527\n",
      "Epoch 24/30, train_loss: 0.00563, valid_loss: 0.00527\n",
      "Epoch 25/30, train_loss: 0.00562, valid_loss: 0.00525\n",
      "Epoch 26/30, train_loss: 0.00560, valid_loss: 0.00524\n",
      "Epoch 27/30, train_loss: 0.00560, valid_loss: 0.00525\n",
      "Epoch 28/30, train_loss: 0.00558, valid_loss: 0.00524\n",
      "Epoch 29/30, train_loss: 0.00557, valid_loss: 0.00523\n",
      "Epoch 30/30, train_loss: 0.00555, valid_loss: 0.00522\n",
      "At step 9\n",
      "Epoch 1/30, train_loss: 0.01681, valid_loss: 0.00998\n",
      "Epoch 2/30, train_loss: 0.01285, valid_loss: 0.00824\n",
      "Epoch 3/30, train_loss: 0.01103, valid_loss: 0.00749\n",
      "Epoch 4/30, train_loss: 0.01003, valid_loss: 0.00741\n",
      "Epoch 5/30, train_loss: 0.00942, valid_loss: 0.00699\n",
      "Epoch 6/30, train_loss: 0.00893, valid_loss: 0.00671\n",
      "Epoch 7/30, train_loss: 0.00857, valid_loss: 0.00659\n",
      "Epoch 8/30, train_loss: 0.00828, valid_loss: 0.00664\n",
      "Epoch 9/30, train_loss: 0.00810, valid_loss: 0.00659\n",
      "Epoch 10/30, train_loss: 0.00791, valid_loss: 0.00648\n",
      "Epoch 11/30, train_loss: 0.00776, valid_loss: 0.00634\n",
      "Epoch 12/30, train_loss: 0.00764, valid_loss: 0.00628\n",
      "Epoch 13/30, train_loss: 0.00752, valid_loss: 0.00630\n",
      "Epoch 14/30, train_loss: 0.00743, valid_loss: 0.00623\n",
      "Epoch 15/30, train_loss: 0.00734, valid_loss: 0.00616\n",
      "Epoch 16/30, train_loss: 0.00726, valid_loss: 0.00609\n",
      "Epoch 17/30, train_loss: 0.00719, valid_loss: 0.00610\n",
      "Epoch 18/30, train_loss: 0.00714, valid_loss: 0.00606\n",
      "Epoch 19/30, train_loss: 0.00709, valid_loss: 0.00632\n",
      "Epoch 20/30, train_loss: 0.00705, valid_loss: 0.00629\n",
      "Epoch 21/30, train_loss: 0.00700, valid_loss: 0.00626\n",
      "Epoch 22/30, train_loss: 0.00697, valid_loss: 0.00621\n",
      "Epoch 23/30, train_loss: 0.00694, valid_loss: 0.00633\n",
      "Epoch 24/30, train_loss: 0.00693, valid_loss: 0.00627\n",
      "Epoch 25/30, train_loss: 0.00688, valid_loss: 0.00625\n",
      "Epoch 26/30, train_loss: 0.00684, valid_loss: 0.00620\n",
      "Epoch 27/30, train_loss: 0.00681, valid_loss: 0.00617\n",
      "Epoch 28/30, train_loss: 0.00677, valid_loss: 0.00614\n",
      "Epoch 29/30, train_loss: 0.00674, valid_loss: 0.00612\n",
      "Epoch 30/30, train_loss: 0.00670, valid_loss: 0.00607\n",
      "At step 8\n",
      "Epoch 1/30, train_loss: 0.02203, valid_loss: 0.00858\n",
      "Epoch 2/30, train_loss: 0.01662, valid_loss: 0.00795\n",
      "Epoch 3/30, train_loss: 0.01411, valid_loss: 0.00757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, train_loss: 0.01260, valid_loss: 0.00719\n",
      "Epoch 5/30, train_loss: 0.01159, valid_loss: 0.00698\n",
      "Epoch 6/30, train_loss: 0.01086, valid_loss: 0.00686\n",
      "Epoch 7/30, train_loss: 0.01029, valid_loss: 0.00676\n",
      "Epoch 8/30, train_loss: 0.00987, valid_loss: 0.00669\n",
      "Epoch 9/30, train_loss: 0.00951, valid_loss: 0.00663\n",
      "Epoch 10/30, train_loss: 0.00922, valid_loss: 0.00661\n",
      "Epoch 11/30, train_loss: 0.00897, valid_loss: 0.00656\n",
      "Epoch 12/30, train_loss: 0.00876, valid_loss: 0.00649\n",
      "Epoch 13/30, train_loss: 0.00857, valid_loss: 0.00645\n",
      "Epoch 14/30, train_loss: 0.00841, valid_loss: 0.00648\n",
      "Epoch 15/30, train_loss: 0.00826, valid_loss: 0.00652\n",
      "Epoch 16/30, train_loss: 0.00814, valid_loss: 0.00648\n",
      "Epoch 17/30, train_loss: 0.00803, valid_loss: 0.00653\n",
      "Epoch 18/30, train_loss: 0.00793, valid_loss: 0.00650\n",
      "Epoch 19/30, train_loss: 0.00783, valid_loss: 0.00646\n",
      "Epoch 20/30, train_loss: 0.00775, valid_loss: 0.00644\n",
      "Epoch 21/30, train_loss: 0.00767, valid_loss: 0.00644\n",
      "Epoch 22/30, train_loss: 0.00759, valid_loss: 0.00642\n",
      "Epoch 23/30, train_loss: 0.00752, valid_loss: 0.00639\n",
      "Epoch 24/30, train_loss: 0.00746, valid_loss: 0.00635\n",
      "Epoch 25/30, train_loss: 0.00740, valid_loss: 0.00638\n",
      "Epoch 26/30, train_loss: 0.00734, valid_loss: 0.00635\n",
      "Epoch 27/30, train_loss: 0.00729, valid_loss: 0.00632\n",
      "Epoch 28/30, train_loss: 0.00724, valid_loss: 0.00630\n",
      "Epoch 29/30, train_loss: 0.00720, valid_loss: 0.00630\n",
      "Epoch 30/30, train_loss: 0.00716, valid_loss: 0.00631\n",
      "At step 7\n",
      "Epoch 1/30, train_loss: 0.02150, valid_loss: 0.00740\n",
      "Epoch 2/30, train_loss: 0.01610, valid_loss: 0.00696\n",
      "Epoch 3/30, train_loss: 0.01367, valid_loss: 0.00668\n",
      "Epoch 4/30, train_loss: 0.01227, valid_loss: 0.00655\n",
      "Epoch 5/30, train_loss: 0.01133, valid_loss: 0.00652\n",
      "Epoch 6/30, train_loss: 0.01066, valid_loss: 0.00647\n",
      "Epoch 7/30, train_loss: 0.01017, valid_loss: 0.00641\n",
      "Epoch 8/30, train_loss: 0.00977, valid_loss: 0.00647\n",
      "Epoch 9/30, train_loss: 0.00947, valid_loss: 0.00651\n",
      "Epoch 10/30, train_loss: 0.00922, valid_loss: 0.00647\n",
      "Epoch 11/30, train_loss: 0.00899, valid_loss: 0.00644\n",
      "Epoch 12/30, train_loss: 0.00879, valid_loss: 0.00642\n",
      "Epoch 13/30, train_loss: 0.00863, valid_loss: 0.00639\n",
      "Epoch 14/30, train_loss: 0.00848, valid_loss: 0.00643\n",
      "Epoch 15/30, train_loss: 0.00836, valid_loss: 0.00640\n",
      "Epoch 16/30, train_loss: 0.00825, valid_loss: 0.00637\n",
      "Epoch 17/30, train_loss: 0.00814, valid_loss: 0.00635\n",
      "Epoch 18/30, train_loss: 0.00805, valid_loss: 0.00633\n",
      "Epoch 19/30, train_loss: 0.00796, valid_loss: 0.00632\n",
      "Epoch 20/30, train_loss: 0.00788, valid_loss: 0.00634\n",
      "Epoch 21/30, train_loss: 0.00781, valid_loss: 0.00631\n",
      "Epoch 22/30, train_loss: 0.00774, valid_loss: 0.00629\n",
      "Epoch 23/30, train_loss: 0.00768, valid_loss: 0.00628\n",
      "Epoch 24/30, train_loss: 0.00764, valid_loss: 0.00628\n",
      "Epoch 25/30, train_loss: 0.00760, valid_loss: 0.00628\n",
      "Epoch 26/30, train_loss: 0.00754, valid_loss: 0.00626\n",
      "Epoch 27/30, train_loss: 0.00750, valid_loss: 0.00625\n",
      "Epoch 28/30, train_loss: 0.00745, valid_loss: 0.00623\n",
      "Epoch 29/30, train_loss: 0.00741, valid_loss: 0.00623\n",
      "Epoch 30/30, train_loss: 0.00736, valid_loss: 0.00621\n",
      "At step 6\n",
      "Epoch 1/30, train_loss: 0.01758, valid_loss: 0.00938\n",
      "Epoch 2/30, train_loss: 0.01359, valid_loss: 0.00796\n",
      "Epoch 3/30, train_loss: 0.01185, valid_loss: 0.00743\n",
      "Epoch 4/30, train_loss: 0.01083, valid_loss: 0.00714\n",
      "Epoch 5/30, train_loss: 0.01015, valid_loss: 0.00696\n",
      "Epoch 6/30, train_loss: 0.00967, valid_loss: 0.00687\n",
      "Epoch 7/30, train_loss: 0.00936, valid_loss: 0.00677\n",
      "Epoch 8/30, train_loss: 0.00908, valid_loss: 0.00680\n",
      "Epoch 9/30, train_loss: 0.00886, valid_loss: 0.00672\n",
      "Epoch 10/30, train_loss: 0.00866, valid_loss: 0.00666\n",
      "Epoch 11/30, train_loss: 0.00850, valid_loss: 0.00660\n",
      "Epoch 12/30, train_loss: 0.00836, valid_loss: 0.00655\n",
      "Epoch 13/30, train_loss: 0.00824, valid_loss: 0.00655\n",
      "Epoch 14/30, train_loss: 0.00817, valid_loss: 0.00653\n",
      "Epoch 15/30, train_loss: 0.00807, valid_loss: 0.00655\n",
      "Epoch 16/30, train_loss: 0.00805, valid_loss: 0.00658\n",
      "Epoch 17/30, train_loss: 0.00798, valid_loss: 0.00661\n",
      "Epoch 18/30, train_loss: 0.00791, valid_loss: 0.00661\n",
      "Epoch 19/30, train_loss: 0.00785, valid_loss: 0.00658\n",
      "Epoch 20/30, train_loss: 0.00779, valid_loss: 0.00655\n",
      "Epoch 21/30, train_loss: 0.00773, valid_loss: 0.00651\n",
      "Epoch 22/30, train_loss: 0.00767, valid_loss: 0.00650\n",
      "Epoch 23/30, train_loss: 0.00762, valid_loss: 0.00651\n",
      "Epoch 24/30, train_loss: 0.00758, valid_loss: 0.00649\n",
      "Epoch 25/30, train_loss: 0.00755, valid_loss: 0.00646\n",
      "Epoch 26/30, train_loss: 0.00750, valid_loss: 0.00643\n",
      "Epoch 27/30, train_loss: 0.00745, valid_loss: 0.00644\n",
      "Epoch 28/30, train_loss: 0.00745, valid_loss: 0.00642\n",
      "Epoch 29/30, train_loss: 0.00741, valid_loss: 0.00645\n",
      "Epoch 30/30, train_loss: 0.00739, valid_loss: 0.00644\n",
      "At step 5\n",
      "Epoch 1/30, train_loss: 0.01743, valid_loss: 0.00716\n",
      "Epoch 2/30, train_loss: 0.01355, valid_loss: 0.00718\n",
      "Epoch 3/30, train_loss: 0.01188, valid_loss: 0.00726\n",
      "Epoch 4/30, train_loss: 0.01093, valid_loss: 0.00763\n",
      "Epoch 5/30, train_loss: 0.01034, valid_loss: 0.00755\n",
      "Epoch 6/30, train_loss: 0.00993, valid_loss: 0.00749\n",
      "Epoch 7/30, train_loss: 0.00959, valid_loss: 0.00747\n",
      "Epoch 8/30, train_loss: 0.00936, valid_loss: 0.00783\n",
      "Epoch 9/30, train_loss: 0.00923, valid_loss: 0.00792\n",
      "Epoch 10/30, train_loss: 0.00910, valid_loss: 0.00785\n",
      "Epoch 11/30, train_loss: 0.00901, valid_loss: 0.00795\n",
      "Epoch 12/30, train_loss: 0.00891, valid_loss: 0.00799\n",
      "Epoch 13/30, train_loss: 0.00880, valid_loss: 0.00793\n",
      "Epoch 14/30, train_loss: 0.00870, valid_loss: 0.00790\n",
      "Epoch 15/30, train_loss: 0.00864, valid_loss: 0.00787\n",
      "Epoch 16/30, train_loss: 0.00856, valid_loss: 0.00784\n",
      "Epoch 17/30, train_loss: 0.00848, valid_loss: 0.00786\n",
      "Epoch 18/30, train_loss: 0.00842, valid_loss: 0.00784\n",
      "Epoch 19/30, train_loss: 0.00836, valid_loss: 0.00780\n",
      "Epoch 20/30, train_loss: 0.00832, valid_loss: 0.00799\n",
      "Epoch 21/30, train_loss: 0.00832, valid_loss: 0.00797\n",
      "Epoch 22/30, train_loss: 0.00829, valid_loss: 0.00792\n",
      "Epoch 23/30, train_loss: 0.00824, valid_loss: 0.00789\n",
      "Epoch 24/30, train_loss: 0.00820, valid_loss: 0.00789\n",
      "Epoch 25/30, train_loss: 0.00816, valid_loss: 0.00786\n",
      "Epoch 26/30, train_loss: 0.00812, valid_loss: 0.00784\n",
      "Epoch 27/30, train_loss: 0.00808, valid_loss: 0.00789\n",
      "Epoch 28/30, train_loss: 0.00807, valid_loss: 0.00794\n",
      "Epoch 29/30, train_loss: 0.00808, valid_loss: 0.00790\n",
      "Epoch 30/30, train_loss: 0.00806, valid_loss: 0.00789\n",
      "At step 4\n",
      "Epoch 1/30, train_loss: 0.01548, valid_loss: 0.00791\n",
      "Epoch 2/30, train_loss: 0.01217, valid_loss: 0.00769\n",
      "Epoch 3/30, train_loss: 0.01080, valid_loss: 0.00774\n",
      "Epoch 4/30, train_loss: 0.01004, valid_loss: 0.00766\n",
      "Epoch 5/30, train_loss: 0.00956, valid_loss: 0.00759\n",
      "Epoch 6/30, train_loss: 0.00924, valid_loss: 0.00758\n",
      "Epoch 7/30, train_loss: 0.00898, valid_loss: 0.00756\n",
      "Epoch 8/30, train_loss: 0.00878, valid_loss: 0.00751\n",
      "Epoch 9/30, train_loss: 0.00864, valid_loss: 0.00755\n",
      "Epoch 10/30, train_loss: 0.00852, valid_loss: 0.00764\n",
      "Epoch 11/30, train_loss: 0.00845, valid_loss: 0.00763\n",
      "Epoch 12/30, train_loss: 0.00834, valid_loss: 0.00759\n",
      "Epoch 13/30, train_loss: 0.00825, valid_loss: 0.00754\n",
      "Epoch 14/30, train_loss: 0.00817, valid_loss: 0.00750\n",
      "Epoch 15/30, train_loss: 0.00810, valid_loss: 0.00748\n",
      "Epoch 16/30, train_loss: 0.00804, valid_loss: 0.00745\n",
      "Epoch 17/30, train_loss: 0.00797, valid_loss: 0.00743\n",
      "Epoch 18/30, train_loss: 0.00793, valid_loss: 0.00739\n",
      "Epoch 19/30, train_loss: 0.00787, valid_loss: 0.00736\n",
      "Epoch 20/30, train_loss: 0.00783, valid_loss: 0.00733\n",
      "Epoch 21/30, train_loss: 0.00778, valid_loss: 0.00732\n",
      "Epoch 22/30, train_loss: 0.00774, valid_loss: 0.00732\n",
      "Epoch 23/30, train_loss: 0.00769, valid_loss: 0.00728\n",
      "Epoch 24/30, train_loss: 0.00765, valid_loss: 0.00724\n",
      "Epoch 25/30, train_loss: 0.00760, valid_loss: 0.00720\n",
      "Epoch 26/30, train_loss: 0.00758, valid_loss: 0.00720\n",
      "Epoch 27/30, train_loss: 0.00755, valid_loss: 0.00716\n",
      "Epoch 28/30, train_loss: 0.00751, valid_loss: 0.00715\n",
      "Epoch 29/30, train_loss: 0.00747, valid_loss: 0.00711\n",
      "Epoch 30/30, train_loss: 0.00742, valid_loss: 0.00708\n",
      "At step 3\n",
      "Epoch 1/30, train_loss: 0.01298, valid_loss: 0.00774\n",
      "Epoch 2/30, train_loss: 0.01073, valid_loss: 0.00767\n",
      "Epoch 3/30, train_loss: 0.00986, valid_loss: 0.00770\n",
      "Epoch 4/30, train_loss: 0.00944, valid_loss: 0.00767\n",
      "Epoch 5/30, train_loss: 0.00919, valid_loss: 0.00763\n",
      "Epoch 6/30, train_loss: 0.00901, valid_loss: 0.00761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, train_loss: 0.00884, valid_loss: 0.00758\n",
      "Epoch 8/30, train_loss: 0.00871, valid_loss: 0.00756\n",
      "Epoch 9/30, train_loss: 0.00860, valid_loss: 0.00754\n",
      "Epoch 10/30, train_loss: 0.00852, valid_loss: 0.00752\n",
      "Epoch 11/30, train_loss: 0.00845, valid_loss: 0.00749\n",
      "Epoch 12/30, train_loss: 0.00839, valid_loss: 0.00758\n",
      "Epoch 13/30, train_loss: 0.00834, valid_loss: 0.00759\n",
      "Epoch 14/30, train_loss: 0.00831, valid_loss: 0.00757\n",
      "Epoch 15/30, train_loss: 0.00828, valid_loss: 0.00754\n",
      "Epoch 16/30, train_loss: 0.00823, valid_loss: 0.00752\n",
      "Epoch 17/30, train_loss: 0.00818, valid_loss: 0.00754\n",
      "Epoch 18/30, train_loss: 0.00813, valid_loss: 0.00754\n",
      "Epoch 19/30, train_loss: 0.00810, valid_loss: 0.00751\n",
      "Epoch 20/30, train_loss: 0.00806, valid_loss: 0.00748\n",
      "Epoch 21/30, train_loss: 0.00803, valid_loss: 0.00745\n",
      "Epoch 22/30, train_loss: 0.00799, valid_loss: 0.00742\n",
      "Epoch 23/30, train_loss: 0.00796, valid_loss: 0.00738\n",
      "Epoch 24/30, train_loss: 0.00793, valid_loss: 0.00735\n",
      "Epoch 25/30, train_loss: 0.00789, valid_loss: 0.00732\n",
      "Epoch 26/30, train_loss: 0.00785, valid_loss: 0.00729\n",
      "Epoch 27/30, train_loss: 0.00782, valid_loss: 0.00730\n",
      "Epoch 28/30, train_loss: 0.00778, valid_loss: 0.00726\n",
      "Epoch 29/30, train_loss: 0.00776, valid_loss: 0.00727\n",
      "Epoch 30/30, train_loss: 0.00772, valid_loss: 0.00723\n",
      "At step 2\n",
      "Epoch 1/30, train_loss: 0.01341, valid_loss: 0.00785\n",
      "Epoch 2/30, train_loss: 0.01085, valid_loss: 0.00795\n",
      "Epoch 3/30, train_loss: 0.00991, valid_loss: 0.00792\n",
      "Epoch 4/30, train_loss: 0.00936, valid_loss: 0.00785\n",
      "Epoch 5/30, train_loss: 0.00902, valid_loss: 0.00779\n",
      "Epoch 6/30, train_loss: 0.00882, valid_loss: 0.00802\n",
      "Epoch 7/30, train_loss: 0.00867, valid_loss: 0.00796\n",
      "Epoch 8/30, train_loss: 0.00852, valid_loss: 0.00801\n",
      "Epoch 9/30, train_loss: 0.00841, valid_loss: 0.00795\n",
      "Epoch 10/30, train_loss: 0.00831, valid_loss: 0.00791\n",
      "Epoch 11/30, train_loss: 0.00822, valid_loss: 0.00792\n",
      "Epoch 12/30, train_loss: 0.00815, valid_loss: 0.00797\n",
      "Epoch 13/30, train_loss: 0.00812, valid_loss: 0.00792\n",
      "Epoch 14/30, train_loss: 0.00805, valid_loss: 0.00788\n",
      "Epoch 15/30, train_loss: 0.00800, valid_loss: 0.00785\n",
      "Epoch 16/30, train_loss: 0.00794, valid_loss: 0.00782\n",
      "Epoch 17/30, train_loss: 0.00790, valid_loss: 0.00778\n",
      "Epoch 18/30, train_loss: 0.00785, valid_loss: 0.00776\n",
      "Epoch 19/30, train_loss: 0.00780, valid_loss: 0.00777\n",
      "Epoch 20/30, train_loss: 0.00777, valid_loss: 0.00773\n",
      "Epoch 21/30, train_loss: 0.00776, valid_loss: 0.00772\n",
      "Epoch 22/30, train_loss: 0.00774, valid_loss: 0.00774\n",
      "Epoch 23/30, train_loss: 0.00771, valid_loss: 0.00771\n",
      "Epoch 24/30, train_loss: 0.00767, valid_loss: 0.00768\n",
      "Epoch 25/30, train_loss: 0.00764, valid_loss: 0.00765\n",
      "Epoch 26/30, train_loss: 0.00762, valid_loss: 0.00763\n",
      "Epoch 27/30, train_loss: 0.00758, valid_loss: 0.00760\n",
      "Epoch 28/30, train_loss: 0.00755, valid_loss: 0.00760\n",
      "Epoch 29/30, train_loss: 0.00752, valid_loss: 0.00761\n",
      "Epoch 30/30, train_loss: 0.00750, valid_loss: 0.00760\n",
      "Wall time: 39.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prc_nn=Bermudan_swaption_nn(lockout,maturity,sim_rates,strike,n_epochs,batch_size,learningrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European swaption pirce: 0.006939140046653583\n"
     ]
    }
   ],
   "source": [
    "print('European swaption pirce: {}'.format(prc_nn[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bermudan swaption pirce: 0.008788116431004304\n"
     ]
    }
   ],
   "source": [
    "print('Bermudan swaption pirce: {}'.format(prc_nn[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excercise Probability Table\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_step</th>\n",
       "      <th>ex_prob_Euro</th>\n",
       "      <th>ex_prob_RLNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.4824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Time_step  ex_prob_Euro  ex_prob_RLNN\n",
       "0           2         0.708        0.4824\n",
       "1           3         0.000        0.1858\n",
       "2           4         0.000        0.0670\n",
       "3           5         0.000        0.0296\n",
       "4           6         0.000        0.0128\n",
       "5           7         0.000        0.0080\n",
       "6           8         0.000        0.0086\n",
       "7           9         0.000        0.0032\n",
       "8          10         0.000        0.0028\n",
       "9          11         0.000        0.0034\n",
       "10         12         0.000        0.0044\n",
       "11         13         0.000        0.0016\n",
       "12         14         0.000        0.0036\n",
       "13         15         0.000        0.0014\n",
       "14         16         0.000        0.0038\n",
       "15         17         0.000        0.0036\n",
       "16         18         0.000        0.0046\n",
       "17         19         0.000        0.0030"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Excercise Probability Table')\n",
    "prc_nn[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import pycaret\n",
    "from pycaret.regression import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following cells is used to show how our XGBoost model is tuned at each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.891232</td>\n",
       "      <td>0.089891</td>\n",
       "      <td>-0.228538</td>\n",
       "      <td>-0.778409</td>\n",
       "      <td>-1.076887</td>\n",
       "      <td>-0.153667</td>\n",
       "      <td>0.329244</td>\n",
       "      <td>0.058707</td>\n",
       "      <td>0.061015</td>\n",
       "      <td>-1.920108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>-1.028953</td>\n",
       "      <td>0.224267</td>\n",
       "      <td>2.352286</td>\n",
       "      <td>1.218678</td>\n",
       "      <td>0.123032</td>\n",
       "      <td>-0.255382</td>\n",
       "      <td>-1.606264</td>\n",
       "      <td>-1.321751</td>\n",
       "      <td>-0.386526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.186863</td>\n",
       "      <td>0.275995</td>\n",
       "      <td>2.344247</td>\n",
       "      <td>0.407977</td>\n",
       "      <td>-0.298008</td>\n",
       "      <td>-0.671003</td>\n",
       "      <td>-0.804555</td>\n",
       "      <td>-0.702106</td>\n",
       "      <td>-0.121839</td>\n",
       "      <td>0.242805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.747894</td>\n",
       "      <td>0.908411</td>\n",
       "      <td>0.764664</td>\n",
       "      <td>-0.329349</td>\n",
       "      <td>-0.580607</td>\n",
       "      <td>-1.154345</td>\n",
       "      <td>0.302104</td>\n",
       "      <td>-0.995525</td>\n",
       "      <td>-0.555875</td>\n",
       "      <td>-0.140838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.833466</td>\n",
       "      <td>-0.039210</td>\n",
       "      <td>0.611904</td>\n",
       "      <td>0.431463</td>\n",
       "      <td>0.538390</td>\n",
       "      <td>1.925852</td>\n",
       "      <td>0.420892</td>\n",
       "      <td>-0.637434</td>\n",
       "      <td>-0.289325</td>\n",
       "      <td>-2.530420</td>\n",
       "      <td>...</td>\n",
       "      <td>1.013046</td>\n",
       "      <td>-0.010963</td>\n",
       "      <td>-0.884846</td>\n",
       "      <td>1.516457</td>\n",
       "      <td>-0.852977</td>\n",
       "      <td>1.103977</td>\n",
       "      <td>-0.260355</td>\n",
       "      <td>1.323633</td>\n",
       "      <td>0.198478</td>\n",
       "      <td>0.884186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-1.832918</td>\n",
       "      <td>1.104425</td>\n",
       "      <td>-1.412599</td>\n",
       "      <td>2.472525</td>\n",
       "      <td>-0.188355</td>\n",
       "      <td>-0.011710</td>\n",
       "      <td>-1.058770</td>\n",
       "      <td>-0.205268</td>\n",
       "      <td>-0.050947</td>\n",
       "      <td>-0.681839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094868</td>\n",
       "      <td>3.024385</td>\n",
       "      <td>-0.873285</td>\n",
       "      <td>0.123418</td>\n",
       "      <td>0.235007</td>\n",
       "      <td>-2.619171</td>\n",
       "      <td>-1.170854</td>\n",
       "      <td>0.984160</td>\n",
       "      <td>0.488254</td>\n",
       "      <td>2.639618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1.682840</td>\n",
       "      <td>-1.151599</td>\n",
       "      <td>1.043588</td>\n",
       "      <td>1.185431</td>\n",
       "      <td>0.456189</td>\n",
       "      <td>-0.580031</td>\n",
       "      <td>-0.203965</td>\n",
       "      <td>-2.090221</td>\n",
       "      <td>1.259256</td>\n",
       "      <td>0.975432</td>\n",
       "      <td>...</td>\n",
       "      <td>1.158101</td>\n",
       "      <td>0.092897</td>\n",
       "      <td>-0.345609</td>\n",
       "      <td>0.295462</td>\n",
       "      <td>0.023780</td>\n",
       "      <td>0.276973</td>\n",
       "      <td>0.899548</td>\n",
       "      <td>1.958868</td>\n",
       "      <td>0.814505</td>\n",
       "      <td>-0.435555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.891232  0.089891 -0.228538 -0.778409 -1.076887 -0.153667  0.329244   \n",
       "1  0.186863  0.275995  2.344247  0.407977 -0.298008 -0.671003 -0.804555   \n",
       "2 -1.833466 -0.039210  0.611904  0.431463  0.538390  1.925852  0.420892   \n",
       "3 -1.832918  1.104425 -1.412599  2.472525 -0.188355 -0.011710 -1.058770   \n",
       "4 -1.682840 -1.151599  1.043588  1.185431  0.456189 -0.580031 -0.203965   \n",
       "\n",
       "          7         8         9  ...        11        12        13        14  \\\n",
       "0  0.058707  0.061015 -1.920108  ...  0.003232 -1.028953  0.224267  2.352286   \n",
       "1 -0.702106 -0.121839  0.242805  ... -0.747894  0.908411  0.764664 -0.329349   \n",
       "2 -0.637434 -0.289325 -2.530420  ...  1.013046 -0.010963 -0.884846  1.516457   \n",
       "3 -0.205268 -0.050947 -0.681839  ...  0.094868  3.024385 -0.873285  0.123418   \n",
       "4 -2.090221  1.259256  0.975432  ...  1.158101  0.092897 -0.345609  0.295462   \n",
       "\n",
       "         15        16        17        18        19         y  \n",
       "0  1.218678  0.123032 -0.255382 -1.606264 -1.321751 -0.386526  \n",
       "1 -0.580607 -1.154345  0.302104 -0.995525 -0.555875 -0.140838  \n",
       "2 -0.852977  1.103977 -0.260355  1.323633  0.198478  0.884186  \n",
       "3  0.235007 -2.619171 -1.170854  0.984160  0.488254  2.639618  \n",
       "4  0.023780  0.276973  0.899548  1.958868  0.814505 -0.435555  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create test data\n",
    "x=np.random.normal(size=(1000,20)) # 1000 obervations with 20 features\n",
    "y=np.random.normal(size=1000)\n",
    "\n",
    "df=pd.DataFrame(x)\n",
    "df['y']=y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow27_col1 {\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8c\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Description</th>        <th class=\"col_heading level0 col1\" >Value</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow0_col1\" class=\"data row0 col1\" >4754</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow1_col1\" class=\"data row1 col1\" >y</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow2_col0\" class=\"data row2 col0\" >Original Data</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow2_col1\" class=\"data row2 col1\" >(1000, 21)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow3_col0\" class=\"data row3 col0\" >Missing Values</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow3_col1\" class=\"data row3 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow4_col0\" class=\"data row4 col0\" >Numeric Features</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow4_col1\" class=\"data row4 col1\" >20</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow5_col0\" class=\"data row5 col0\" >Categorical Features</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow5_col1\" class=\"data row5 col1\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow6_col0\" class=\"data row6 col0\" >Ordinal Features</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow6_col1\" class=\"data row6 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow7_col0\" class=\"data row7 col0\" >High Cardinality Features</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow7_col1\" class=\"data row7 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow8_col0\" class=\"data row8 col0\" >High Cardinality Method</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow8_col1\" class=\"data row8 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow9_col0\" class=\"data row9 col0\" >Transformed Train Set</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow9_col1\" class=\"data row9 col1\" >(900, 20)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow10_col0\" class=\"data row10 col0\" >Transformed Test Set</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow10_col1\" class=\"data row10 col1\" >(100, 20)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow11_col0\" class=\"data row11 col0\" >Shuffle Train-Test</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow11_col1\" class=\"data row11 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow12_col0\" class=\"data row12 col0\" >Stratify Train-Test</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow12_col1\" class=\"data row12 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow13_col0\" class=\"data row13 col0\" >Fold Generator</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow13_col1\" class=\"data row13 col1\" >KFold</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow14_col0\" class=\"data row14 col0\" >Fold Number</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow14_col1\" class=\"data row14 col1\" >10</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow15_col0\" class=\"data row15 col0\" >CPU Jobs</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow15_col1\" class=\"data row15 col1\" >-1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow16_col0\" class=\"data row16 col0\" >Use GPU</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow16_col1\" class=\"data row16 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow17_col0\" class=\"data row17 col0\" >Log Experiment</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow17_col1\" class=\"data row17 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow18_col0\" class=\"data row18 col0\" >Experiment Name</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow18_col1\" class=\"data row18 col1\" >reg-default-name</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow19_col0\" class=\"data row19 col0\" >USI</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow19_col1\" class=\"data row19 col1\" >ada4</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow20_col0\" class=\"data row20 col0\" >Imputation Type</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow20_col1\" class=\"data row20 col1\" >simple</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow21_col0\" class=\"data row21 col0\" >Iterative Imputation Iteration</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow21_col1\" class=\"data row21 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow22_col0\" class=\"data row22 col0\" >Numeric Imputer</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow22_col1\" class=\"data row22 col1\" >mean</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow23_col0\" class=\"data row23 col0\" >Iterative Imputation Numeric Model</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow23_col1\" class=\"data row23 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow24_col0\" class=\"data row24 col0\" >Categorical Imputer</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow24_col1\" class=\"data row24 col1\" >constant</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow25_col0\" class=\"data row25 col0\" >Iterative Imputation Categorical Model</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow25_col1\" class=\"data row25 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow26_col0\" class=\"data row26 col0\" >Unknown Categoricals Handling</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow26_col1\" class=\"data row26 col1\" >least_frequent</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow27_col0\" class=\"data row27 col0\" >Normalize</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow27_col1\" class=\"data row27 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow28_col0\" class=\"data row28 col0\" >Normalize Method</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow28_col1\" class=\"data row28 col1\" >minmax</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow29_col0\" class=\"data row29 col0\" >Transformation</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow29_col1\" class=\"data row29 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow30_col0\" class=\"data row30 col0\" >Transformation Method</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow30_col1\" class=\"data row30 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow31_col0\" class=\"data row31 col0\" >PCA</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow31_col1\" class=\"data row31 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow32_col0\" class=\"data row32 col0\" >PCA Method</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow32_col1\" class=\"data row32 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow33_col0\" class=\"data row33 col0\" >PCA Components</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow33_col1\" class=\"data row33 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow34_col0\" class=\"data row34 col0\" >Ignore Low Variance</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow34_col1\" class=\"data row34 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow35_col0\" class=\"data row35 col0\" >Combine Rare Levels</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow35_col1\" class=\"data row35 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow36_col0\" class=\"data row36 col0\" >Rare Level Threshold</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow36_col1\" class=\"data row36 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow37_col0\" class=\"data row37 col0\" >Numeric Binning</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow37_col1\" class=\"data row37 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow38_col0\" class=\"data row38 col0\" >Remove Outliers</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow38_col1\" class=\"data row38 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow39_col0\" class=\"data row39 col0\" >Outliers Threshold</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow39_col1\" class=\"data row39 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow40_col0\" class=\"data row40 col0\" >Remove Multicollinearity</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow40_col1\" class=\"data row40 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow41_col0\" class=\"data row41 col0\" >Multicollinearity Threshold</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow41_col1\" class=\"data row41 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow42_col0\" class=\"data row42 col0\" >Clustering</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow42_col1\" class=\"data row42 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow43_col0\" class=\"data row43 col0\" >Clustering Iteration</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow43_col1\" class=\"data row43 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow44_col0\" class=\"data row44 col0\" >Polynomial Features</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow44_col1\" class=\"data row44 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow45_col0\" class=\"data row45 col0\" >Polynomial Degree</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow45_col1\" class=\"data row45 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow46_col0\" class=\"data row46 col0\" >Trignometry Features</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow46_col1\" class=\"data row46 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow47_col0\" class=\"data row47 col0\" >Polynomial Threshold</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow47_col1\" class=\"data row47 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow48_col0\" class=\"data row48 col0\" >Group Features</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow48_col1\" class=\"data row48 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow49_col0\" class=\"data row49 col0\" >Feature Selection</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow49_col1\" class=\"data row49 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow50_col0\" class=\"data row50 col0\" >Features Selection Threshold</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow50_col1\" class=\"data row50 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow51_col0\" class=\"data row51 col0\" >Feature Interaction</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow51_col1\" class=\"data row51 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow52_col0\" class=\"data row52 col0\" >Feature Ratio</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow52_col1\" class=\"data row52 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow53_col0\" class=\"data row53 col0\" >Interaction Threshold</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow53_col1\" class=\"data row53 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow54_col0\" class=\"data row54 col0\" >Transform Target</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow54_col1\" class=\"data row54 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8clevel0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow55_col0\" class=\"data row55 col0\" >Transform Target Method</td>\n",
       "                        <td id=\"T_5dcb979c_1f28_11eb_b5e3_9cb6d09a5d8crow55_col1\" class=\"data row55 col1\" >box-cox</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c3838c50c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set up environment\n",
    "\"\"\"\n",
    " target: target predict value\n",
    " html: Notebook is True\n",
    " normalize_method: z_score, minmax....\n",
    " train_size: default 0.7, chosen as train and valid data, left as test data, here we choose 0.9\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "exp_reg=setup(df,target='y',html=True,\n",
    "                  normalize=True,\n",
    "                  normalize_method='minmax',\n",
    "                  data_split_shuffle=True,\n",
    "                  train_size=0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8c th {\n",
       "          text-align: left;\n",
       "    }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow0_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow0_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow0_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow0_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow0_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow0_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow0_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow0_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow1_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow1_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow1_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow1_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow1_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow1_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow1_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow1_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow2_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow2_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow2_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow2_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow2_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow2_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow2_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow2_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow3_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow3_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow3_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow3_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow3_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow3_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow3_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow3_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow4_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow4_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow4_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow4_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow4_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow4_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow4_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow4_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow5_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow5_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow5_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow5_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow5_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow5_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow5_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow5_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow6_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow6_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow6_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow6_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow6_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow6_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow6_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow6_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow7_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow7_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow7_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow7_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow7_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow7_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow7_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow7_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow8_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow8_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow8_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow8_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow8_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow8_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow8_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow8_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow9_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow9_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow9_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow9_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow9_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow9_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow9_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow9_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow10_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow10_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow10_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow10_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow10_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow10_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow10_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow10_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow11_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow11_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow11_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow11_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow11_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow11_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow11_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow11_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow12_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow12_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow12_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow12_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow12_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow12_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow12_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow12_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow13_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow13_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow13_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow13_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow13_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow13_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow13_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow13_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow14_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow14_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow14_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow14_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow14_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow14_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow14_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow14_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow15_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow15_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow15_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow15_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow15_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow15_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow15_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow15_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow16_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow16_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow16_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow16_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow16_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow16_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow16_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow16_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow17_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow17_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow17_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow17_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow17_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow17_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow17_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow17_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow18_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow18_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow18_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow18_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow18_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow18_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow18_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow18_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }</style><table id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8c\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model</th>        <th class=\"col_heading level0 col1\" >MAE</th>        <th class=\"col_heading level0 col2\" >MSE</th>        <th class=\"col_heading level0 col3\" >RMSE</th>        <th class=\"col_heading level0 col4\" >R2</th>        <th class=\"col_heading level0 col5\" >RMSLE</th>        <th class=\"col_heading level0 col6\" >MAPE</th>        <th class=\"col_heading level0 col7\" >TT (Sec)</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8clevel0_row0\" class=\"row_heading level0 row0\" >lasso</th>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow0_col0\" class=\"data row0 col0\" >Lasso Regression</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow0_col1\" class=\"data row0 col1\" >0.7814</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow0_col2\" class=\"data row0 col2\" >0.9383</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow0_col3\" class=\"data row0 col3\" >0.9675</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow0_col4\" class=\"data row0 col4\" >-0.0058</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow0_col5\" class=\"data row0 col5\" >0.5768</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow0_col6\" class=\"data row0 col6\" >1.159</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow0_col7\" class=\"data row0 col7\" >0.008</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8clevel0_row1\" class=\"row_heading level0 row1\" >en</th>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow1_col0\" class=\"data row1 col0\" >Elastic Net</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow1_col1\" class=\"data row1 col1\" >0.7814</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow1_col2\" class=\"data row1 col2\" >0.9383</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow1_col3\" class=\"data row1 col3\" >0.9675</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow1_col4\" class=\"data row1 col4\" >-0.0058</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow1_col5\" class=\"data row1 col5\" >0.5768</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow1_col6\" class=\"data row1 col6\" >1.159</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow1_col7\" class=\"data row1 col7\" >0.007</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8clevel0_row2\" class=\"row_heading level0 row2\" >llar</th>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow2_col0\" class=\"data row2 col0\" >Lasso Least Angle Regression</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow2_col1\" class=\"data row2 col1\" >0.7814</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow2_col2\" class=\"data row2 col2\" >0.9383</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow2_col3\" class=\"data row2 col3\" >0.9675</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow2_col4\" class=\"data row2 col4\" >-0.0058</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow2_col5\" class=\"data row2 col5\" >0.5768</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow2_col6\" class=\"data row2 col6\" >1.159</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow2_col7\" class=\"data row2 col7\" >0.012</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8clevel0_row3\" class=\"row_heading level0 row3\" >br</th>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow3_col0\" class=\"data row3 col0\" >Bayesian Ridge</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow3_col1\" class=\"data row3 col1\" >0.7823</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow3_col2\" class=\"data row3 col2\" >0.9409</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow3_col3\" class=\"data row3 col3\" >0.9689</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow3_col4\" class=\"data row3 col4\" >-0.0089</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow3_col5\" class=\"data row3 col5\" >0.578</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow3_col6\" class=\"data row3 col6\" >1.16</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow3_col7\" class=\"data row3 col7\" >0.008</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8clevel0_row4\" class=\"row_heading level0 row4\" >omp</th>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow4_col0\" class=\"data row4 col0\" >Orthogonal Matching Pursuit</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow4_col1\" class=\"data row4 col1\" >0.7846</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow4_col2\" class=\"data row4 col2\" >0.9451</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow4_col3\" class=\"data row4 col3\" >0.9711</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow4_col4\" class=\"data row4 col4\" >-0.0136</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow4_col5\" class=\"data row4 col5\" >0.5457</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow4_col6\" class=\"data row4 col6\" >1.561</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow4_col7\" class=\"data row4 col7\" >0.009</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8clevel0_row5\" class=\"row_heading level0 row5\" >ridge</th>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow5_col0\" class=\"data row5 col0\" >Ridge Regression</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow5_col1\" class=\"data row5 col1\" >0.7866</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow5_col2\" class=\"data row5 col2\" >0.9558</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow5_col3\" class=\"data row5 col3\" >0.9767</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow5_col4\" class=\"data row5 col4\" >-0.0258</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow5_col5\" class=\"data row5 col5\" >0.526</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow5_col6\" class=\"data row5 col6\" >1.385</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow5_col7\" class=\"data row5 col7\" >0.008</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8clevel0_row6\" class=\"row_heading level0 row6\" >lr</th>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow6_col0\" class=\"data row6 col0\" >Linear Regression</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow6_col1\" class=\"data row6 col1\" >0.7875</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow6_col2\" class=\"data row6 col2\" >0.9581</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow6_col3\" class=\"data row6 col3\" >0.9778</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow6_col4\" class=\"data row6 col4\" >-0.0284</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow6_col5\" class=\"data row6 col5\" >0.5224</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow6_col6\" class=\"data row6 col6\" >1.413</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow6_col7\" class=\"data row6 col7\" >0.009</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8clevel0_row7\" class=\"row_heading level0 row7\" >lar</th>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow7_col0\" class=\"data row7 col0\" >Least Angle Regression</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow7_col1\" class=\"data row7 col1\" >0.7875</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow7_col2\" class=\"data row7 col2\" >0.9581</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow7_col3\" class=\"data row7 col3\" >0.9778</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow7_col4\" class=\"data row7 col4\" >-0.0284</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow7_col5\" class=\"data row7 col5\" >0.5224</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow7_col6\" class=\"data row7 col6\" >1.413</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow7_col7\" class=\"data row7 col7\" >0.008</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8clevel0_row8\" class=\"row_heading level0 row8\" >huber</th>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow8_col0\" class=\"data row8 col0\" >Huber Regressor</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow8_col1\" class=\"data row8 col1\" >0.7907</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow8_col2\" class=\"data row8 col2\" >0.9614</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow8_col3\" class=\"data row8 col3\" >0.9795</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow8_col4\" class=\"data row8 col4\" >-0.0318</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow8_col5\" class=\"data row8 col5\" >0.5146</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow8_col6\" class=\"data row8 col6\" >1.546</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow8_col7\" class=\"data row8 col7\" >0.009</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8clevel0_row9\" class=\"row_heading level0 row9\" >et</th>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow9_col0\" class=\"data row9 col0\" >Extra Trees Regressor</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow9_col1\" class=\"data row9 col1\" >0.7949</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow9_col2\" class=\"data row9 col2\" >0.9629</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow9_col3\" class=\"data row9 col3\" >0.9802</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow9_col4\" class=\"data row9 col4\" >-0.0334</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow9_col5\" class=\"data row9 col5\" >0.5016</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow9_col6\" class=\"data row9 col6\" >1.739</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow9_col7\" class=\"data row9 col7\" >0.211</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8clevel0_row10\" class=\"row_heading level0 row10\" >ada</th>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow10_col0\" class=\"data row10 col0\" >AdaBoost Regressor</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow10_col1\" class=\"data row10 col1\" >0.7972</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow10_col2\" class=\"data row10 col2\" >0.9665</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow10_col3\" class=\"data row10 col3\" >0.9822</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow10_col4\" class=\"data row10 col4\" >-0.0381</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow10_col5\" class=\"data row10 col5\" >0.5088</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow10_col6\" class=\"data row10 col6\" >1.974</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow10_col7\" class=\"data row10 col7\" >0.042</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8clevel0_row11\" class=\"row_heading level0 row11\" >rf</th>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow11_col0\" class=\"data row11 col0\" >Random Forest Regressor</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow11_col1\" class=\"data row11 col1\" >0.7988</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow11_col2\" class=\"data row11 col2\" >0.9722</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow11_col3\" class=\"data row11 col3\" >0.9849</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow11_col4\" class=\"data row11 col4\" >-0.0432</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow11_col5\" class=\"data row11 col5\" >0.502</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow11_col6\" class=\"data row11 col6\" >1.923</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow11_col7\" class=\"data row11 col7\" >0.301</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8clevel0_row12\" class=\"row_heading level0 row12\" >catboost</th>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow12_col0\" class=\"data row12 col0\" >CatBoost Regressor</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow12_col1\" class=\"data row12 col1\" >0.8176</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow12_col2\" class=\"data row12 col2\" >1.015</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow12_col3\" class=\"data row12 col3\" >1.006</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow12_col4\" class=\"data row12 col4\" >-0.0895</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow12_col5\" class=\"data row12 col5\" >0.4696</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow12_col6\" class=\"data row12 col6\" >2.357</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow12_col7\" class=\"data row12 col7\" >2.723</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8clevel0_row13\" class=\"row_heading level0 row13\" >gbr</th>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow13_col0\" class=\"data row13 col0\" >Gradient Boosting Regressor</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow13_col1\" class=\"data row13 col1\" >0.8182</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow13_col2\" class=\"data row13 col2\" >1.024</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow13_col3\" class=\"data row13 col3\" >1.01</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow13_col4\" class=\"data row13 col4\" >-0.0988</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow13_col5\" class=\"data row13 col5\" >0.4876</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow13_col6\" class=\"data row13 col6\" >2.744</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow13_col7\" class=\"data row13 col7\" >0.094</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8clevel0_row14\" class=\"row_heading level0 row14\" >lightgbm</th>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow14_col0\" class=\"data row14 col0\" >Light Gradient Boosting Machine</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow14_col1\" class=\"data row14 col1\" >0.8455</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow14_col2\" class=\"data row14 col2\" >1.099</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow14_col3\" class=\"data row14 col3\" >1.047</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow14_col4\" class=\"data row14 col4\" >-0.183</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow14_col5\" class=\"data row14 col5\" >0.4496</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow14_col6\" class=\"data row14 col6\" >2.643</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow14_col7\" class=\"data row14 col7\" >0.052</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8clevel0_row15\" class=\"row_heading level0 row15\" >knn</th>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow15_col0\" class=\"data row15 col0\" >K Neighbors Regressor</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow15_col1\" class=\"data row15 col1\" >0.848</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow15_col2\" class=\"data row15 col2\" >1.103</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow15_col3\" class=\"data row15 col3\" >1.05</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow15_col4\" class=\"data row15 col4\" >-0.1912</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow15_col5\" class=\"data row15 col5\" >0.4363</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow15_col6\" class=\"data row15 col6\" >2.678</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow15_col7\" class=\"data row15 col7\" >0.032</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8clevel0_row16\" class=\"row_heading level0 row16\" >xgboost</th>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow16_col0\" class=\"data row16 col0\" >Extreme Gradient Boosting</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow16_col1\" class=\"data row16 col1\" >0.8755</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow16_col2\" class=\"data row16 col2\" >1.168</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow16_col3\" class=\"data row16 col3\" >1.079</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow16_col4\" class=\"data row16 col4\" >-0.2539</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow16_col5\" class=\"data row16 col5\" >0.4345</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow16_col6\" class=\"data row16 col6\" >3.962</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow16_col7\" class=\"data row16 col7\" >0.188</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8clevel0_row17\" class=\"row_heading level0 row17\" >par</th>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow17_col0\" class=\"data row17 col0\" >Passive Aggressive Regressor</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow17_col1\" class=\"data row17 col1\" >0.9499</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow17_col2\" class=\"data row17 col2\" >1.409</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow17_col3\" class=\"data row17 col3\" >1.178</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow17_col4\" class=\"data row17 col4\" >-0.498</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow17_col5\" class=\"data row17 col5\" >0.3801</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow17_col6\" class=\"data row17 col6\" >4.29</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow17_col7\" class=\"data row17 col7\" >0.01</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8clevel0_row18\" class=\"row_heading level0 row18\" >dt</th>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow18_col0\" class=\"data row18 col0\" >Decision Tree Regressor</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow18_col1\" class=\"data row18 col1\" >1.122</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow18_col2\" class=\"data row18 col2\" >1.943</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow18_col3\" class=\"data row18 col3\" >1.391</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow18_col4\" class=\"data row18 col4\" >-1.096</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow18_col5\" class=\"data row18 col5\" >0.4391</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow18_col6\" class=\"data row18 col6\" >8.099</td>\n",
       "                        <td id=\"T_785d5bee_1f28_11eb_8c33_9cb6d09a5d8crow18_col7\" class=\"data row18 col7\" >0.009</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c380946048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=4754,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8c th {\n",
       "          text-align: left;\n",
       "    }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow0_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow0_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow0_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow0_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow0_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow0_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow0_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow0_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow1_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow1_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow1_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow1_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow1_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow1_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow1_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow1_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow2_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow2_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow2_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow2_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow2_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow2_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow2_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow2_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow3_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow3_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow3_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow3_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow3_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow3_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow3_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow3_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow4_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow4_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow4_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow4_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow4_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow4_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow4_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow4_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow5_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow5_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow5_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow5_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow5_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow5_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow5_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow5_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow6_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow6_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow6_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow6_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow6_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow6_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow6_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow6_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow7_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow7_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow7_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow7_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow7_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow7_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow7_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow7_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow8_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow8_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow8_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow8_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow8_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow8_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow8_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow8_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow9_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow9_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow9_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow9_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow9_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow9_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow9_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow9_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow10_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow10_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow10_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow10_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow10_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow10_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow10_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow10_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow11_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow11_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow11_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow11_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow11_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow11_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow11_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow11_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow12_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow12_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow12_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow12_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow12_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow12_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow12_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow12_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow13_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow13_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow13_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow13_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow13_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow13_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow13_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow13_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow14_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow14_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow14_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow14_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow14_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow14_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow14_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow14_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow15_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow15_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow15_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow15_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow15_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow15_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow15_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow15_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow16_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow16_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow16_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow16_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow16_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow16_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow16_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow16_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow17_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow17_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow17_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow17_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow17_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow17_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow17_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow17_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow18_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow18_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow18_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow18_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow18_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow18_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow18_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow18_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }</style><table id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8c\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model</th>        <th class=\"col_heading level0 col1\" >MAE</th>        <th class=\"col_heading level0 col2\" >MSE</th>        <th class=\"col_heading level0 col3\" >RMSE</th>        <th class=\"col_heading level0 col4\" >R2</th>        <th class=\"col_heading level0 col5\" >RMSLE</th>        <th class=\"col_heading level0 col6\" >MAPE</th>        <th class=\"col_heading level0 col7\" >TT (Sec)</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8clevel0_row0\" class=\"row_heading level0 row0\" >lasso</th>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow0_col0\" class=\"data row0 col0\" >Lasso Regression</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow0_col1\" class=\"data row0 col1\" >0.7814</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow0_col2\" class=\"data row0 col2\" >0.9383</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow0_col3\" class=\"data row0 col3\" >0.9675</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow0_col4\" class=\"data row0 col4\" >-0.0058</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow0_col5\" class=\"data row0 col5\" >0.5768</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow0_col6\" class=\"data row0 col6\" >1.159</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow0_col7\" class=\"data row0 col7\" >0.007</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8clevel0_row1\" class=\"row_heading level0 row1\" >en</th>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow1_col0\" class=\"data row1 col0\" >Elastic Net</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow1_col1\" class=\"data row1 col1\" >0.7814</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow1_col2\" class=\"data row1 col2\" >0.9383</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow1_col3\" class=\"data row1 col3\" >0.9675</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow1_col4\" class=\"data row1 col4\" >-0.0058</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow1_col5\" class=\"data row1 col5\" >0.5768</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow1_col6\" class=\"data row1 col6\" >1.159</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow1_col7\" class=\"data row1 col7\" >0.007</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8clevel0_row2\" class=\"row_heading level0 row2\" >llar</th>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow2_col0\" class=\"data row2 col0\" >Lasso Least Angle Regression</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow2_col1\" class=\"data row2 col1\" >0.7814</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow2_col2\" class=\"data row2 col2\" >0.9383</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow2_col3\" class=\"data row2 col3\" >0.9675</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow2_col4\" class=\"data row2 col4\" >-0.0058</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow2_col5\" class=\"data row2 col5\" >0.5768</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow2_col6\" class=\"data row2 col6\" >1.159</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow2_col7\" class=\"data row2 col7\" >0.007</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8clevel0_row3\" class=\"row_heading level0 row3\" >br</th>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow3_col0\" class=\"data row3 col0\" >Bayesian Ridge</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow3_col1\" class=\"data row3 col1\" >0.7823</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow3_col2\" class=\"data row3 col2\" >0.9409</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow3_col3\" class=\"data row3 col3\" >0.9689</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow3_col4\" class=\"data row3 col4\" >-0.0089</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow3_col5\" class=\"data row3 col5\" >0.578</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow3_col6\" class=\"data row3 col6\" >1.16</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow3_col7\" class=\"data row3 col7\" >0.007</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8clevel0_row4\" class=\"row_heading level0 row4\" >omp</th>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow4_col0\" class=\"data row4 col0\" >Orthogonal Matching Pursuit</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow4_col1\" class=\"data row4 col1\" >0.7846</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow4_col2\" class=\"data row4 col2\" >0.9451</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow4_col3\" class=\"data row4 col3\" >0.9711</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow4_col4\" class=\"data row4 col4\" >-0.0136</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow4_col5\" class=\"data row4 col5\" >0.5457</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow4_col6\" class=\"data row4 col6\" >1.561</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow4_col7\" class=\"data row4 col7\" >0.008</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8clevel0_row5\" class=\"row_heading level0 row5\" >ridge</th>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow5_col0\" class=\"data row5 col0\" >Ridge Regression</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow5_col1\" class=\"data row5 col1\" >0.7866</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow5_col2\" class=\"data row5 col2\" >0.9558</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow5_col3\" class=\"data row5 col3\" >0.9767</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow5_col4\" class=\"data row5 col4\" >-0.0258</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow5_col5\" class=\"data row5 col5\" >0.526</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow5_col6\" class=\"data row5 col6\" >1.385</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow5_col7\" class=\"data row5 col7\" >0.007</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8clevel0_row6\" class=\"row_heading level0 row6\" >lr</th>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow6_col0\" class=\"data row6 col0\" >Linear Regression</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow6_col1\" class=\"data row6 col1\" >0.7875</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow6_col2\" class=\"data row6 col2\" >0.9581</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow6_col3\" class=\"data row6 col3\" >0.9778</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow6_col4\" class=\"data row6 col4\" >-0.0284</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow6_col5\" class=\"data row6 col5\" >0.5224</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow6_col6\" class=\"data row6 col6\" >1.413</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow6_col7\" class=\"data row6 col7\" >0.009</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8clevel0_row7\" class=\"row_heading level0 row7\" >lar</th>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow7_col0\" class=\"data row7 col0\" >Least Angle Regression</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow7_col1\" class=\"data row7 col1\" >0.7875</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow7_col2\" class=\"data row7 col2\" >0.9581</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow7_col3\" class=\"data row7 col3\" >0.9778</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow7_col4\" class=\"data row7 col4\" >-0.0284</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow7_col5\" class=\"data row7 col5\" >0.5224</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow7_col6\" class=\"data row7 col6\" >1.413</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow7_col7\" class=\"data row7 col7\" >0.007</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8clevel0_row8\" class=\"row_heading level0 row8\" >huber</th>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow8_col0\" class=\"data row8 col0\" >Huber Regressor</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow8_col1\" class=\"data row8 col1\" >0.7907</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow8_col2\" class=\"data row8 col2\" >0.9614</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow8_col3\" class=\"data row8 col3\" >0.9795</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow8_col4\" class=\"data row8 col4\" >-0.0318</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow8_col5\" class=\"data row8 col5\" >0.5146</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow8_col6\" class=\"data row8 col6\" >1.546</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow8_col7\" class=\"data row8 col7\" >0.01</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8clevel0_row9\" class=\"row_heading level0 row9\" >et</th>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow9_col0\" class=\"data row9 col0\" >Extra Trees Regressor</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow9_col1\" class=\"data row9 col1\" >0.7949</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow9_col2\" class=\"data row9 col2\" >0.9629</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow9_col3\" class=\"data row9 col3\" >0.9802</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow9_col4\" class=\"data row9 col4\" >-0.0334</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow9_col5\" class=\"data row9 col5\" >0.5016</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow9_col6\" class=\"data row9 col6\" >1.739</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow9_col7\" class=\"data row9 col7\" >0.205</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8clevel0_row10\" class=\"row_heading level0 row10\" >ada</th>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow10_col0\" class=\"data row10 col0\" >AdaBoost Regressor</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow10_col1\" class=\"data row10 col1\" >0.7972</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow10_col2\" class=\"data row10 col2\" >0.9665</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow10_col3\" class=\"data row10 col3\" >0.9822</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow10_col4\" class=\"data row10 col4\" >-0.0381</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow10_col5\" class=\"data row10 col5\" >0.5088</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow10_col6\" class=\"data row10 col6\" >1.974</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow10_col7\" class=\"data row10 col7\" >0.044</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8clevel0_row11\" class=\"row_heading level0 row11\" >rf</th>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow11_col0\" class=\"data row11 col0\" >Random Forest Regressor</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow11_col1\" class=\"data row11 col1\" >0.7988</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow11_col2\" class=\"data row11 col2\" >0.9722</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow11_col3\" class=\"data row11 col3\" >0.9849</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow11_col4\" class=\"data row11 col4\" >-0.0432</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow11_col5\" class=\"data row11 col5\" >0.502</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow11_col6\" class=\"data row11 col6\" >1.923</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow11_col7\" class=\"data row11 col7\" >0.297</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8clevel0_row12\" class=\"row_heading level0 row12\" >catboost</th>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow12_col0\" class=\"data row12 col0\" >CatBoost Regressor</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow12_col1\" class=\"data row12 col1\" >0.8176</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow12_col2\" class=\"data row12 col2\" >1.015</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow12_col3\" class=\"data row12 col3\" >1.006</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow12_col4\" class=\"data row12 col4\" >-0.0895</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow12_col5\" class=\"data row12 col5\" >0.4696</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow12_col6\" class=\"data row12 col6\" >2.357</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow12_col7\" class=\"data row12 col7\" >3.317</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8clevel0_row13\" class=\"row_heading level0 row13\" >gbr</th>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow13_col0\" class=\"data row13 col0\" >Gradient Boosting Regressor</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow13_col1\" class=\"data row13 col1\" >0.8182</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow13_col2\" class=\"data row13 col2\" >1.024</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow13_col3\" class=\"data row13 col3\" >1.01</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow13_col4\" class=\"data row13 col4\" >-0.0988</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow13_col5\" class=\"data row13 col5\" >0.4876</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow13_col6\" class=\"data row13 col6\" >2.744</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow13_col7\" class=\"data row13 col7\" >0.097</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8clevel0_row14\" class=\"row_heading level0 row14\" >lightgbm</th>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow14_col0\" class=\"data row14 col0\" >Light Gradient Boosting Machine</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow14_col1\" class=\"data row14 col1\" >0.8455</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow14_col2\" class=\"data row14 col2\" >1.099</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow14_col3\" class=\"data row14 col3\" >1.047</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow14_col4\" class=\"data row14 col4\" >-0.183</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow14_col5\" class=\"data row14 col5\" >0.4496</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow14_col6\" class=\"data row14 col6\" >2.643</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow14_col7\" class=\"data row14 col7\" >0.046</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8clevel0_row15\" class=\"row_heading level0 row15\" >knn</th>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow15_col0\" class=\"data row15 col0\" >K Neighbors Regressor</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow15_col1\" class=\"data row15 col1\" >0.848</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow15_col2\" class=\"data row15 col2\" >1.103</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow15_col3\" class=\"data row15 col3\" >1.05</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow15_col4\" class=\"data row15 col4\" >-0.1912</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow15_col5\" class=\"data row15 col5\" >0.4363</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow15_col6\" class=\"data row15 col6\" >2.678</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow15_col7\" class=\"data row15 col7\" >0.025</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8clevel0_row16\" class=\"row_heading level0 row16\" >xgboost</th>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow16_col0\" class=\"data row16 col0\" >Extreme Gradient Boosting</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow16_col1\" class=\"data row16 col1\" >0.8755</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow16_col2\" class=\"data row16 col2\" >1.168</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow16_col3\" class=\"data row16 col3\" >1.079</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow16_col4\" class=\"data row16 col4\" >-0.2539</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow16_col5\" class=\"data row16 col5\" >0.4345</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow16_col6\" class=\"data row16 col6\" >3.962</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow16_col7\" class=\"data row16 col7\" >0.193</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8clevel0_row17\" class=\"row_heading level0 row17\" >par</th>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow17_col0\" class=\"data row17 col0\" >Passive Aggressive Regressor</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow17_col1\" class=\"data row17 col1\" >0.9499</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow17_col2\" class=\"data row17 col2\" >1.409</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow17_col3\" class=\"data row17 col3\" >1.178</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow17_col4\" class=\"data row17 col4\" >-0.498</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow17_col5\" class=\"data row17 col5\" >0.3801</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow17_col6\" class=\"data row17 col6\" >4.29</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow17_col7\" class=\"data row17 col7\" >0.007</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8clevel0_row18\" class=\"row_heading level0 row18\" >dt</th>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow18_col0\" class=\"data row18 col0\" >Decision Tree Regressor</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow18_col1\" class=\"data row18 col1\" >1.122</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow18_col2\" class=\"data row18 col2\" >1.943</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow18_col3\" class=\"data row18 col3\" >1.391</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow18_col4\" class=\"data row18 col4\" >-1.096</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow18_col5\" class=\"data row18 col5\" >0.4391</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow18_col6\" class=\"data row18 col6\" >8.099</td>\n",
       "                        <td id=\"T_a66e2bf4_1f28_11eb_990c_9cb6d09a5d8crow18_col7\" class=\"data row18 col7\" >0.014</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c38122a308>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=4754,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return the best model\n",
    "compare_models(sort='R2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow10_col0 {\n",
       "            background:  yellow;\n",
       "        }    #T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow10_col1 {\n",
       "            background:  yellow;\n",
       "        }    #T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow10_col2 {\n",
       "            background:  yellow;\n",
       "        }    #T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow10_col3 {\n",
       "            background:  yellow;\n",
       "        }    #T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow10_col4 {\n",
       "            background:  yellow;\n",
       "        }    #T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow10_col5 {\n",
       "            background:  yellow;\n",
       "        }</style><table id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8c\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >MAE</th>        <th class=\"col_heading level0 col1\" >MSE</th>        <th class=\"col_heading level0 col2\" >RMSE</th>        <th class=\"col_heading level0 col3\" >R2</th>        <th class=\"col_heading level0 col4\" >RMSLE</th>        <th class=\"col_heading level0 col5\" >MAPE</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8clevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow0_col0\" class=\"data row0 col0\" >0.82705</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow0_col1\" class=\"data row0 col1\" >1.10395</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow0_col2\" class=\"data row0 col2\" >1.05069</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow0_col3\" class=\"data row0 col3\" >-0.144272</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow0_col4\" class=\"data row0 col4\" >0.448954</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow0_col5\" class=\"data row0 col5\" >16.4483</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8clevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow1_col0\" class=\"data row1 col0\" >0.792315</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow1_col1\" class=\"data row1 col1\" >0.975749</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow1_col2\" class=\"data row1 col2\" >0.9878</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow1_col3\" class=\"data row1 col3\" >-0.11047</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow1_col4\" class=\"data row1 col4\" >0.426496</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow1_col5\" class=\"data row1 col5\" >1.61091</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8clevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow2_col0\" class=\"data row2 col0\" >0.914441</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow2_col1\" class=\"data row2 col1\" >1.22117</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow2_col2\" class=\"data row2 col2\" >1.10506</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow2_col3\" class=\"data row2 col3\" >-0.262818</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow2_col4\" class=\"data row2 col4\" >0.424968</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow2_col5\" class=\"data row2 col5\" >6.10835</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8clevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow3_col0\" class=\"data row3 col0\" >0.893664</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow3_col1\" class=\"data row3 col1\" >1.17067</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow3_col2\" class=\"data row3 col2\" >1.08198</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow3_col3\" class=\"data row3 col3\" >-0.293927</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow3_col4\" class=\"data row3 col4\" >0.431852</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow3_col5\" class=\"data row3 col5\" >3.02101</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8clevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow4_col0\" class=\"data row4 col0\" >0.924988</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow4_col1\" class=\"data row4 col1\" >1.2632</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow4_col2\" class=\"data row4 col2\" >1.12392</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow4_col3\" class=\"data row4 col3\" >-0.327255</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow4_col4\" class=\"data row4 col4\" >0.412864</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow4_col5\" class=\"data row4 col5\" >1.79451</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8clevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow5_col0\" class=\"data row5 col0\" >0.872792</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow5_col1\" class=\"data row5 col1\" >1.13729</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow5_col2\" class=\"data row5 col2\" >1.06644</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow5_col3\" class=\"data row5 col3\" >-0.36733</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow5_col4\" class=\"data row5 col4\" >0.428397</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow5_col5\" class=\"data row5 col5\" >2.36737</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8clevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow6_col0\" class=\"data row6 col0\" >0.931947</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow6_col1\" class=\"data row6 col1\" >1.3772</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow6_col2\" class=\"data row6 col2\" >1.17354</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow6_col3\" class=\"data row6 col3\" >-0.322317</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow6_col4\" class=\"data row6 col4\" >0.42308</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow6_col5\" class=\"data row6 col5\" >2.4195</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8clevel0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow7_col0\" class=\"data row7 col0\" >0.903684</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow7_col1\" class=\"data row7 col1\" >1.29788</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow7_col2\" class=\"data row7 col2\" >1.13925</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow7_col3\" class=\"data row7 col3\" >-0.194493</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow7_col4\" class=\"data row7 col4\" >0.452334</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow7_col5\" class=\"data row7 col5\" >1.55859</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8clevel0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow8_col0\" class=\"data row8 col0\" >0.849634</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow8_col1\" class=\"data row8 col1\" >1.01758</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow8_col2\" class=\"data row8 col2\" >1.00875</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow8_col3\" class=\"data row8 col3\" >-0.331904</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow8_col4\" class=\"data row8 col4\" >0.433642</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow8_col5\" class=\"data row8 col5\" >2.55809</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8clevel0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow9_col0\" class=\"data row9 col0\" >0.844918</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow9_col1\" class=\"data row9 col1\" >1.11098</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow9_col2\" class=\"data row9 col2\" >1.05403</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow9_col3\" class=\"data row9 col3\" >-0.184232</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow9_col4\" class=\"data row9 col4\" >0.462144</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow9_col5\" class=\"data row9 col5\" >1.7366</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8clevel0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow10_col0\" class=\"data row10 col0\" >0.875543</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow10_col1\" class=\"data row10 col1\" >1.16757</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow10_col2\" class=\"data row10 col2\" >1.07915</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow10_col3\" class=\"data row10 col3\" >-0.253902</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow10_col4\" class=\"data row10 col4\" >0.434473</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow10_col5\" class=\"data row10 col5\" >3.96233</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8clevel0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow11_col0\" class=\"data row11 col0\" >0.043766</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow11_col1\" class=\"data row11 col1\" >0.118495</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow11_col2\" class=\"data row11 col2\" >0.054871</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow11_col3\" class=\"data row11 col3\" >0.084657</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow11_col4\" class=\"data row11 col4\" >0.014455</td>\n",
       "                        <td id=\"T_abcb1dc8_1f28_11eb_9721_9cb6d09a5d8crow11_col5\" class=\"data row11 col5\" >4.35027</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c3811f4648>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fold: k_fold validation\n",
    "round: round digits\n",
    "estimtor: 'xgboost'\n",
    "\"\"\"\n",
    "xgb=create_model('xgboost',fold=10,cross_validation=True,round=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow10_col0 {\n",
       "            background:  yellow;\n",
       "        }    #T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow10_col1 {\n",
       "            background:  yellow;\n",
       "        }    #T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow10_col2 {\n",
       "            background:  yellow;\n",
       "        }    #T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow10_col3 {\n",
       "            background:  yellow;\n",
       "        }    #T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow10_col4 {\n",
       "            background:  yellow;\n",
       "        }    #T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow10_col5 {\n",
       "            background:  yellow;\n",
       "        }</style><table id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8c\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >MAE</th>        <th class=\"col_heading level0 col1\" >MSE</th>        <th class=\"col_heading level0 col2\" >RMSE</th>        <th class=\"col_heading level0 col3\" >R2</th>        <th class=\"col_heading level0 col4\" >RMSLE</th>        <th class=\"col_heading level0 col5\" >MAPE</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8clevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow0_col0\" class=\"data row0 col0\" >0.789519</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow0_col1\" class=\"data row0 col1\" >0.948559</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow0_col2\" class=\"data row0 col2\" >0.97394</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow0_col3\" class=\"data row0 col3\" >0.016797</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow0_col4\" class=\"data row0 col4\" >0.562861</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow0_col5\" class=\"data row0 col5\" >3.26843</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8clevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow1_col0\" class=\"data row1 col0\" >0.7642</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow1_col1\" class=\"data row1 col1\" >0.880946</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow1_col2\" class=\"data row1 col2\" >0.938587</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow1_col3\" class=\"data row1 col3\" >-0.002577</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow1_col4\" class=\"data row1 col4\" >0.536489</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow1_col5\" class=\"data row1 col5\" >1.02483</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8clevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow2_col0\" class=\"data row2 col0\" >0.788939</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow2_col1\" class=\"data row2 col1\" >0.991195</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow2_col2\" class=\"data row2 col2\" >0.995588</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow2_col3\" class=\"data row2 col3\" >-0.025003</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow2_col4\" class=\"data row2 col4\" >0.524114</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow2_col5\" class=\"data row2 col5\" >2.04016</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8clevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow3_col0\" class=\"data row3 col0\" >0.774376</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow3_col1\" class=\"data row3 col1\" >0.895563</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow3_col2\" class=\"data row3 col2\" >0.946342</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow3_col3\" class=\"data row3 col3\" >0.010146</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow3_col4\" class=\"data row3 col4\" >0.531062</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow3_col5\" class=\"data row3 col5\" >1.35682</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8clevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow4_col0\" class=\"data row4 col0\" >0.816377</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow4_col1\" class=\"data row4 col1\" >0.951831</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow4_col2\" class=\"data row4 col2\" >0.975618</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow4_col3\" class=\"data row4 col3\" >-0.0001</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow4_col4\" class=\"data row4 col4\" >0.533972</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow4_col5\" class=\"data row4 col5\" >1.08008</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8clevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow5_col0\" class=\"data row5 col0\" >0.76278</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow5_col1\" class=\"data row5 col1\" >0.875844</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow5_col2\" class=\"data row5 col2\" >0.935865</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow5_col3\" class=\"data row5 col3\" >-0.052997</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow5_col4\" class=\"data row5 col4\" >0.505015</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow5_col5\" class=\"data row5 col5\" >1.73213</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8clevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow6_col0\" class=\"data row6 col0\" >0.822949</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow6_col1\" class=\"data row6 col1\" >1.06041</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow6_col2\" class=\"data row6 col2\" >1.02976</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow6_col3\" class=\"data row6 col3\" >-0.018145</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow6_col4\" class=\"data row6 col4\" >0.568202</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow6_col5\" class=\"data row6 col5\" >1.12923</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8clevel0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow7_col0\" class=\"data row7 col0\" >0.841527</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow7_col1\" class=\"data row7 col1\" >1.06797</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow7_col2\" class=\"data row7 col2\" >1.03343</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow7_col3\" class=\"data row7 col3\" >0.017102</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow7_col4\" class=\"data row7 col4\" >0.561674</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow7_col5\" class=\"data row7 col5\" >1.10662</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8clevel0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow8_col0\" class=\"data row8 col0\" >0.719216</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow8_col1\" class=\"data row8 col1\" >0.783862</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow8_col2\" class=\"data row8 col2\" >0.88536</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow8_col3\" class=\"data row8 col3\" >-0.025988</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow8_col4\" class=\"data row8 col4\" >0.49384</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow8_col5\" class=\"data row8 col5\" >1.52328</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8clevel0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow9_col0\" class=\"data row9 col0\" >0.754257</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow9_col1\" class=\"data row9 col1\" >0.920123</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow9_col2\" class=\"data row9 col2\" >0.959231</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow9_col3\" class=\"data row9 col3\" >0.019213</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow9_col4\" class=\"data row9 col4\" >0.532063</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow9_col5\" class=\"data row9 col5\" >1.40583</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8clevel0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow10_col0\" class=\"data row10 col0\" >0.783414</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow10_col1\" class=\"data row10 col1\" >0.93763</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow10_col2\" class=\"data row10 col2\" >0.967372</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow10_col3\" class=\"data row10 col3\" >-0.006155</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow10_col4\" class=\"data row10 col4\" >0.534929</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow10_col5\" class=\"data row10 col5\" >1.56674</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8clevel0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow11_col0\" class=\"data row11 col0\" >0.034558</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow11_col1\" class=\"data row11 col1\" >0.082465</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow11_col2\" class=\"data row11 col2\" >0.042683</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow11_col3\" class=\"data row11 col3\" >0.022612</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow11_col4\" class=\"data row11 col4\" >0.023085</td>\n",
       "                        <td id=\"T_531e266c_1f29_11eb_9762_9cb6d09a5d8crow11_col5\" class=\"data row11 col5\" >0.644415</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c38384d488>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "estimator: a algorithm or a defined model by create_model()\n",
    "optimize: cretirion\n",
    "n_iter: default 500\n",
    "choose_better: at least return the basic model\n",
    "\"\"\"\n",
    "tuned_xgb=tune_model(xgb,optimize='R2',n_iter=100,choose_better=True,round=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can custom our parameters for tuning\n",
    "\"\"\"\n",
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'reg:linear',\n",
    "}\n",
    "\"\"\"\n",
    "params = {\n",
    "    'colsample_bytree':[0.4,0.6,0.8],\n",
    "    'gamma':[0,0.03,0.1,0.3],\n",
    "    'min_child_weight':[1.5,6,10],\n",
    "    'learning_rate':[0.1,0.07,0.01],\n",
    "    'max_depth':[3,5],\n",
    "    'n_estimators':[10],\n",
    "    'reg_alpha':[1e-5, 1e-2,  0.75],\n",
    "    'reg_lambda':[1e-5, 1e-2, 0.45],\n",
    "    'subsample':[0.6,0.95]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow10_col0 {\n",
       "            background:  yellow;\n",
       "        }    #T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow10_col1 {\n",
       "            background:  yellow;\n",
       "        }    #T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow10_col2 {\n",
       "            background:  yellow;\n",
       "        }    #T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow10_col3 {\n",
       "            background:  yellow;\n",
       "        }    #T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow10_col4 {\n",
       "            background:  yellow;\n",
       "        }    #T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow10_col5 {\n",
       "            background:  yellow;\n",
       "        }</style><table id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8c\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >MAE</th>        <th class=\"col_heading level0 col1\" >MSE</th>        <th class=\"col_heading level0 col2\" >RMSE</th>        <th class=\"col_heading level0 col3\" >R2</th>        <th class=\"col_heading level0 col4\" >RMSLE</th>        <th class=\"col_heading level0 col5\" >MAPE</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8clevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow0_col0\" class=\"data row0 col0\" >0.786034</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow0_col1\" class=\"data row0 col1\" >0.992191</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow0_col2\" class=\"data row0 col2\" >0.996088</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow0_col3\" class=\"data row0 col3\" >-0.028429</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow0_col4\" class=\"data row0 col4\" >0.500336</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow0_col5\" class=\"data row0 col5\" >1.72736</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8clevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow1_col0\" class=\"data row1 col0\" >0.81609</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow1_col1\" class=\"data row1 col1\" >0.99509</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow1_col2\" class=\"data row1 col2\" >0.997542</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow1_col3\" class=\"data row1 col3\" >-0.132482</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow1_col4\" class=\"data row1 col4\" >0.484065</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow1_col5\" class=\"data row1 col5\" >1.24804</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8clevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow2_col0\" class=\"data row2 col0\" >0.791174</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow2_col1\" class=\"data row2 col1\" >0.986167</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow2_col2\" class=\"data row2 col2\" >0.99306</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow2_col3\" class=\"data row2 col3\" >-0.019803</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow2_col4\" class=\"data row2 col4\" >0.521374</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow2_col5\" class=\"data row2 col5\" >3.14754</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8clevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow3_col0\" class=\"data row3 col0\" >0.807007</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow3_col1\" class=\"data row3 col1\" >0.960835</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow3_col2\" class=\"data row3 col2\" >0.980222</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow3_col3\" class=\"data row3 col3\" >-0.061997</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow3_col4\" class=\"data row3 col4\" >0.498004</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow3_col5\" class=\"data row3 col5\" >2.17847</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8clevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow4_col0\" class=\"data row4 col0\" >0.806409</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow4_col1\" class=\"data row4 col1\" >0.95253</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow4_col2\" class=\"data row4 col2\" >0.975976</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow4_col3\" class=\"data row4 col3\" >-0.000834</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow4_col4\" class=\"data row4 col4\" >0.497357</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow4_col5\" class=\"data row4 col5\" >1.07564</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8clevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow5_col0\" class=\"data row5 col0\" >0.749972</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow5_col1\" class=\"data row5 col1\" >0.872635</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow5_col2\" class=\"data row5 col2\" >0.93415</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow5_col3\" class=\"data row5 col3\" >-0.04914</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow5_col4\" class=\"data row5 col4\" >0.475243</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow5_col5\" class=\"data row5 col5\" >2.38227</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8clevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow6_col0\" class=\"data row6 col0\" >0.85546</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow6_col1\" class=\"data row6 col1\" >1.11518</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow6_col2\" class=\"data row6 col2\" >1.05602</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow6_col3\" class=\"data row6 col3\" >-0.070735</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow6_col4\" class=\"data row6 col4\" >0.523907</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow6_col5\" class=\"data row6 col5\" >1.45188</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8clevel0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow7_col0\" class=\"data row7 col0\" >0.857415</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow7_col1\" class=\"data row7 col1\" >1.09145</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow7_col2\" class=\"data row7 col2\" >1.04473</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow7_col3\" class=\"data row7 col3\" >-0.004507</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow7_col4\" class=\"data row7 col4\" >0.540506</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow7_col5\" class=\"data row7 col5\" >1.47522</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8clevel0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow8_col0\" class=\"data row8 col0\" >0.730689</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow8_col1\" class=\"data row8 col1\" >0.837337</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow8_col2\" class=\"data row8 col2\" >0.915061</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow8_col3\" class=\"data row8 col3\" >-0.09598</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow8_col4\" class=\"data row8 col4\" >0.456599</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow8_col5\" class=\"data row8 col5\" >1.19495</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8clevel0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow9_col0\" class=\"data row9 col0\" >0.81217</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow9_col1\" class=\"data row9 col1\" >0.971476</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow9_col2\" class=\"data row9 col2\" >0.985635</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow9_col3\" class=\"data row9 col3\" >-0.035526</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow9_col4\" class=\"data row9 col4\" >0.491884</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow9_col5\" class=\"data row9 col5\" >1.75773</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8clevel0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow10_col0\" class=\"data row10 col0\" >0.801242</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow10_col1\" class=\"data row10 col1\" >0.977489</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow10_col2\" class=\"data row10 col2\" >0.987848</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow10_col3\" class=\"data row10 col3\" >-0.049943</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow10_col4\" class=\"data row10 col4\" >0.498927</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow10_col5\" class=\"data row10 col5\" >1.76391</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8clevel0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow11_col0\" class=\"data row11 col0\" >0.037992</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow11_col1\" class=\"data row11 col1\" >0.080075</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow11_col2\" class=\"data row11 col2\" >0.040567</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow11_col3\" class=\"data row11 col3\" >0.039453</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow11_col4\" class=\"data row11 col4\" >0.02342</td>\n",
       "                        <td id=\"T_a3ad5f1c_1f29_11eb_b3e8_9cb6d09a5d8crow11_col5\" class=\"data row11 col5\" >0.609451</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c38100c5c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuned_xgb_2=tune_model(xgb,optimize='R2',custom_grid=params,choose_better=True,round=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Well, seems the default n_iter tuning works better than our custom discrete training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the model \n",
    "plot_model(tuned_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=finalize_model(tuned_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 17., 123., 393., 338.,  78.,  33.,  10.,   6.,   1.,   1.]),\n",
       " array([-0.35881704, -0.24916968, -0.13952231, -0.02987495,  0.07977241,\n",
       "         0.18941978,  0.29906714,  0.4087145 ,  0.51836187,  0.62800923,\n",
       "         0.73765659]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict out of sample and plot the distribution\n",
    "import matplotlib.pyplot as plt\n",
    "df2=pd.DataFrame(np.random.normal(size=(500,20)))\n",
    "y_hat=predict_model(model,data=df)['Label'].values\n",
    "plt.hist(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Now we are going to use the same process for our XGBoost \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_basic(basis,cv,seed,step):\n",
    "    step=np.int(step)\n",
    "    df=pd.DataFrame(basis)\n",
    "    df['cv']=cv.ravel().astype('float64')    \n",
    "    exp_reg=setup(df,target='cv',html=False,\n",
    "                  normalize=True,\n",
    "                  normalize_method='minmax',\n",
    "                  data_split_shuffle=True,\n",
    "                  train_size=0.9, # should it be 1 or less than 1\n",
    "                  session_id=seed)    \n",
    "    xgb=create_model('xgboost',fold=10,cross_validation=True,round=6)\n",
    "    tuned_xgb=tune_model(xgb,optimize='R2',n_iter=200,choose_better=True,round=6)\n",
    "    # to see the parameters\n",
    "    print(tuned_xgb)\n",
    "    # finalize the model to predict\n",
    "    model=finalize_model(tuned_xgb)\n",
    "    y_hat=predict_model(model,data=df.iloc[:,:-1])['Label'].values.reshape((-1,1))\n",
    "    \n",
    "    # save the model for each time step\n",
    "    save_model(tuned_xgb,'step'+str(step)+'tuned_xgb')\n",
    "    \n",
    "    return y_hat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_fixed(basis,cv,seed):\n",
    "    train_x=basis\n",
    "    train_y=cv\n",
    "# base model  from the step 18 parameters\n",
    "    xgb_model = xgboost.XGBRegressor(seed=seed,base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.9, gamma=0, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints='',\n",
    "             learning_rate=0.212, max_delta_step=0, max_depth=3,\n",
    "             min_child_weight=3, monotone_constraints='()',\n",
    "             n_estimators=70, n_jobs=-1, num_parallel_tree=1,\n",
    "             objective='reg:squarederror', random_state=123, reg_alpha=0.01,\n",
    "             reg_lambda=5, scale_pos_weight=4.800000000000001, subsample=0.5,\n",
    "             tree_method='auto', validate_parameters=1, verbosity=0)\n",
    "\n",
    "# fit the model\n",
    "    xgb_model.fit(train_x,train_y)\n",
    "    y_xgb=xgb_model.predict(train_x).reshape((-1,1))\n",
    "    return y_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bermudan_swaption_xgboost(lockout,maturity,sim_rates,strike,seed):\n",
    "   \n",
    "    expiry=int(2*lockout)\n",
    "    tenor=int(2*maturity)\n",
    "    \n",
    "    step=tenor-expiry  # 18\n",
    "    paths=sim_rates.shape[2] # 5000\n",
    "    di = np.diag_indices(expiry) # 1y 2 dis\n",
    "    \n",
    "# discount factor for calculate the final prc\n",
    "    cmmf = np.prod(sim_rates[di], axis = 0) # (5000,1)\n",
    "    \n",
    "    rates=sim_rates[expiry:tenor,expiry:tenor,:] #18*18*5000\n",
    "    \n",
    "    di=np.diag_indices(int(tenor-expiry-1))\n",
    "    di=(di[0]+expiry,di[1]+expiry)\n",
    "    disc_mat=sim_rates[di]\n",
    "    \n",
    "# discount map for each related time step \n",
    "    discount_mat=np.hstack((np.ones((paths,1)),np.cumprod(sim_rates[di],axis=0).T)) #5000 * 18\n",
    "\n",
    "# initial matrix\n",
    "\n",
    "    value_xgb,index_xgb=np.zeros((paths,step)),np.zeros((paths,step))\n",
    "    \n",
    "# calculate the par rate at 18 possible excercise date\n",
    "    denominator=np.sum(sim_rates[expiry-1:tenor,expiry:tenor,:],axis=0)-1 # 18*5000 3D to 2D\n",
    "    \n",
    "    numerator=2*(1-sim_rates[int(tenor-1),expiry:tenor,:]) # 18*5000\n",
    "    par=numerator/denominator # 19*5000\n",
    "    payoff_mat = 0.5 * np.maximum(strike-par.T, 0) * denominator.T #5000 *100\n",
    "\n",
    "    \n",
    "    index_xgb[:,-1]=np.where(payoff_mat[:,-1]>0,1,0)\n",
    "    value_xgb[:,-1]=payoff_mat[:,-1]\n",
    "    \n",
    "# European swaption price and ex prob\n",
    "    Euro_prc=np.mean(payoff_mat[:,0]*cmmf)\n",
    "    ex_prob=np.sum(np.where(payoff_mat[:,0]>0,1,0))/paths    \n",
    "            \n",
    "    for i in range(step-2,-1,-1):\n",
    "        y=value_xgb[:,i+1].reshape((paths,1)) # 5000*1\n",
    "        bond_prc=rates[i:int(tenor-expiry),i,:].T # 5000*n\n",
    "        cv=disc_mat[i].T.reshape((paths,1))*y # 5000*1\n",
    "        ev=payoff_mat[:,i].reshape((paths,1)) # 5000*1 \n",
    "        \n",
    "# construct the basis functions        \n",
    "#        swap_value = np.repeat(ev, 3, axis = 1) ** np.arange(1, 4) # 5000*3\n",
    "        swap_value = Laguerre_feature(ev.ravel(),3)\n",
    "        constant=np.ones((paths,1))\n",
    "#        basis=np.hstack((np.hstack((constant,bond_prc)),swap_value))\n",
    "        bond_prc_laguerre=np.apply_along_axis(Laguerre_feature,0,bond_prc,k=3).reshape((paths,-1))\n",
    "        basis=np.hstack((np.hstack((constant,bond_prc_laguerre)),swap_value))\n",
    "        \n",
    "\n",
    "        # Regress now NN\n",
    "        mask=ev.ravel()>0\n",
    "        ev=ev[mask]\n",
    "        cv=cv[mask]\n",
    "        basis=basis[mask]\n",
    "        \n",
    "        cv_xgb=train_xgb_basic(basis,cv,seed,i+1)\n",
    "        value_xgb[mask,i]=np.where(ev>cv_xgb,ev,cv).ravel()\n",
    "        index_xgb[mask,i]=np.where(ev>cv_xgb,1,0).ravel()\n",
    "        \n",
    "        for j in range(i+1,index_xgb.shape[1]):            \n",
    "             index_xgb[:,j][index_xgb[:,int(i)]==1]=0\n",
    "             \n",
    "    prob=pd.DataFrame({'Time_step': np.arange(expiry,tenor),\n",
    "                       'ex_prob_Euro':np.append(ex_prob,np.repeat(0,step-1)),\n",
    "                       'ex_prob_xgb':np.sum(index_xgb,axis=0)/paths})\n",
    "\n",
    "    price_xgb=np.mean(np.sum(np.multiply(discount_mat,np.multiply(index_xgb,payoff_mat)),axis=1)*cmmf)\n",
    "    \n",
    "    return Euro_prc,price_xgb,prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bermudan_swaption_xgboost_fixed(lockout,maturity,sim_rates,strike,seed):\n",
    "   \n",
    "    expiry=int(2*lockout)\n",
    "    tenor=int(2*maturity)\n",
    "    \n",
    "    step=tenor-expiry  # 18\n",
    "    paths=sim_rates.shape[2] # 5000\n",
    "    di = np.diag_indices(expiry) # 1y 2 dis\n",
    "    \n",
    "# discount factor for calculate the final prc\n",
    "    cmmf = np.prod(sim_rates[di], axis = 0) # (5000,1)\n",
    "    \n",
    "    rates=sim_rates[expiry:tenor,expiry:tenor,:] #18*18*5000\n",
    "    \n",
    "    di=np.diag_indices(int(tenor-expiry-1))\n",
    "    di=(di[0]+expiry,di[1]+expiry)\n",
    "    disc_mat=sim_rates[di]\n",
    "    \n",
    "# discount map for each related time step \n",
    "    discount_mat=np.hstack((np.ones((paths,1)),np.cumprod(sim_rates[di],axis=0).T)) #5000 * 18\n",
    "\n",
    "# initial matrix\n",
    "\n",
    "    value_xgb,index_xgb=np.zeros((paths,step)),np.zeros((paths,step))\n",
    "    \n",
    "# calculate the par rate at 18 possible excercise date\n",
    "    denominator=np.sum(sim_rates[expiry-1:tenor,expiry:tenor,:],axis=0)-1 # 18*5000 3D to 2D\n",
    "    \n",
    "    numerator=2*(1-sim_rates[int(tenor-1),expiry:tenor,:]) # 18*5000\n",
    "    par=numerator/denominator # 19*5000\n",
    "    payoff_mat = 0.5 * np.maximum(strike-par.T, 0) * denominator.T #5000 *100\n",
    "\n",
    "    \n",
    "    index_xgb[:,-1]=np.where(payoff_mat[:,-1]>0,1,0)\n",
    "    value_xgb[:,-1]=payoff_mat[:,-1]\n",
    "    \n",
    "# European swaption price and ex prob\n",
    "    Euro_prc=np.mean(payoff_mat[:,0]*cmmf)\n",
    "    ex_prob=np.sum(np.where(payoff_mat[:,0]>0,1,0))/paths    \n",
    "            \n",
    "    for i in range(step-2,-1,-1):\n",
    "        y=value_xgb[:,i+1].reshape((paths,1)) # 5000*1\n",
    "        bond_prc=rates[i:int(tenor-expiry),i,:].T # 5000*n\n",
    "        cv=disc_mat[i].T.reshape((paths,1))*y # 5000*1\n",
    "        ev=payoff_mat[:,i].reshape((paths,1)) # 5000*1 \n",
    "        \n",
    "# construct the basis functions        \n",
    "#        swap_value = np.repeat(ev, 3, axis = 1) ** np.arange(1, 4) # 5000*3\n",
    "        swap_value = Laguerre_feature(ev.ravel(),3)\n",
    "        constant=np.ones((paths,1))\n",
    "#        basis=np.hstack((np.hstack((constant,bond_prc)),swap_value))\n",
    "        bond_prc_laguerre=np.apply_along_axis(Laguerre_feature,0,bond_prc,k=4).reshape((paths,-1))\n",
    "        basis=np.hstack((np.hstack((constant,bond_prc_laguerre)),swap_value))\n",
    "        \n",
    "\n",
    "        # Regress now NN\n",
    "        mask=ev.ravel()>0\n",
    "        ev=ev[mask]\n",
    "        cv=cv[mask]\n",
    "        basis=basis[mask]\n",
    "        \n",
    "        cv_xgb=train_xgb_fixed(basis,cv,seed)\n",
    "        value_xgb[mask,i]=np.where(ev>cv_xgb,ev,cv).ravel()\n",
    "        index_xgb[mask,i]=np.where(ev>cv_xgb,1,0).ravel()\n",
    "        \n",
    "        for j in range(i+1,index_xgb.shape[1]):            \n",
    "             index_xgb[:,j][index_xgb[:,int(i)]==1]=0\n",
    "             \n",
    "    prob=pd.DataFrame({'Time_step': np.arange(expiry,tenor),\n",
    "                       'ex_prob_Euro':np.append(ex_prob,np.repeat(0,step-1)),\n",
    "                       'ex_prob_xgb':np.sum(index_xgb,axis=0)/paths})\n",
    "\n",
    "    price_xgb=np.mean(np.sum(np.multiply(discount_mat,np.multiply(index_xgb,payoff_mat)),axis=1)*cmmf)\n",
    "    \n",
    "    return Euro_prc,price_xgb,prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for test 10 nc 1\n",
    "lockout=1\n",
    "maturity=10\n",
    "strike=0.008\n",
    "seed=123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83d0f5da35a45ac810ed6face5b8142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=\"Following data types have been inferred automatically, if they are correct press enter to continue"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cv</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Type\n",
       "0    Numeric\n",
       "1    Numeric\n",
       "2    Numeric\n",
       "3    Numeric\n",
       "4    Numeric\n",
       "5    Numeric\n",
       "6    Numeric\n",
       "7    Numeric\n",
       "8    Numeric\n",
       "9    Numeric\n",
       "cv     Label"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup Succesfully Completed!\n",
      "                               Description             Value\n",
      "0                               session_id               123\n",
      "1                                   Target                cv\n",
      "2                            Original Data        (1197, 11)\n",
      "3                           Missing Values             False\n",
      "4                         Numeric Features                10\n",
      "5                     Categorical Features                 0\n",
      "6                         Ordinal Features             False\n",
      "7                High Cardinality Features             False\n",
      "8                  High Cardinality Method              None\n",
      "9                    Transformed Train Set         (1077, 2)\n",
      "10                    Transformed Test Set          (120, 2)\n",
      "11                      Shuffle Train-Test              True\n",
      "12                     Stratify Train-Test             False\n",
      "13                          Fold Generator             KFold\n",
      "14                             Fold Number                10\n",
      "15                                CPU Jobs                -1\n",
      "16                                 Use GPU             False\n",
      "17                          Log Experiment             False\n",
      "18                         Experiment Name  reg-default-name\n",
      "19                                     USI              9f8c\n",
      "20                         Imputation Type            simple\n",
      "21          Iterative Imputation Iteration              None\n",
      "22                         Numeric Imputer              mean\n",
      "23      Iterative Imputation Numeric Model              None\n",
      "24                     Categorical Imputer          constant\n",
      "25  Iterative Imputation Categorical Model              None\n",
      "26           Unknown Categoricals Handling    least_frequent\n",
      "27                               Normalize              True\n",
      "28                        Normalize Method            minmax\n",
      "29                          Transformation             False\n",
      "30                   Transformation Method              None\n",
      "31                                     PCA             False\n",
      "32                              PCA Method              None\n",
      "33                          PCA Components              None\n",
      "34                     Ignore Low Variance             False\n",
      "35                     Combine Rare Levels             False\n",
      "36                    Rare Level Threshold              None\n",
      "37                         Numeric Binning             False\n",
      "38                         Remove Outliers             False\n",
      "39                      Outliers Threshold              None\n",
      "40                Remove Multicollinearity             False\n",
      "41             Multicollinearity Threshold              None\n",
      "42                              Clustering             False\n",
      "43                    Clustering Iteration              None\n",
      "44                     Polynomial Features             False\n",
      "45                       Polynomial Degree              None\n",
      "46                    Trignometry Features             False\n",
      "47                    Polynomial Threshold              None\n",
      "48                          Group Features             False\n",
      "49                       Feature Selection             False\n",
      "50            Features Selection Threshold              None\n",
      "51                     Feature Interaction             False\n",
      "52                           Feature Ratio             False\n",
      "53                   Interaction Threshold              None\n",
      "54                        Transform Target             False\n",
      "55                 Transform Target Method           box-cox\n",
      "           MAE  MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.000404  0.0  0.000499  0.607223  0.000499  1.270020\n",
      "1     0.000383  0.0  0.000480  0.537297  0.000479  0.675396\n",
      "2     0.000382  0.0  0.000465  0.551212  0.000464  0.589345\n",
      "3     0.000439  0.0  0.000527  0.531268  0.000527  1.621018\n",
      "4     0.000413  0.0  0.000501  0.556650  0.000500  0.833613\n",
      "5     0.000404  0.0  0.000501  0.577166  0.000501  0.716555\n",
      "6     0.000387  0.0  0.000478  0.609091  0.000478  0.579782\n",
      "7     0.000444  0.0  0.000553  0.326171  0.000552  0.845443\n",
      "8     0.000403  0.0  0.000469  0.653605  0.000469  0.669906\n",
      "9     0.000367  0.0  0.000460  0.610653  0.000459  0.842714\n",
      "Mean  0.000403  0.0  0.000493  0.556034  0.000493  0.864379\n",
      "SD    0.000023  0.0  0.000028  0.084977  0.000028  0.314777\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 656 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1656 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:   33.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE  MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.000396  0.0  0.000494  0.615762  0.000493  1.263288\n",
      "1     0.000379  0.0  0.000470  0.555483  0.000470  0.667941\n",
      "2     0.000377  0.0  0.000462  0.556673  0.000462  0.583528\n",
      "3     0.000446  0.0  0.000529  0.528817  0.000528  1.608209\n",
      "4     0.000409  0.0  0.000499  0.560220  0.000498  0.842193\n",
      "5     0.000395  0.0  0.000493  0.590900  0.000493  0.706455\n",
      "6     0.000384  0.0  0.000478  0.610268  0.000477  0.570300\n",
      "7     0.000441  0.0  0.000549  0.335140  0.000548  0.835100\n",
      "8     0.000400  0.0  0.000468  0.655033  0.000468  0.664132\n",
      "9     0.000359  0.0  0.000456  0.616401  0.000456  0.827740\n",
      "Mean  0.000399  0.0  0.000490  0.562470  0.000489  0.856889\n",
      "SD    0.000026  0.0  0.000028  0.083850  0.000028  0.313613\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.151, max_delta_step=0, max_depth=1,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=210, n_jobs=-1, num_parallel_tree=1,\n",
      "             objective='reg:squarederror', random_state=123, reg_alpha=0.005,\n",
      "             reg_lambda=0.1, scale_pos_weight=12.3, subsample=0.9,\n",
      "             tree_method='auto', validate_parameters=1, verbosity=0)\n",
      "Transformation Pipeline and Model Succesfully Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6710605e46fc4f388845a651b3ebcb59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=\"Following data types have been inferred automatically, if they are correct press enter to continue"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cv</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Type\n",
       "0    Numeric\n",
       "1    Numeric\n",
       "2    Numeric\n",
       "3    Numeric\n",
       "4    Numeric\n",
       "5    Numeric\n",
       "6    Numeric\n",
       "7    Numeric\n",
       "8    Numeric\n",
       "9    Numeric\n",
       "10   Numeric\n",
       "11   Numeric\n",
       "12   Numeric\n",
       "cv     Label"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup Succesfully Completed!\n",
      "                               Description             Value\n",
      "0                               session_id               123\n",
      "1                                   Target                cv\n",
      "2                            Original Data        (1156, 14)\n",
      "3                           Missing Values             False\n",
      "4                         Numeric Features                13\n",
      "5                     Categorical Features                 0\n",
      "6                         Ordinal Features             False\n",
      "7                High Cardinality Features             False\n",
      "8                  High Cardinality Method              None\n",
      "9                    Transformed Train Set         (1040, 4)\n",
      "10                    Transformed Test Set          (116, 4)\n",
      "11                      Shuffle Train-Test              True\n",
      "12                     Stratify Train-Test             False\n",
      "13                          Fold Generator             KFold\n",
      "14                             Fold Number                10\n",
      "15                                CPU Jobs                -1\n",
      "16                                 Use GPU             False\n",
      "17                          Log Experiment             False\n",
      "18                         Experiment Name  reg-default-name\n",
      "19                                     USI              92f5\n",
      "20                         Imputation Type            simple\n",
      "21          Iterative Imputation Iteration              None\n",
      "22                         Numeric Imputer              mean\n",
      "23      Iterative Imputation Numeric Model              None\n",
      "24                     Categorical Imputer          constant\n",
      "25  Iterative Imputation Categorical Model              None\n",
      "26           Unknown Categoricals Handling    least_frequent\n",
      "27                               Normalize              True\n",
      "28                        Normalize Method            minmax\n",
      "29                          Transformation             False\n",
      "30                   Transformation Method              None\n",
      "31                                     PCA             False\n",
      "32                              PCA Method              None\n",
      "33                          PCA Components              None\n",
      "34                     Ignore Low Variance             False\n",
      "35                     Combine Rare Levels             False\n",
      "36                    Rare Level Threshold              None\n",
      "37                         Numeric Binning             False\n",
      "38                         Remove Outliers             False\n",
      "39                      Outliers Threshold              None\n",
      "40                Remove Multicollinearity             False\n",
      "41             Multicollinearity Threshold              None\n",
      "42                              Clustering             False\n",
      "43                    Clustering Iteration              None\n",
      "44                     Polynomial Features             False\n",
      "45                       Polynomial Degree              None\n",
      "46                    Trignometry Features             False\n",
      "47                    Polynomial Threshold              None\n",
      "48                          Group Features             False\n",
      "49                       Feature Selection             False\n",
      "50            Features Selection Threshold              None\n",
      "51                     Feature Interaction             False\n",
      "52                           Feature Ratio             False\n",
      "53                   Interaction Threshold              None\n",
      "54                        Transform Target             False\n",
      "55                 Transform Target Method           box-cox\n",
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.000535  0.000000  0.000666  0.769555  0.000665  0.939258\n",
      "1     0.000520  0.000000  0.000652  0.794152  0.000651  0.375344\n",
      "2     0.000532  0.000000  0.000645  0.804918  0.000644  0.423480\n",
      "3     0.000556  0.000000  0.000694  0.772702  0.000693  0.638417\n",
      "4     0.000533  0.000000  0.000638  0.776143  0.000637  0.461157\n",
      "5     0.000540  0.000000  0.000672  0.803377  0.000671  0.380573\n",
      "6     0.000522  0.000000  0.000640  0.787770  0.000639  0.933226\n",
      "7     0.000492  0.000000  0.000625  0.837708  0.000624  0.312712\n",
      "8     0.000525  0.000000  0.000678  0.741908  0.000677  0.712379\n",
      "9     0.000590  0.000001  0.000722  0.769921  0.000721  0.335696\n",
      "Mean  0.000535  0.000000  0.000663  0.785815  0.000662  0.551224\n",
      "SD    0.000024  0.000000  0.000028  0.024799  0.000028  0.227573\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 656 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1194 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1544 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:   43.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE  MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.000523  0.0  0.000653  0.778667  0.000651  0.911061\n",
      "1     0.000519  0.0  0.000643  0.799531  0.000642  0.414782\n",
      "2     0.000505  0.0  0.000618  0.820842  0.000617  0.369662\n",
      "3     0.000531  0.0  0.000665  0.791083  0.000664  0.562855\n",
      "4     0.000503  0.0  0.000619  0.789320  0.000618  0.417280\n",
      "5     0.000527  0.0  0.000670  0.804261  0.000669  0.357208\n",
      "6     0.000491  0.0  0.000613  0.805052  0.000612  0.972270\n",
      "7     0.000493  0.0  0.000628  0.835967  0.000627  0.335912\n",
      "8     0.000498  0.0  0.000667  0.749924  0.000666  0.717349\n",
      "9     0.000557  0.0  0.000692  0.788795  0.000690  0.297619\n",
      "Mean  0.000515  0.0  0.000647  0.796344  0.000646  0.535600\n",
      "SD    0.000020  0.0  0.000025  0.022181  0.000025  0.234498\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=0.9, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.191, max_delta_step=0, max_depth=2,\n",
      "             min_child_weight=3, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=180, n_jobs=-1, num_parallel_tree=1,\n",
      "             objective='reg:squarederror', random_state=123, reg_alpha=0.001,\n",
      "             reg_lambda=0.4, scale_pos_weight=13.8, subsample=0.7,\n",
      "             tree_method='auto', validate_parameters=1, verbosity=0)\n",
      "Transformation Pipeline and Model Succesfully Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38038b90b96c4f309f9169595aa6e879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=\"Following data types have been inferred automatically, if they are correct press enter to continue"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cv</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Type\n",
       "0    Numeric\n",
       "1    Numeric\n",
       "2    Numeric\n",
       "3    Numeric\n",
       "4    Numeric\n",
       "5    Numeric\n",
       "6    Numeric\n",
       "7    Numeric\n",
       "8    Numeric\n",
       "9    Numeric\n",
       "10   Numeric\n",
       "11   Numeric\n",
       "12   Numeric\n",
       "13   Numeric\n",
       "14   Numeric\n",
       "15   Numeric\n",
       "cv     Label"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup Succesfully Completed!\n",
      "                               Description             Value\n",
      "0                               session_id               123\n",
      "1                                   Target                cv\n",
      "2                            Original Data        (1141, 17)\n",
      "3                           Missing Values             False\n",
      "4                         Numeric Features                16\n",
      "5                     Categorical Features                 0\n",
      "6                         Ordinal Features             False\n",
      "7                High Cardinality Features             False\n",
      "8                  High Cardinality Method              None\n",
      "9                    Transformed Train Set         (1026, 4)\n",
      "10                    Transformed Test Set          (115, 4)\n",
      "11                      Shuffle Train-Test              True\n",
      "12                     Stratify Train-Test             False\n",
      "13                          Fold Generator             KFold\n",
      "14                             Fold Number                10\n",
      "15                                CPU Jobs                -1\n",
      "16                                 Use GPU             False\n",
      "17                          Log Experiment             False\n",
      "18                         Experiment Name  reg-default-name\n",
      "19                                     USI              6bcb\n",
      "20                         Imputation Type            simple\n",
      "21          Iterative Imputation Iteration              None\n",
      "22                         Numeric Imputer              mean\n",
      "23      Iterative Imputation Numeric Model              None\n",
      "24                     Categorical Imputer          constant\n",
      "25  Iterative Imputation Categorical Model              None\n",
      "26           Unknown Categoricals Handling    least_frequent\n",
      "27                               Normalize              True\n",
      "28                        Normalize Method            minmax\n",
      "29                          Transformation             False\n",
      "30                   Transformation Method              None\n",
      "31                                     PCA             False\n",
      "32                              PCA Method              None\n",
      "33                          PCA Components              None\n",
      "34                     Ignore Low Variance             False\n",
      "35                     Combine Rare Levels             False\n",
      "36                    Rare Level Threshold              None\n",
      "37                         Numeric Binning             False\n",
      "38                         Remove Outliers             False\n",
      "39                      Outliers Threshold              None\n",
      "40                Remove Multicollinearity             False\n",
      "41             Multicollinearity Threshold              None\n",
      "42                              Clustering             False\n",
      "43                    Clustering Iteration              None\n",
      "44                     Polynomial Features             False\n",
      "45                       Polynomial Degree              None\n",
      "46                    Trignometry Features             False\n",
      "47                    Polynomial Threshold              None\n",
      "48                          Group Features             False\n",
      "49                       Feature Selection             False\n",
      "50            Features Selection Threshold              None\n",
      "51                     Feature Interaction             False\n",
      "52                           Feature Ratio             False\n",
      "53                   Interaction Threshold              None\n",
      "54                        Transform Target             False\n",
      "55                 Transform Target Method           box-cox\n",
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.000821  0.000001  0.001061  0.710677  0.001058  0.503145\n",
      "1     0.000782  0.000001  0.000987  0.730697  0.000984  0.614985\n",
      "2     0.000792  0.000001  0.001027  0.652332  0.001024  0.297511\n",
      "3     0.000748  0.000001  0.000960  0.792786  0.000957  0.431513\n",
      "4     0.000802  0.000001  0.001018  0.771622  0.001015  0.525561\n",
      "5     0.000754  0.000001  0.000970  0.748057  0.000968  0.295377\n",
      "6     0.000791  0.000001  0.000992  0.779663  0.000989  0.313020\n",
      "7     0.000798  0.000001  0.000980  0.761735  0.000978  0.374921\n",
      "8     0.000854  0.000001  0.001050  0.775108  0.001047  0.824542\n",
      "9     0.000792  0.000001  0.001013  0.779791  0.001010  0.446719\n",
      "Mean  0.000793  0.000001  0.001006  0.750247  0.001003  0.462729\n",
      "SD    0.000029  0.000000  0.000032  0.040367  0.000032  0.156949\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 320 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1152 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:   53.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.000772  0.000001  0.000999  0.743536  0.000997  0.466995\n",
      "1     0.000737  0.000001  0.000939  0.755831  0.000937  0.571392\n",
      "2     0.000837  0.000001  0.001020  0.656886  0.001018  0.316730\n",
      "3     0.000719  0.000001  0.000921  0.809333  0.000918  0.406632\n",
      "4     0.000791  0.000001  0.001004  0.777938  0.001001  0.502759\n",
      "5     0.000716  0.000001  0.000938  0.764135  0.000936  0.285291\n",
      "6     0.000767  0.000001  0.000968  0.790273  0.000965  0.301099\n",
      "7     0.000749  0.000001  0.000982  0.761058  0.000979  0.335949\n",
      "8     0.000764  0.000001  0.000966  0.809536  0.000963  0.762193\n",
      "9     0.000772  0.000001  0.000979  0.794168  0.000976  0.429483\n",
      "Mean  0.000762  0.000001  0.000972  0.766269  0.000969  0.437852\n",
      "SD    0.000034  0.000000  0.000030  0.042237  0.000030  0.140060\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=0.9, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.231, max_delta_step=0, max_depth=5,\n",
      "             min_child_weight=4, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=80, n_jobs=-1, num_parallel_tree=1,\n",
      "             objective='reg:squarederror', random_state=123, reg_alpha=0.005,\n",
      "             reg_lambda=0.001, scale_pos_weight=0.6, subsample=0.7,\n",
      "             tree_method='auto', validate_parameters=1, verbosity=0)\n",
      "Transformation Pipeline and Model Succesfully Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12dfceb744c4949b4eec25e41eb6edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=\"Following data types have been inferred automatically, if they are correct press enter to continue"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cv</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Type\n",
       "0    Numeric\n",
       "1    Numeric\n",
       "2    Numeric\n",
       "3    Numeric\n",
       "4    Numeric\n",
       "5    Numeric\n",
       "6    Numeric\n",
       "7    Numeric\n",
       "8    Numeric\n",
       "9    Numeric\n",
       "10   Numeric\n",
       "11   Numeric\n",
       "12   Numeric\n",
       "13   Numeric\n",
       "14   Numeric\n",
       "15   Numeric\n",
       "16   Numeric\n",
       "17   Numeric\n",
       "18   Numeric\n",
       "cv     Label"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup Succesfully Completed!\n",
      "                               Description             Value\n",
      "0                               session_id               123\n",
      "1                                   Target                cv\n",
      "2                            Original Data        (1121, 20)\n",
      "3                           Missing Values             False\n",
      "4                         Numeric Features                19\n",
      "5                     Categorical Features                 0\n",
      "6                         Ordinal Features             False\n",
      "7                High Cardinality Features             False\n",
      "8                  High Cardinality Method              None\n",
      "9                    Transformed Train Set         (1008, 4)\n",
      "10                    Transformed Test Set          (113, 4)\n",
      "11                      Shuffle Train-Test              True\n",
      "12                     Stratify Train-Test             False\n",
      "13                          Fold Generator             KFold\n",
      "14                             Fold Number                10\n",
      "15                                CPU Jobs                -1\n",
      "16                                 Use GPU             False\n",
      "17                          Log Experiment             False\n",
      "18                         Experiment Name  reg-default-name\n",
      "19                                     USI              7c55\n",
      "20                         Imputation Type            simple\n",
      "21          Iterative Imputation Iteration              None\n",
      "22                         Numeric Imputer              mean\n",
      "23      Iterative Imputation Numeric Model              None\n",
      "24                     Categorical Imputer          constant\n",
      "25  Iterative Imputation Categorical Model              None\n",
      "26           Unknown Categoricals Handling    least_frequent\n",
      "27                               Normalize              True\n",
      "28                        Normalize Method            minmax\n",
      "29                          Transformation             False\n",
      "30                   Transformation Method              None\n",
      "31                                     PCA             False\n",
      "32                              PCA Method              None\n",
      "33                          PCA Components              None\n",
      "34                     Ignore Low Variance             False\n",
      "35                     Combine Rare Levels             False\n",
      "36                    Rare Level Threshold              None\n",
      "37                         Numeric Binning             False\n",
      "38                         Remove Outliers             False\n",
      "39                      Outliers Threshold              None\n",
      "40                Remove Multicollinearity             False\n",
      "41             Multicollinearity Threshold              None\n",
      "42                              Clustering             False\n",
      "43                    Clustering Iteration              None\n",
      "44                     Polynomial Features             False\n",
      "45                       Polynomial Degree              None\n",
      "46                    Trignometry Features             False\n",
      "47                    Polynomial Threshold              None\n",
      "48                          Group Features             False\n",
      "49                       Feature Selection             False\n",
      "50            Features Selection Threshold              None\n",
      "51                     Feature Interaction             False\n",
      "52                           Feature Ratio             False\n",
      "53                   Interaction Threshold              None\n",
      "54                        Transform Target             False\n",
      "55                 Transform Target Method           box-cox\n",
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.001085  0.000002  0.001330  0.695642  0.001326  0.388660\n",
      "1     0.001036  0.000002  0.001285  0.750183  0.001280  0.322327\n",
      "2     0.001005  0.000001  0.001222  0.801153  0.001217  0.286555\n",
      "3     0.001177  0.000002  0.001488  0.718522  0.001482  0.372797\n",
      "4     0.001105  0.000002  0.001420  0.713147  0.001415  0.369291\n",
      "5     0.001146  0.000002  0.001416  0.709110  0.001411  0.424256\n",
      "6     0.001104  0.000002  0.001362  0.717495  0.001357  0.366410\n",
      "7     0.001069  0.000002  0.001349  0.763657  0.001344  0.291566\n",
      "8     0.001177  0.000002  0.001464  0.717005  0.001460  0.604428\n",
      "9     0.001015  0.000001  0.001193  0.779485  0.001189  0.382427\n",
      "Mean  0.001092  0.000002  0.001353  0.736540  0.001348  0.380872\n",
      "SD    0.000059  0.000000  0.000093  0.033139  0.000093  0.085223\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 296 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done 896 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1346 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1896 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.001020  0.000002  0.001254  0.729682  0.001250  0.343496\n",
      "1     0.000938  0.000001  0.001137  0.804308  0.001132  0.280219\n",
      "2     0.000943  0.000001  0.001142  0.826201  0.001138  0.277742\n",
      "3     0.001122  0.000002  0.001462  0.728189  0.001456  0.340664\n",
      "4     0.001090  0.000002  0.001434  0.707326  0.001429  0.350108\n",
      "5     0.001102  0.000002  0.001410  0.711407  0.001405  0.417118\n",
      "6     0.001101  0.000002  0.001366  0.715890  0.001361  0.379108\n",
      "7     0.001038  0.000002  0.001320  0.773546  0.001316  0.285667\n",
      "8     0.001161  0.000002  0.001454  0.721027  0.001449  0.592666\n",
      "9     0.001016  0.000001  0.001210  0.773463  0.001206  0.382702\n",
      "Mean  0.001053  0.000002  0.001319  0.749104  0.001314  0.364949\n",
      "SD    0.000071  0.000000  0.000120  0.040068  0.000119  0.087996\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=0.9, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.231, max_delta_step=0, max_depth=5,\n",
      "             min_child_weight=4, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=80, n_jobs=-1, num_parallel_tree=1,\n",
      "             objective='reg:squarederror', random_state=123, reg_alpha=0.005,\n",
      "             reg_lambda=0.001, scale_pos_weight=0.6, subsample=0.7,\n",
      "             tree_method='auto', validate_parameters=1, verbosity=0)\n",
      "Transformation Pipeline and Model Succesfully Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383a3961dc1b4ab5a3bdc7210ec5da9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=\"Following data types have been inferred automatically, if they are correct press enter to continue"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cv</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Type\n",
       "0    Numeric\n",
       "1    Numeric\n",
       "2    Numeric\n",
       "3    Numeric\n",
       "4    Numeric\n",
       "5    Numeric\n",
       "6    Numeric\n",
       "7    Numeric\n",
       "8    Numeric\n",
       "9    Numeric\n",
       "10   Numeric\n",
       "11   Numeric\n",
       "12   Numeric\n",
       "13   Numeric\n",
       "14   Numeric\n",
       "15   Numeric\n",
       "16   Numeric\n",
       "17   Numeric\n",
       "18   Numeric\n",
       "19   Numeric\n",
       "20   Numeric\n",
       "21   Numeric\n",
       "cv     Label"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup Succesfully Completed!\n",
      "                               Description             Value\n",
      "0                               session_id               123\n",
      "1                                   Target                cv\n",
      "2                            Original Data        (1158, 23)\n",
      "3                           Missing Values             False\n",
      "4                         Numeric Features                22\n",
      "5                     Categorical Features                 0\n",
      "6                         Ordinal Features             False\n",
      "7                High Cardinality Features             False\n",
      "8                  High Cardinality Method              None\n",
      "9                    Transformed Train Set         (1042, 4)\n",
      "10                    Transformed Test Set          (116, 4)\n",
      "11                      Shuffle Train-Test              True\n",
      "12                     Stratify Train-Test             False\n",
      "13                          Fold Generator             KFold\n",
      "14                             Fold Number                10\n",
      "15                                CPU Jobs                -1\n",
      "16                                 Use GPU             False\n",
      "17                          Log Experiment             False\n",
      "18                         Experiment Name  reg-default-name\n",
      "19                                     USI              33c2\n",
      "20                         Imputation Type            simple\n",
      "21          Iterative Imputation Iteration              None\n",
      "22                         Numeric Imputer              mean\n",
      "23      Iterative Imputation Numeric Model              None\n",
      "24                     Categorical Imputer          constant\n",
      "25  Iterative Imputation Categorical Model              None\n",
      "26           Unknown Categoricals Handling    least_frequent\n",
      "27                               Normalize              True\n",
      "28                        Normalize Method            minmax\n",
      "29                          Transformation             False\n",
      "30                   Transformation Method              None\n",
      "31                                     PCA             False\n",
      "32                              PCA Method              None\n",
      "33                          PCA Components              None\n",
      "34                     Ignore Low Variance             False\n",
      "35                     Combine Rare Levels             False\n",
      "36                    Rare Level Threshold              None\n",
      "37                         Numeric Binning             False\n",
      "38                         Remove Outliers             False\n",
      "39                      Outliers Threshold              None\n",
      "40                Remove Multicollinearity             False\n",
      "41             Multicollinearity Threshold              None\n",
      "42                              Clustering             False\n",
      "43                    Clustering Iteration              None\n",
      "44                     Polynomial Features             False\n",
      "45                       Polynomial Degree              None\n",
      "46                    Trignometry Features             False\n",
      "47                    Polynomial Threshold              None\n",
      "48                          Group Features             False\n",
      "49                       Feature Selection             False\n",
      "50            Features Selection Threshold              None\n",
      "51                     Feature Interaction             False\n",
      "52                           Feature Ratio             False\n",
      "53                   Interaction Threshold              None\n",
      "54                        Transform Target             False\n",
      "55                 Transform Target Method           box-cox\n",
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.001373  0.000003  0.001672  0.744030  0.001666  0.331897\n",
      "1     0.001415  0.000003  0.001736  0.700699  0.001729  0.366691\n",
      "2     0.001240  0.000003  0.001604  0.742518  0.001598  0.328139\n",
      "3     0.001507  0.000004  0.001887  0.659437  0.001879  0.363313\n",
      "4     0.001263  0.000002  0.001544  0.749166  0.001537  0.423245\n",
      "5     0.001394  0.000003  0.001793  0.772613  0.001784  0.388970\n",
      "6     0.001301  0.000003  0.001588  0.716909  0.001582  0.334240\n",
      "7     0.001316  0.000003  0.001625  0.766369  0.001618  0.380107\n",
      "8     0.001291  0.000002  0.001581  0.736528  0.001576  0.367560\n",
      "9     0.001513  0.000004  0.001879  0.629187  0.001872  0.455798\n",
      "Mean  0.001361  0.000003  0.001691  0.721746  0.001684  0.373996\n",
      "SD    0.000091  0.000000  0.000120  0.044037  0.000119  0.038786\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 296 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done 896 tasks      | elapsed:   29.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1346 tasks      | elapsed:   48.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1896 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.001285  0.000002  0.001569  0.774562  0.001563  0.280908\n",
      "1     0.001330  0.000003  0.001623  0.738334  0.001617  0.329537\n",
      "2     0.001240  0.000003  0.001609  0.740862  0.001602  0.313344\n",
      "3     0.001459  0.000003  0.001810  0.686807  0.001802  0.339601\n",
      "4     0.001185  0.000002  0.001450  0.778602  0.001444  0.393652\n",
      "5     0.001422  0.000003  0.001799  0.770938  0.001791  0.413311\n",
      "6     0.001211  0.000002  0.001510  0.744131  0.001504  0.302925\n",
      "7     0.001275  0.000003  0.001591  0.775922  0.001585  0.348254\n",
      "8     0.001299  0.000003  0.001613  0.725800  0.001608  0.353559\n",
      "9     0.001400  0.000003  0.001792  0.662730  0.001785  0.425088\n",
      "Mean  0.001311  0.000003  0.001637  0.739869  0.001630  0.350018\n",
      "SD    0.000087  0.000000  0.000118  0.037356  0.000117  0.045197\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=0.9, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.212, max_delta_step=0, max_depth=3,\n",
      "             min_child_weight=3, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=70, n_jobs=-1, num_parallel_tree=1,\n",
      "             objective='reg:squarederror', random_state=123, reg_alpha=0.01,\n",
      "             reg_lambda=5, scale_pos_weight=4.800000000000001, subsample=0.5,\n",
      "             tree_method='auto', validate_parameters=1, verbosity=0)\n",
      "Transformation Pipeline and Model Succesfully Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bad0fd831f456ca1fd072ad8e08e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=\"Following data types have been inferred automatically, if they are correct press enter to continue"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cv</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Type\n",
       "0    Numeric\n",
       "1    Numeric\n",
       "2    Numeric\n",
       "3    Numeric\n",
       "4    Numeric\n",
       "5    Numeric\n",
       "6    Numeric\n",
       "7    Numeric\n",
       "8    Numeric\n",
       "9    Numeric\n",
       "10   Numeric\n",
       "11   Numeric\n",
       "12   Numeric\n",
       "13   Numeric\n",
       "14   Numeric\n",
       "15   Numeric\n",
       "16   Numeric\n",
       "17   Numeric\n",
       "18   Numeric\n",
       "19   Numeric\n",
       "20   Numeric\n",
       "21   Numeric\n",
       "22   Numeric\n",
       "23   Numeric\n",
       "24   Numeric\n",
       "cv     Label"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup Succesfully Completed!\n",
      "                               Description             Value\n",
      "0                               session_id               123\n",
      "1                                   Target                cv\n",
      "2                            Original Data        (1142, 26)\n",
      "3                           Missing Values             False\n",
      "4                         Numeric Features                25\n",
      "5                     Categorical Features                 0\n",
      "6                         Ordinal Features             False\n",
      "7                High Cardinality Features             False\n",
      "8                  High Cardinality Method              None\n",
      "9                    Transformed Train Set         (1027, 6)\n",
      "10                    Transformed Test Set          (115, 6)\n",
      "11                      Shuffle Train-Test              True\n",
      "12                     Stratify Train-Test             False\n",
      "13                          Fold Generator             KFold\n",
      "14                             Fold Number                10\n",
      "15                                CPU Jobs                -1\n",
      "16                                 Use GPU             False\n",
      "17                          Log Experiment             False\n",
      "18                         Experiment Name  reg-default-name\n",
      "19                                     USI              2021\n",
      "20                         Imputation Type            simple\n",
      "21          Iterative Imputation Iteration              None\n",
      "22                         Numeric Imputer              mean\n",
      "23      Iterative Imputation Numeric Model              None\n",
      "24                     Categorical Imputer          constant\n",
      "25  Iterative Imputation Categorical Model              None\n",
      "26           Unknown Categoricals Handling    least_frequent\n",
      "27                               Normalize              True\n",
      "28                        Normalize Method            minmax\n",
      "29                          Transformation             False\n",
      "30                   Transformation Method              None\n",
      "31                                     PCA             False\n",
      "32                              PCA Method              None\n",
      "33                          PCA Components              None\n",
      "34                     Ignore Low Variance             False\n",
      "35                     Combine Rare Levels             False\n",
      "36                    Rare Level Threshold              None\n",
      "37                         Numeric Binning             False\n",
      "38                         Remove Outliers             False\n",
      "39                      Outliers Threshold              None\n",
      "40                Remove Multicollinearity             False\n",
      "41             Multicollinearity Threshold              None\n",
      "42                              Clustering             False\n",
      "43                    Clustering Iteration              None\n",
      "44                     Polynomial Features             False\n",
      "45                       Polynomial Degree              None\n",
      "46                    Trignometry Features             False\n",
      "47                    Polynomial Threshold              None\n",
      "48                          Group Features             False\n",
      "49                       Feature Selection             False\n",
      "50            Features Selection Threshold              None\n",
      "51                     Feature Interaction             False\n",
      "52                           Feature Ratio             False\n",
      "53                   Interaction Threshold              None\n",
      "54                        Transform Target             False\n",
      "55                 Transform Target Method           box-cox\n",
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.001632  0.000004  0.002080  0.715043  0.002071  0.281483\n",
      "1     0.001788  0.000005  0.002224  0.636885  0.002214  0.394737\n",
      "2     0.001615  0.000004  0.001923  0.677140  0.001915  0.358567\n",
      "3     0.001679  0.000004  0.002069  0.684715  0.002060  0.429706\n",
      "4     0.001560  0.000004  0.001940  0.697842  0.001931  0.357974\n",
      "5     0.001717  0.000005  0.002126  0.735953  0.002115  0.344031\n",
      "6     0.001992  0.000006  0.002392  0.617474  0.002379  0.452863\n",
      "7     0.001656  0.000004  0.002082  0.638281  0.002072  0.409020\n",
      "8     0.001893  0.000006  0.002426  0.641947  0.002414  0.475332\n",
      "9     0.001749  0.000005  0.002219  0.593000  0.002207  0.397910\n",
      "Mean  0.001728  0.000005  0.002148  0.663828  0.002138  0.390162\n",
      "SD    0.000126  0.000001  0.000160  0.043149  0.000159  0.053999\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 296 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=-1)]: Done 896 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1346 tasks      | elapsed:   50.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1896 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.001621  0.000004  0.001969  0.744765  0.001960  0.285738\n",
      "1     0.001706  0.000004  0.002098  0.676721  0.002089  0.378556\n",
      "2     0.001525  0.000004  0.001883  0.690363  0.001876  0.319070\n",
      "3     0.001620  0.000004  0.002009  0.702584  0.002001  0.391905\n",
      "4     0.001427  0.000003  0.001808  0.737567  0.001799  0.315837\n",
      "5     0.001723  0.000005  0.002134  0.733923  0.002124  0.321172\n",
      "6     0.002019  0.000006  0.002427  0.606150  0.002414  0.450565\n",
      "7     0.001660  0.000004  0.002041  0.652256  0.002031  0.384841\n",
      "8     0.001889  0.000006  0.002366  0.659457  0.002353  0.476981\n",
      "9     0.001788  0.000005  0.002234  0.587502  0.002222  0.401194\n",
      "Mean  0.001698  0.000004  0.002097  0.679129  0.002087  0.372586\n",
      "SD    0.000163  0.000001  0.000189  0.051223  0.000188  0.058845\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=0.9, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.212, max_delta_step=0, max_depth=3,\n",
      "             min_child_weight=3, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=70, n_jobs=-1, num_parallel_tree=1,\n",
      "             objective='reg:squarederror', random_state=123, reg_alpha=0.01,\n",
      "             reg_lambda=5, scale_pos_weight=4.800000000000001, subsample=0.5,\n",
      "             tree_method='auto', validate_parameters=1, verbosity=0)\n",
      "Transformation Pipeline and Model Succesfully Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869b16cc7c744f6ba4616ed679827a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=\"Following data types have been inferred automatically, if they are correct press enter to continue"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cv</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Type\n",
       "0    Numeric\n",
       "1    Numeric\n",
       "2    Numeric\n",
       "3    Numeric\n",
       "4    Numeric\n",
       "5    Numeric\n",
       "6    Numeric\n",
       "7    Numeric\n",
       "8    Numeric\n",
       "9    Numeric\n",
       "10   Numeric\n",
       "11   Numeric\n",
       "12   Numeric\n",
       "13   Numeric\n",
       "14   Numeric\n",
       "15   Numeric\n",
       "16   Numeric\n",
       "17   Numeric\n",
       "18   Numeric\n",
       "19   Numeric\n",
       "20   Numeric\n",
       "21   Numeric\n",
       "22   Numeric\n",
       "23   Numeric\n",
       "24   Numeric\n",
       "25   Numeric\n",
       "26   Numeric\n",
       "27   Numeric\n",
       "cv     Label"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup Succesfully Completed!\n",
      "                               Description             Value\n",
      "0                               session_id               123\n",
      "1                                   Target                cv\n",
      "2                            Original Data        (1185, 29)\n",
      "3                           Missing Values             False\n",
      "4                         Numeric Features                28\n",
      "5                     Categorical Features                 0\n",
      "6                         Ordinal Features             False\n",
      "7                High Cardinality Features             False\n",
      "8                  High Cardinality Method              None\n",
      "9                    Transformed Train Set         (1066, 6)\n",
      "10                    Transformed Test Set          (119, 6)\n",
      "11                      Shuffle Train-Test              True\n",
      "12                     Stratify Train-Test             False\n",
      "13                          Fold Generator             KFold\n",
      "14                             Fold Number                10\n",
      "15                                CPU Jobs                -1\n",
      "16                                 Use GPU             False\n",
      "17                          Log Experiment             False\n",
      "18                         Experiment Name  reg-default-name\n",
      "19                                     USI              4d5a\n",
      "20                         Imputation Type            simple\n",
      "21          Iterative Imputation Iteration              None\n",
      "22                         Numeric Imputer              mean\n",
      "23      Iterative Imputation Numeric Model              None\n",
      "24                     Categorical Imputer          constant\n",
      "25  Iterative Imputation Categorical Model              None\n",
      "26           Unknown Categoricals Handling    least_frequent\n",
      "27                               Normalize              True\n",
      "28                        Normalize Method            minmax\n",
      "29                          Transformation             False\n",
      "30                   Transformation Method              None\n",
      "31                                     PCA             False\n",
      "32                              PCA Method              None\n",
      "33                          PCA Components              None\n",
      "34                     Ignore Low Variance             False\n",
      "35                     Combine Rare Levels             False\n",
      "36                    Rare Level Threshold              None\n",
      "37                         Numeric Binning             False\n",
      "38                         Remove Outliers             False\n",
      "39                      Outliers Threshold              None\n",
      "40                Remove Multicollinearity             False\n",
      "41             Multicollinearity Threshold              None\n",
      "42                              Clustering             False\n",
      "43                    Clustering Iteration              None\n",
      "44                     Polynomial Features             False\n",
      "45                       Polynomial Degree              None\n",
      "46                    Trignometry Features             False\n",
      "47                    Polynomial Threshold              None\n",
      "48                          Group Features             False\n",
      "49                       Feature Selection             False\n",
      "50            Features Selection Threshold              None\n",
      "51                     Feature Interaction             False\n",
      "52                           Feature Ratio             False\n",
      "53                   Interaction Threshold              None\n",
      "54                        Transform Target             False\n",
      "55                 Transform Target Method           box-cox\n",
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.001963  0.000006  0.002485  0.624578  0.002474  0.348927\n",
      "1     0.002018  0.000006  0.002481  0.635821  0.002469  0.484852\n",
      "2     0.001883  0.000006  0.002498  0.627305  0.002484  0.324452\n",
      "3     0.002413  0.000008  0.002876  0.583259  0.002860  0.481949\n",
      "4     0.002188  0.000008  0.002788  0.600383  0.002773  0.377331\n",
      "5     0.001995  0.000006  0.002503  0.627942  0.002491  0.478526\n",
      "6     0.002048  0.000006  0.002532  0.655844  0.002518  0.488870\n",
      "7     0.001814  0.000005  0.002321  0.669022  0.002309  0.336833\n",
      "8     0.001738  0.000005  0.002231  0.696980  0.002220  0.379763\n",
      "9     0.002137  0.000007  0.002621  0.656277  0.002604  0.500082\n",
      "Mean  0.002020  0.000006  0.002534  0.637741  0.002520  0.420158\n",
      "SD    0.000185  0.000001  0.000183  0.031472  0.000181  0.068674\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 296 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 896 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1346 tasks      | elapsed:   58.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1896 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.001911  0.000006  0.002345  0.665556  0.002335  0.336692\n",
      "1     0.001995  0.000006  0.002413  0.655502  0.002401  0.413987\n",
      "2     0.001806  0.000005  0.002339  0.673242  0.002318  0.289077\n",
      "3     0.002429  0.000008  0.002807  0.602760  0.002792  0.459701\n",
      "4     0.002111  0.000007  0.002641  0.641411  0.002608  0.356518\n",
      "5     0.001887  0.000006  0.002388  0.661480  0.002376  0.415286\n",
      "6     0.002003  0.000006  0.002505  0.663189  0.002492  0.459099\n",
      "7     0.001810  0.000005  0.002295  0.676367  0.002283  0.337097\n",
      "8     0.001712  0.000005  0.002185  0.709240  0.002175  0.340320\n",
      "9     0.002212  0.000007  0.002703  0.634321  0.002686  0.477764\n",
      "Mean  0.001987  0.000006  0.002462  0.658307  0.002447  0.388554\n",
      "SD    0.000204  0.000001  0.000188  0.026803  0.000185  0.061599\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.366, max_delta_step=0, max_depth=1,\n",
      "             min_child_weight=4, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=130, n_jobs=-1, num_parallel_tree=1,\n",
      "             objective='reg:squarederror', random_state=123, reg_alpha=0.0001,\n",
      "             reg_lambda=1e-07, scale_pos_weight=28.6, subsample=1,\n",
      "             tree_method='auto', validate_parameters=1, verbosity=0)\n",
      "Transformation Pipeline and Model Succesfully Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13fb422e42b740daa45980488e285a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=\"Following data types have been inferred automatically, if they are correct press enter to continue"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cv</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Type\n",
       "0    Numeric\n",
       "1    Numeric\n",
       "2    Numeric\n",
       "3    Numeric\n",
       "4    Numeric\n",
       "5    Numeric\n",
       "6    Numeric\n",
       "7    Numeric\n",
       "8    Numeric\n",
       "9    Numeric\n",
       "10   Numeric\n",
       "11   Numeric\n",
       "12   Numeric\n",
       "13   Numeric\n",
       "14   Numeric\n",
       "15   Numeric\n",
       "16   Numeric\n",
       "17   Numeric\n",
       "18   Numeric\n",
       "19   Numeric\n",
       "20   Numeric\n",
       "21   Numeric\n",
       "22   Numeric\n",
       "23   Numeric\n",
       "24   Numeric\n",
       "25   Numeric\n",
       "26   Numeric\n",
       "27   Numeric\n",
       "28   Numeric\n",
       "29   Numeric\n",
       "30   Numeric\n",
       "cv     Label"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup Succesfully Completed!\n",
      "                               Description             Value\n",
      "0                               session_id               123\n",
      "1                                   Target                cv\n",
      "2                            Original Data        (1214, 32)\n",
      "3                           Missing Values             False\n",
      "4                         Numeric Features                31\n",
      "5                     Categorical Features                 0\n",
      "6                         Ordinal Features             False\n",
      "7                High Cardinality Features             False\n",
      "8                  High Cardinality Method              None\n",
      "9                    Transformed Train Set         (1092, 6)\n",
      "10                    Transformed Test Set          (122, 6)\n",
      "11                      Shuffle Train-Test              True\n",
      "12                     Stratify Train-Test             False\n",
      "13                          Fold Generator             KFold\n",
      "14                             Fold Number                10\n",
      "15                                CPU Jobs                -1\n",
      "16                                 Use GPU             False\n",
      "17                          Log Experiment             False\n",
      "18                         Experiment Name  reg-default-name\n",
      "19                                     USI              f614\n",
      "20                         Imputation Type            simple\n",
      "21          Iterative Imputation Iteration              None\n",
      "22                         Numeric Imputer              mean\n",
      "23      Iterative Imputation Numeric Model              None\n",
      "24                     Categorical Imputer          constant\n",
      "25  Iterative Imputation Categorical Model              None\n",
      "26           Unknown Categoricals Handling    least_frequent\n",
      "27                               Normalize              True\n",
      "28                        Normalize Method            minmax\n",
      "29                          Transformation             False\n",
      "30                   Transformation Method              None\n",
      "31                                     PCA             False\n",
      "32                              PCA Method              None\n",
      "33                          PCA Components              None\n",
      "34                     Ignore Low Variance             False\n",
      "35                     Combine Rare Levels             False\n",
      "36                    Rare Level Threshold              None\n",
      "37                         Numeric Binning             False\n",
      "38                         Remove Outliers             False\n",
      "39                      Outliers Threshold              None\n",
      "40                Remove Multicollinearity             False\n",
      "41             Multicollinearity Threshold              None\n",
      "42                              Clustering             False\n",
      "43                    Clustering Iteration              None\n",
      "44                     Polynomial Features             False\n",
      "45                       Polynomial Degree              None\n",
      "46                    Trignometry Features             False\n",
      "47                    Polynomial Threshold              None\n",
      "48                          Group Features             False\n",
      "49                       Feature Selection             False\n",
      "50            Features Selection Threshold              None\n",
      "51                     Feature Interaction             False\n",
      "52                           Feature Ratio             False\n",
      "53                   Interaction Threshold              None\n",
      "54                        Transform Target             False\n",
      "55                 Transform Target Method           box-cox\n",
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.002314  0.000008  0.002880  0.668123  0.002864  0.463561\n",
      "1     0.002582  0.000010  0.003164  0.617181  0.003145  0.543181\n",
      "2     0.002163  0.000007  0.002691  0.606466  0.002678  0.353710\n",
      "3     0.002352  0.000008  0.002874  0.583838  0.002857  0.392597\n",
      "4     0.002375  0.000009  0.002938  0.598901  0.002918  0.364825\n",
      "5     0.002209  0.000008  0.002740  0.579870  0.002724  0.414750\n",
      "6     0.002387  0.000008  0.002854  0.535936  0.002841  0.368854\n",
      "7     0.002044  0.000006  0.002516  0.729317  0.002498  0.324650\n",
      "8     0.002050  0.000007  0.002615  0.751327  0.002600  0.460933\n",
      "9     0.002227  0.000008  0.002846  0.574913  0.002832  0.339658\n",
      "Mean  0.002270  0.000008  0.002812  0.624587  0.002796  0.402672\n",
      "SD    0.000157  0.000001  0.000172  0.066300  0.000172  0.064903\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 482 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=-1)]: Done 832 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1282 tasks      | elapsed:   59.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1832 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.002214  0.000008  0.002789  0.688750  0.002773  0.436843\n",
      "1     0.002370  0.000008  0.002822  0.695610  0.002804  0.477340\n",
      "2     0.002076  0.000006  0.002483  0.665056  0.002470  0.320648\n",
      "3     0.002002  0.000006  0.002425  0.703753  0.002411  0.330824\n",
      "4     0.002152  0.000007  0.002687  0.664494  0.002668  0.316703\n",
      "5     0.002205  0.000007  0.002652  0.606493  0.002636  0.402880\n",
      "6     0.002097  0.000007  0.002573  0.622799  0.002561  0.273787\n",
      "7     0.001929  0.000006  0.002412  0.751197  0.002399  0.307723\n",
      "8     0.001910  0.000006  0.002467  0.778630  0.002453  0.444215\n",
      "9     0.002132  0.000007  0.002620  0.639686  0.002607  0.320389\n",
      "Mean  0.002109  0.000007  0.002593  0.681647  0.002578  0.363135\n",
      "SD    0.000133  0.000001  0.000139  0.051399  0.000137  0.066720\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=0.7, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.042, max_delta_step=0, max_depth=2,\n",
      "             min_child_weight=3, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=270, n_jobs=-1, num_parallel_tree=1,\n",
      "             objective='reg:squarederror', random_state=123, reg_alpha=1e-06,\n",
      "             reg_lambda=0.01, scale_pos_weight=42.2, subsample=0.2,\n",
      "             tree_method='auto', validate_parameters=1, verbosity=0)\n",
      "Transformation Pipeline and Model Succesfully Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3996ad500aa5457b81515a45972e50de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=\"Following data types have been inferred automatically, if they are correct press enter to continue"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cv</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Type\n",
       "0    Numeric\n",
       "1    Numeric\n",
       "2    Numeric\n",
       "3    Numeric\n",
       "4    Numeric\n",
       "5    Numeric\n",
       "6    Numeric\n",
       "7    Numeric\n",
       "8    Numeric\n",
       "9    Numeric\n",
       "10   Numeric\n",
       "11   Numeric\n",
       "12   Numeric\n",
       "13   Numeric\n",
       "14   Numeric\n",
       "15   Numeric\n",
       "16   Numeric\n",
       "17   Numeric\n",
       "18   Numeric\n",
       "19   Numeric\n",
       "20   Numeric\n",
       "21   Numeric\n",
       "22   Numeric\n",
       "23   Numeric\n",
       "24   Numeric\n",
       "25   Numeric\n",
       "26   Numeric\n",
       "27   Numeric\n",
       "28   Numeric\n",
       "29   Numeric\n",
       "30   Numeric\n",
       "31   Numeric\n",
       "32   Numeric\n",
       "33   Numeric\n",
       "cv     Label"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup Succesfully Completed!\n",
      "                               Description             Value\n",
      "0                               session_id               123\n",
      "1                                   Target                cv\n",
      "2                            Original Data        (1271, 35)\n",
      "3                           Missing Values             False\n",
      "4                         Numeric Features                34\n",
      "5                     Categorical Features                 0\n",
      "6                         Ordinal Features             False\n",
      "7                High Cardinality Features             False\n",
      "8                  High Cardinality Method              None\n",
      "9                    Transformed Train Set        (1143, 10)\n",
      "10                    Transformed Test Set         (128, 10)\n",
      "11                      Shuffle Train-Test              True\n",
      "12                     Stratify Train-Test             False\n",
      "13                          Fold Generator             KFold\n",
      "14                             Fold Number                10\n",
      "15                                CPU Jobs                -1\n",
      "16                                 Use GPU             False\n",
      "17                          Log Experiment             False\n",
      "18                         Experiment Name  reg-default-name\n",
      "19                                     USI              0fef\n",
      "20                         Imputation Type            simple\n",
      "21          Iterative Imputation Iteration              None\n",
      "22                         Numeric Imputer              mean\n",
      "23      Iterative Imputation Numeric Model              None\n",
      "24                     Categorical Imputer          constant\n",
      "25  Iterative Imputation Categorical Model              None\n",
      "26           Unknown Categoricals Handling    least_frequent\n",
      "27                               Normalize              True\n",
      "28                        Normalize Method            minmax\n",
      "29                          Transformation             False\n",
      "30                   Transformation Method              None\n",
      "31                                     PCA             False\n",
      "32                              PCA Method              None\n",
      "33                          PCA Components              None\n",
      "34                     Ignore Low Variance             False\n",
      "35                     Combine Rare Levels             False\n",
      "36                    Rare Level Threshold              None\n",
      "37                         Numeric Binning             False\n",
      "38                         Remove Outliers             False\n",
      "39                      Outliers Threshold              None\n",
      "40                Remove Multicollinearity             False\n",
      "41             Multicollinearity Threshold              None\n",
      "42                              Clustering             False\n",
      "43                    Clustering Iteration              None\n",
      "44                     Polynomial Features             False\n",
      "45                       Polynomial Degree              None\n",
      "46                    Trignometry Features             False\n",
      "47                    Polynomial Threshold              None\n",
      "48                          Group Features             False\n",
      "49                       Feature Selection             False\n",
      "50            Features Selection Threshold              None\n",
      "51                     Feature Interaction             False\n",
      "52                           Feature Ratio             False\n",
      "53                   Interaction Threshold              None\n",
      "54                        Transform Target             False\n",
      "55                 Transform Target Method           box-cox\n",
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.002624  0.000011  0.003244  0.551755  0.003222  0.452265\n",
      "1     0.002611  0.000011  0.003358  0.576972  0.003336  0.401535\n",
      "2     0.002617  0.000011  0.003346  0.562492  0.003323  0.453313\n",
      "3     0.002634  0.000011  0.003256  0.582179  0.003236  0.540162\n",
      "4     0.002422  0.000009  0.003037  0.667791  0.003018  0.414302\n",
      "5     0.002746  0.000011  0.003315  0.593022  0.003295  0.487784\n",
      "6     0.002313  0.000008  0.002900  0.564771  0.002882  0.372712\n",
      "7     0.002615  0.000011  0.003247  0.610245  0.003228  0.417492\n",
      "8     0.002252  0.000008  0.002804  0.735064  0.002786  0.377274\n",
      "9     0.002351  0.000008  0.002820  0.711103  0.002802  0.407169\n",
      "Mean  0.002518  0.000010  0.003133  0.615539  0.003113  0.432401\n",
      "SD    0.000160  0.000001  0.000210  0.062245  0.000208  0.049247\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 240 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 490 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done 840 tasks      | elapsed:   40.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1290 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1840 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.002502  0.000009  0.003069  0.599042  0.003048  0.408508\n",
      "1     0.002287  0.000008  0.002820  0.701656  0.002801  0.338615\n",
      "2     0.002298  0.000008  0.002851  0.682326  0.002832  0.374259\n",
      "3     0.002413  0.000008  0.002913  0.665679  0.002895  0.462752\n",
      "4     0.002242  0.000008  0.002844  0.708596  0.002827  0.366061\n",
      "5     0.002489  0.000009  0.003021  0.662079  0.003001  0.459298\n",
      "6     0.002294  0.000008  0.002812  0.590789  0.002794  0.358960\n",
      "7     0.002496  0.000009  0.003048  0.656424  0.003030  0.388648\n",
      "8     0.002042  0.000007  0.002550  0.780893  0.002532  0.339020\n",
      "9     0.002102  0.000007  0.002566  0.760869  0.002550  0.331217\n",
      "Mean  0.002316  0.000008  0.002849  0.680835  0.002831  0.382734\n",
      "SD    0.000153  0.000001  0.000171  0.057965  0.000170  0.045156\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=0.7, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.042, max_delta_step=0, max_depth=2,\n",
      "             min_child_weight=3, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=270, n_jobs=-1, num_parallel_tree=1,\n",
      "             objective='reg:squarederror', random_state=123, reg_alpha=1e-06,\n",
      "             reg_lambda=0.01, scale_pos_weight=42.2, subsample=0.2,\n",
      "             tree_method='auto', validate_parameters=1, verbosity=0)\n",
      "Transformation Pipeline and Model Succesfully Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da9390e7b464a4e8231acf80f362579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=\"Following data types have been inferred automatically, if they are correct press enter to continue"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cv</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Type\n",
       "0    Numeric\n",
       "1    Numeric\n",
       "2    Numeric\n",
       "3    Numeric\n",
       "4    Numeric\n",
       "5    Numeric\n",
       "6    Numeric\n",
       "7    Numeric\n",
       "8    Numeric\n",
       "9    Numeric\n",
       "10   Numeric\n",
       "11   Numeric\n",
       "12   Numeric\n",
       "13   Numeric\n",
       "14   Numeric\n",
       "15   Numeric\n",
       "16   Numeric\n",
       "17   Numeric\n",
       "18   Numeric\n",
       "19   Numeric\n",
       "20   Numeric\n",
       "21   Numeric\n",
       "22   Numeric\n",
       "23   Numeric\n",
       "24   Numeric\n",
       "25   Numeric\n",
       "26   Numeric\n",
       "27   Numeric\n",
       "28   Numeric\n",
       "29   Numeric\n",
       "30   Numeric\n",
       "31   Numeric\n",
       "32   Numeric\n",
       "33   Numeric\n",
       "34   Numeric\n",
       "35   Numeric\n",
       "36   Numeric\n",
       "cv     Label"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup Succesfully Completed!\n",
      "                               Description             Value\n",
      "0                               session_id               123\n",
      "1                                   Target                cv\n",
      "2                            Original Data        (1362, 38)\n",
      "3                           Missing Values             False\n",
      "4                         Numeric Features                37\n",
      "5                     Categorical Features                 0\n",
      "6                         Ordinal Features             False\n",
      "7                High Cardinality Features             False\n",
      "8                  High Cardinality Method              None\n",
      "9                    Transformed Train Set         (1225, 8)\n",
      "10                    Transformed Test Set          (137, 8)\n",
      "11                      Shuffle Train-Test              True\n",
      "12                     Stratify Train-Test             False\n",
      "13                          Fold Generator             KFold\n",
      "14                             Fold Number                10\n",
      "15                                CPU Jobs                -1\n",
      "16                                 Use GPU             False\n",
      "17                          Log Experiment             False\n",
      "18                         Experiment Name  reg-default-name\n",
      "19                                     USI              9088\n",
      "20                         Imputation Type            simple\n",
      "21          Iterative Imputation Iteration              None\n",
      "22                         Numeric Imputer              mean\n",
      "23      Iterative Imputation Numeric Model              None\n",
      "24                     Categorical Imputer          constant\n",
      "25  Iterative Imputation Categorical Model              None\n",
      "26           Unknown Categoricals Handling    least_frequent\n",
      "27                               Normalize              True\n",
      "28                        Normalize Method            minmax\n",
      "29                          Transformation             False\n",
      "30                   Transformation Method              None\n",
      "31                                     PCA             False\n",
      "32                              PCA Method              None\n",
      "33                          PCA Components              None\n",
      "34                     Ignore Low Variance             False\n",
      "35                     Combine Rare Levels             False\n",
      "36                    Rare Level Threshold              None\n",
      "37                         Numeric Binning             False\n",
      "38                         Remove Outliers             False\n",
      "39                      Outliers Threshold              None\n",
      "40                Remove Multicollinearity             False\n",
      "41             Multicollinearity Threshold              None\n",
      "42                              Clustering             False\n",
      "43                    Clustering Iteration              None\n",
      "44                     Polynomial Features             False\n",
      "45                       Polynomial Degree              None\n",
      "46                    Trignometry Features             False\n",
      "47                    Polynomial Threshold              None\n",
      "48                          Group Features             False\n",
      "49                       Feature Selection             False\n",
      "50            Features Selection Threshold              None\n",
      "51                     Feature Interaction             False\n",
      "52                           Feature Ratio             False\n",
      "53                   Interaction Threshold              None\n",
      "54                        Transform Target             False\n",
      "55                 Transform Target Method           box-cox\n",
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.002833  0.000012  0.003479  0.558894  0.003456  0.505410\n",
      "1     0.002581  0.000010  0.003204  0.736379  0.003181  0.400819\n",
      "2     0.002788  0.000012  0.003491  0.602517  0.003468  0.348564\n",
      "3     0.002944  0.000014  0.003744  0.525596  0.003687  0.428986\n",
      "4     0.002492  0.000010  0.003233  0.563659  0.003208  0.417201\n",
      "5     0.002427  0.000009  0.003053  0.686193  0.003033  0.322273\n",
      "6     0.002548  0.000010  0.003095  0.670421  0.003075  0.363607\n",
      "7     0.003149  0.000014  0.003802  0.599054  0.003772  0.642007\n",
      "8     0.002616  0.000011  0.003290  0.665444  0.003266  0.474021\n",
      "9     0.002782  0.000011  0.003316  0.584293  0.003294  0.434426\n",
      "Mean  0.002716  0.000011  0.003370  0.619245  0.003344  0.433731\n",
      "SD    0.000213  0.000002  0.000242  0.063535  0.000235  0.087243\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 240 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done 490 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=-1)]: Done 840 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1290 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1840 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.002631  0.000010  0.003203  0.626023  0.003183  0.449051\n",
      "1     0.002461  0.000009  0.002969  0.773553  0.002947  0.351099\n",
      "2     0.002675  0.000011  0.003343  0.635484  0.003320  0.351224\n",
      "3     0.002592  0.000011  0.003313  0.628493  0.003287  0.360107\n",
      "4     0.002414  0.000009  0.003012  0.621127  0.002989  0.409222\n",
      "5     0.002284  0.000008  0.002871  0.722435  0.002851  0.284173\n",
      "6     0.002385  0.000009  0.003009  0.688607  0.002987  0.303931\n",
      "7     0.002812  0.000011  0.003354  0.687978  0.003330  0.553861\n",
      "8     0.002535  0.000010  0.003084  0.706010  0.003061  0.435835\n",
      "9     0.002582  0.000009  0.003068  0.643954  0.003049  0.412934\n",
      "Mean  0.002537  0.000010  0.003123  0.673367  0.003100  0.391144\n",
      "SD    0.000147  0.000001  0.000162  0.048208  0.000161  0.074725\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.151, max_delta_step=0, max_depth=1,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=210, n_jobs=-1, num_parallel_tree=1,\n",
      "             objective='reg:squarederror', random_state=123, reg_alpha=0.005,\n",
      "             reg_lambda=0.1, scale_pos_weight=12.3, subsample=0.9,\n",
      "             tree_method='auto', validate_parameters=1, verbosity=0)\n",
      "Transformation Pipeline and Model Succesfully Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c63899840342c8b28a719c9c0781a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=\"Following data types have been inferred automatically, if they are correct press enter to continue"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cv</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Type\n",
       "0    Numeric\n",
       "1    Numeric\n",
       "2    Numeric\n",
       "3    Numeric\n",
       "4    Numeric\n",
       "5    Numeric\n",
       "6    Numeric\n",
       "7    Numeric\n",
       "8    Numeric\n",
       "9    Numeric\n",
       "10   Numeric\n",
       "11   Numeric\n",
       "12   Numeric\n",
       "13   Numeric\n",
       "14   Numeric\n",
       "15   Numeric\n",
       "16   Numeric\n",
       "17   Numeric\n",
       "18   Numeric\n",
       "19   Numeric\n",
       "20   Numeric\n",
       "21   Numeric\n",
       "22   Numeric\n",
       "23   Numeric\n",
       "24   Numeric\n",
       "25   Numeric\n",
       "26   Numeric\n",
       "27   Numeric\n",
       "28   Numeric\n",
       "29   Numeric\n",
       "30   Numeric\n",
       "31   Numeric\n",
       "32   Numeric\n",
       "33   Numeric\n",
       "34   Numeric\n",
       "35   Numeric\n",
       "36   Numeric\n",
       "37   Numeric\n",
       "38   Numeric\n",
       "39   Numeric\n",
       "cv     Label"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup Succesfully Completed!\n",
      "                               Description             Value\n",
      "0                               session_id               123\n",
      "1                                   Target                cv\n",
      "2                            Original Data        (1477, 41)\n",
      "3                           Missing Values             False\n",
      "4                         Numeric Features                40\n",
      "5                     Categorical Features                 0\n",
      "6                         Ordinal Features             False\n",
      "7                High Cardinality Features             False\n",
      "8                  High Cardinality Method              None\n",
      "9                    Transformed Train Set         (1329, 9)\n",
      "10                    Transformed Test Set          (148, 9)\n",
      "11                      Shuffle Train-Test              True\n",
      "12                     Stratify Train-Test             False\n",
      "13                          Fold Generator             KFold\n",
      "14                             Fold Number                10\n",
      "15                                CPU Jobs                -1\n",
      "16                                 Use GPU             False\n",
      "17                          Log Experiment             False\n",
      "18                         Experiment Name  reg-default-name\n",
      "19                                     USI              d584\n",
      "20                         Imputation Type            simple\n",
      "21          Iterative Imputation Iteration              None\n",
      "22                         Numeric Imputer              mean\n",
      "23      Iterative Imputation Numeric Model              None\n",
      "24                     Categorical Imputer          constant\n",
      "25  Iterative Imputation Categorical Model              None\n",
      "26           Unknown Categoricals Handling    least_frequent\n",
      "27                               Normalize              True\n",
      "28                        Normalize Method            minmax\n",
      "29                          Transformation             False\n",
      "30                   Transformation Method              None\n",
      "31                                     PCA             False\n",
      "32                              PCA Method              None\n",
      "33                          PCA Components              None\n",
      "34                     Ignore Low Variance             False\n",
      "35                     Combine Rare Levels             False\n",
      "36                    Rare Level Threshold              None\n",
      "37                         Numeric Binning             False\n",
      "38                         Remove Outliers             False\n",
      "39                      Outliers Threshold              None\n",
      "40                Remove Multicollinearity             False\n",
      "41             Multicollinearity Threshold              None\n",
      "42                              Clustering             False\n",
      "43                    Clustering Iteration              None\n",
      "44                     Polynomial Features             False\n",
      "45                       Polynomial Degree              None\n",
      "46                    Trignometry Features             False\n",
      "47                    Polynomial Threshold              None\n",
      "48                          Group Features             False\n",
      "49                       Feature Selection             False\n",
      "50            Features Selection Threshold              None\n",
      "51                     Feature Interaction             False\n",
      "52                           Feature Ratio             False\n",
      "53                   Interaction Threshold              None\n",
      "54                        Transform Target             False\n",
      "55                 Transform Target Method           box-cox\n",
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.003178  0.000015  0.003815  0.522221  0.003789  0.469070\n",
      "1     0.002992  0.000014  0.003789  0.556566  0.003763  0.421103\n",
      "2     0.002997  0.000015  0.003845  0.593594  0.003815  0.449313\n",
      "3     0.002766  0.000012  0.003498  0.640776  0.003476  0.392189\n",
      "4     0.002885  0.000014  0.003706  0.626081  0.003678  0.392058\n",
      "5     0.002706  0.000013  0.003576  0.679539  0.003536  0.292162\n",
      "6     0.003002  0.000014  0.003801  0.516097  0.003771  0.659743\n",
      "7     0.002999  0.000014  0.003774  0.653235  0.003746  0.405374\n",
      "8     0.002892  0.000012  0.003492  0.657984  0.003469  0.410025\n",
      "9     0.003021  0.000014  0.003764  0.562732  0.003735  0.541753\n",
      "Mean  0.002944  0.000014  0.003706  0.600882  0.003678  0.443279\n",
      "SD    0.000129  0.000001  0.000127  0.055914  0.000126  0.094000\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done 482 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=-1)]: Done 832 tasks      | elapsed:   47.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1282 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1832 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.002888  0.000012  0.003516  0.594225  0.003492  0.402772\n",
      "1     0.002734  0.000012  0.003412  0.640300  0.003389  0.380054\n",
      "2     0.002982  0.000013  0.003652  0.633338  0.003623  0.425905\n",
      "3     0.002730  0.000011  0.003346  0.671283  0.003324  0.389752\n",
      "4     0.002658  0.000010  0.003236  0.714978  0.003212  0.336470\n",
      "5     0.002776  0.000012  0.003405  0.709465  0.003379  0.318321\n",
      "6     0.002818  0.000012  0.003430  0.606017  0.003406  0.586369\n",
      "7     0.002838  0.000013  0.003605  0.683559  0.003579  0.348245\n",
      "8     0.002583  0.000010  0.003132  0.724888  0.003109  0.360136\n",
      "9     0.002902  0.000012  0.003534  0.614454  0.003506  0.516968\n",
      "Mean  0.002791  0.000012  0.003427  0.659251  0.003402  0.406499\n",
      "SD    0.000114  0.000001  0.000153  0.045574  0.000151  0.080093\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.151, max_delta_step=0, max_depth=1,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=210, n_jobs=-1, num_parallel_tree=1,\n",
      "             objective='reg:squarederror', random_state=123, reg_alpha=0.005,\n",
      "             reg_lambda=0.1, scale_pos_weight=12.3, subsample=0.9,\n",
      "             tree_method='auto', validate_parameters=1, verbosity=0)\n",
      "Transformation Pipeline and Model Succesfully Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d93ee02c60a4236a2ed1956789ad775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=\"Following data types have been inferred automatically, if they are correct press enter to continue"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cv</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Type\n",
       "0    Numeric\n",
       "1    Numeric\n",
       "2    Numeric\n",
       "3    Numeric\n",
       "4    Numeric\n",
       "5    Numeric\n",
       "6    Numeric\n",
       "7    Numeric\n",
       "8    Numeric\n",
       "9    Numeric\n",
       "10   Numeric\n",
       "11   Numeric\n",
       "12   Numeric\n",
       "13   Numeric\n",
       "14   Numeric\n",
       "15   Numeric\n",
       "16   Numeric\n",
       "17   Numeric\n",
       "18   Numeric\n",
       "19   Numeric\n",
       "20   Numeric\n",
       "21   Numeric\n",
       "22   Numeric\n",
       "23   Numeric\n",
       "24   Numeric\n",
       "25   Numeric\n",
       "26   Numeric\n",
       "27   Numeric\n",
       "28   Numeric\n",
       "29   Numeric\n",
       "30   Numeric\n",
       "31   Numeric\n",
       "32   Numeric\n",
       "33   Numeric\n",
       "34   Numeric\n",
       "35   Numeric\n",
       "36   Numeric\n",
       "37   Numeric\n",
       "38   Numeric\n",
       "39   Numeric\n",
       "40   Numeric\n",
       "41   Numeric\n",
       "42   Numeric\n",
       "cv     Label"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup Succesfully Completed!\n",
      "                               Description             Value\n",
      "0                               session_id               123\n",
      "1                                   Target                cv\n",
      "2                            Original Data        (1660, 44)\n",
      "3                           Missing Values             False\n",
      "4                         Numeric Features                43\n",
      "5                     Categorical Features                 0\n",
      "6                         Ordinal Features             False\n",
      "7                High Cardinality Features             False\n",
      "8                  High Cardinality Method              None\n",
      "9                    Transformed Train Set         (1494, 5)\n",
      "10                    Transformed Test Set          (166, 5)\n",
      "11                      Shuffle Train-Test              True\n",
      "12                     Stratify Train-Test             False\n",
      "13                          Fold Generator             KFold\n",
      "14                             Fold Number                10\n",
      "15                                CPU Jobs                -1\n",
      "16                                 Use GPU             False\n",
      "17                          Log Experiment             False\n",
      "18                         Experiment Name  reg-default-name\n",
      "19                                     USI              5712\n",
      "20                         Imputation Type            simple\n",
      "21          Iterative Imputation Iteration              None\n",
      "22                         Numeric Imputer              mean\n",
      "23      Iterative Imputation Numeric Model              None\n",
      "24                     Categorical Imputer          constant\n",
      "25  Iterative Imputation Categorical Model              None\n",
      "26           Unknown Categoricals Handling    least_frequent\n",
      "27                               Normalize              True\n",
      "28                        Normalize Method            minmax\n",
      "29                          Transformation             False\n",
      "30                   Transformation Method              None\n",
      "31                                     PCA             False\n",
      "32                              PCA Method              None\n",
      "33                          PCA Components              None\n",
      "34                     Ignore Low Variance             False\n",
      "35                     Combine Rare Levels             False\n",
      "36                    Rare Level Threshold              None\n",
      "37                         Numeric Binning             False\n",
      "38                         Remove Outliers             False\n",
      "39                      Outliers Threshold              None\n",
      "40                Remove Multicollinearity             False\n",
      "41             Multicollinearity Threshold              None\n",
      "42                              Clustering             False\n",
      "43                    Clustering Iteration              None\n",
      "44                     Polynomial Features             False\n",
      "45                       Polynomial Degree              None\n",
      "46                    Trignometry Features             False\n",
      "47                    Polynomial Threshold              None\n",
      "48                          Group Features             False\n",
      "49                       Feature Selection             False\n",
      "50            Features Selection Threshold              None\n",
      "51                     Feature Interaction             False\n",
      "52                           Feature Ratio             False\n",
      "53                   Interaction Threshold              None\n",
      "54                        Transform Target             False\n",
      "55                 Transform Target Method           box-cox\n",
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.003583  0.000019  0.004362  0.481279  0.004323  0.453604\n",
      "1     0.003798  0.000023  0.004769  0.424259  0.004730  0.595291\n",
      "2     0.003535  0.000019  0.004340  0.515305  0.004309  0.421616\n",
      "3     0.003646  0.000020  0.004474  0.542675  0.004436  0.474805\n",
      "4     0.003466  0.000018  0.004299  0.583087  0.004242  0.474863\n",
      "5     0.003289  0.000018  0.004277  0.539908  0.004242  0.473547\n",
      "6     0.003581  0.000020  0.004511  0.495670  0.004460  0.542723\n",
      "7     0.003406  0.000018  0.004261  0.491899  0.004232  0.545900\n",
      "8     0.003299  0.000017  0.004182  0.506863  0.004151  0.380603\n",
      "9     0.003389  0.000019  0.004302  0.527279  0.004266  0.365192\n",
      "Mean  0.003499  0.000019  0.004378  0.510823  0.004339  0.472814\n",
      "SD    0.000152  0.000001  0.000160  0.040426  0.000158  0.069508\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 296 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done 896 tasks      | elapsed:   47.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1346 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1896 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.003358  0.000017  0.004099  0.542096  0.004068  0.405832\n",
      "1     0.003594  0.000019  0.004404  0.509090  0.004369  0.559041\n",
      "2     0.003331  0.000016  0.003963  0.595904  0.003936  0.394435\n",
      "3     0.003594  0.000019  0.004322  0.573287  0.004285  0.407541\n",
      "4     0.003449  0.000017  0.004163  0.609029  0.004125  0.423711\n",
      "5     0.003229  0.000016  0.003939  0.609646  0.003910  0.418274\n",
      "6     0.003474  0.000019  0.004361  0.528694  0.004326  0.461213\n",
      "7     0.003421  0.000017  0.004142  0.519924  0.004112  0.500079\n",
      "8     0.003047  0.000015  0.003902  0.570671  0.003874  0.348861\n",
      "9     0.003211  0.000016  0.004040  0.583279  0.004004  0.330802\n",
      "Mean  0.003371  0.000017  0.004133  0.564162  0.004101  0.424979\n",
      "SD    0.000165  0.000001  0.000171  0.035093  0.000168  0.064218\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.051, max_delta_step=0, max_depth=11,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=160, n_jobs=-1, num_parallel_tree=1,\n",
      "             objective='reg:squarederror', random_state=123, reg_alpha=0.01,\n",
      "             reg_lambda=3, scale_pos_weight=4.9, subsample=0.5,\n",
      "             tree_method='auto', validate_parameters=1, verbosity=0)\n",
      "Transformation Pipeline and Model Succesfully Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f6f9a91e1244f795f7c4903e1fcfde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=\"Following data types have been inferred automatically, if they are correct press enter to continue"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cv</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Type\n",
       "0    Numeric\n",
       "1    Numeric\n",
       "2    Numeric\n",
       "3    Numeric\n",
       "4    Numeric\n",
       "5    Numeric\n",
       "6    Numeric\n",
       "7    Numeric\n",
       "8    Numeric\n",
       "9    Numeric\n",
       "10   Numeric\n",
       "11   Numeric\n",
       "12   Numeric\n",
       "13   Numeric\n",
       "14   Numeric\n",
       "15   Numeric\n",
       "16   Numeric\n",
       "17   Numeric\n",
       "18   Numeric\n",
       "19   Numeric\n",
       "20   Numeric\n",
       "21   Numeric\n",
       "22   Numeric\n",
       "23   Numeric\n",
       "24   Numeric\n",
       "25   Numeric\n",
       "26   Numeric\n",
       "27   Numeric\n",
       "28   Numeric\n",
       "29   Numeric\n",
       "30   Numeric\n",
       "31   Numeric\n",
       "32   Numeric\n",
       "33   Numeric\n",
       "34   Numeric\n",
       "35   Numeric\n",
       "36   Numeric\n",
       "37   Numeric\n",
       "38   Numeric\n",
       "39   Numeric\n",
       "40   Numeric\n",
       "41   Numeric\n",
       "42   Numeric\n",
       "43   Numeric\n",
       "44   Numeric\n",
       "45   Numeric\n",
       "cv     Label"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup Succesfully Completed!\n",
      "                               Description             Value\n",
      "0                               session_id               123\n",
      "1                                   Target                cv\n",
      "2                            Original Data        (1833, 47)\n",
      "3                           Missing Values             False\n",
      "4                         Numeric Features                46\n",
      "5                     Categorical Features                 0\n",
      "6                         Ordinal Features             False\n",
      "7                High Cardinality Features             False\n",
      "8                  High Cardinality Method              None\n",
      "9                    Transformed Train Set         (1649, 6)\n",
      "10                    Transformed Test Set          (184, 6)\n",
      "11                      Shuffle Train-Test              True\n",
      "12                     Stratify Train-Test             False\n",
      "13                          Fold Generator             KFold\n",
      "14                             Fold Number                10\n",
      "15                                CPU Jobs                -1\n",
      "16                                 Use GPU             False\n",
      "17                          Log Experiment             False\n",
      "18                         Experiment Name  reg-default-name\n",
      "19                                     USI              7745\n",
      "20                         Imputation Type            simple\n",
      "21          Iterative Imputation Iteration              None\n",
      "22                         Numeric Imputer              mean\n",
      "23      Iterative Imputation Numeric Model              None\n",
      "24                     Categorical Imputer          constant\n",
      "25  Iterative Imputation Categorical Model              None\n",
      "26           Unknown Categoricals Handling    least_frequent\n",
      "27                               Normalize              True\n",
      "28                        Normalize Method            minmax\n",
      "29                          Transformation             False\n",
      "30                   Transformation Method              None\n",
      "31                                     PCA             False\n",
      "32                              PCA Method              None\n",
      "33                          PCA Components              None\n",
      "34                     Ignore Low Variance             False\n",
      "35                     Combine Rare Levels             False\n",
      "36                    Rare Level Threshold              None\n",
      "37                         Numeric Binning             False\n",
      "38                         Remove Outliers             False\n",
      "39                      Outliers Threshold              None\n",
      "40                Remove Multicollinearity             False\n",
      "41             Multicollinearity Threshold              None\n",
      "42                              Clustering             False\n",
      "43                    Clustering Iteration              None\n",
      "44                     Polynomial Features             False\n",
      "45                       Polynomial Degree              None\n",
      "46                    Trignometry Features             False\n",
      "47                    Polynomial Threshold              None\n",
      "48                          Group Features             False\n",
      "49                       Feature Selection             False\n",
      "50            Features Selection Threshold              None\n",
      "51                     Feature Interaction             False\n",
      "52                           Feature Ratio             False\n",
      "53                   Interaction Threshold              None\n",
      "54                        Transform Target             False\n",
      "55                 Transform Target Method           box-cox\n",
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.003593  0.000021  0.004537  0.486699  0.004477  0.467727\n",
      "1     0.003589  0.000022  0.004666  0.521487  0.004624  0.396538\n",
      "2     0.003780  0.000021  0.004585  0.550066  0.004546  0.460827\n",
      "3     0.004139  0.000027  0.005203  0.376201  0.005159  0.475791\n",
      "4     0.003402  0.000019  0.004351  0.517079  0.004310  0.440277\n",
      "5     0.003724  0.000021  0.004615  0.578910  0.004572  0.376870\n",
      "6     0.003858  0.000023  0.004833  0.427002  0.004771  0.539493\n",
      "7     0.003467  0.000020  0.004459  0.607667  0.004409  0.363542\n",
      "8     0.003729  0.000023  0.004802  0.392735  0.004751  0.486853\n",
      "9     0.003861  0.000024  0.004870  0.557000  0.004828  0.490024\n",
      "Mean  0.003714  0.000022  0.004692  0.501485  0.004645  0.449794\n",
      "SD    0.000204  0.000002  0.000232  0.075262  0.000232  0.052764\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done 474 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=-1)]: Done 824 tasks      | elapsed:   57.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1274 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1824 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.003531  0.000019  0.004334  0.531557  0.004298  0.417738\n",
      "1     0.003677  0.000020  0.004457  0.563434  0.004417  0.391415\n",
      "2     0.003759  0.000019  0.004387  0.588087  0.004351  0.412965\n",
      "3     0.003796  0.000022  0.004692  0.492780  0.004651  0.409971\n",
      "4     0.003182  0.000015  0.003850  0.621960  0.003824  0.367929\n",
      "5     0.003549  0.000019  0.004382  0.620320  0.004343  0.333315\n",
      "6     0.003524  0.000019  0.004411  0.522672  0.004370  0.470551\n",
      "7     0.003581  0.000018  0.004294  0.636150  0.004256  0.346051\n",
      "8     0.003456  0.000018  0.004292  0.514905  0.004258  0.388522\n",
      "9     0.003906  0.000022  0.004706  0.586479  0.004664  0.457142\n",
      "Mean  0.003596  0.000019  0.004381  0.567835  0.004343  0.399560\n",
      "SD    0.000193  0.000002  0.000226  0.047874  0.000221  0.041730\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=0.7, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.042, max_delta_step=0, max_depth=2,\n",
      "             min_child_weight=3, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=270, n_jobs=-1, num_parallel_tree=1,\n",
      "             objective='reg:squarederror', random_state=123, reg_alpha=1e-06,\n",
      "             reg_lambda=0.01, scale_pos_weight=42.2, subsample=0.2,\n",
      "             tree_method='auto', validate_parameters=1, verbosity=0)\n",
      "Transformation Pipeline and Model Succesfully Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4beb4957ee064ef3a06f83b8b7d9b86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=\"Following data types have been inferred automatically, if they are correct press enter to continue"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cv</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Type\n",
       "0    Numeric\n",
       "1    Numeric\n",
       "2    Numeric\n",
       "3    Numeric\n",
       "4    Numeric\n",
       "5    Numeric\n",
       "6    Numeric\n",
       "7    Numeric\n",
       "8    Numeric\n",
       "9    Numeric\n",
       "10   Numeric\n",
       "11   Numeric\n",
       "12   Numeric\n",
       "13   Numeric\n",
       "14   Numeric\n",
       "15   Numeric\n",
       "16   Numeric\n",
       "17   Numeric\n",
       "18   Numeric\n",
       "19   Numeric\n",
       "20   Numeric\n",
       "21   Numeric\n",
       "22   Numeric\n",
       "23   Numeric\n",
       "24   Numeric\n",
       "25   Numeric\n",
       "26   Numeric\n",
       "27   Numeric\n",
       "28   Numeric\n",
       "29   Numeric\n",
       "30   Numeric\n",
       "31   Numeric\n",
       "32   Numeric\n",
       "33   Numeric\n",
       "34   Numeric\n",
       "35   Numeric\n",
       "36   Numeric\n",
       "37   Numeric\n",
       "38   Numeric\n",
       "39   Numeric\n",
       "40   Numeric\n",
       "41   Numeric\n",
       "42   Numeric\n",
       "43   Numeric\n",
       "44   Numeric\n",
       "45   Numeric\n",
       "46   Numeric\n",
       "47   Numeric\n",
       "48   Numeric\n",
       "cv     Label"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup Succesfully Completed!\n",
      "                               Description             Value\n",
      "0                               session_id               123\n",
      "1                                   Target                cv\n",
      "2                            Original Data        (2135, 50)\n",
      "3                           Missing Values             False\n",
      "4                         Numeric Features                49\n",
      "5                     Categorical Features                 0\n",
      "6                         Ordinal Features             False\n",
      "7                High Cardinality Features             False\n",
      "8                  High Cardinality Method              None\n",
      "9                    Transformed Train Set         (1921, 9)\n",
      "10                    Transformed Test Set          (214, 9)\n",
      "11                      Shuffle Train-Test              True\n",
      "12                     Stratify Train-Test             False\n",
      "13                          Fold Generator             KFold\n",
      "14                             Fold Number                10\n",
      "15                                CPU Jobs                -1\n",
      "16                                 Use GPU             False\n",
      "17                          Log Experiment             False\n",
      "18                         Experiment Name  reg-default-name\n",
      "19                                     USI              c06e\n",
      "20                         Imputation Type            simple\n",
      "21          Iterative Imputation Iteration              None\n",
      "22                         Numeric Imputer              mean\n",
      "23      Iterative Imputation Numeric Model              None\n",
      "24                     Categorical Imputer          constant\n",
      "25  Iterative Imputation Categorical Model              None\n",
      "26           Unknown Categoricals Handling    least_frequent\n",
      "27                               Normalize              True\n",
      "28                        Normalize Method            minmax\n",
      "29                          Transformation             False\n",
      "30                   Transformation Method              None\n",
      "31                                     PCA             False\n",
      "32                              PCA Method              None\n",
      "33                          PCA Components              None\n",
      "34                     Ignore Low Variance             False\n",
      "35                     Combine Rare Levels             False\n",
      "36                    Rare Level Threshold              None\n",
      "37                         Numeric Binning             False\n",
      "38                         Remove Outliers             False\n",
      "39                      Outliers Threshold              None\n",
      "40                Remove Multicollinearity             False\n",
      "41             Multicollinearity Threshold              None\n",
      "42                              Clustering             False\n",
      "43                    Clustering Iteration              None\n",
      "44                     Polynomial Features             False\n",
      "45                       Polynomial Degree              None\n",
      "46                    Trignometry Features             False\n",
      "47                    Polynomial Threshold              None\n",
      "48                          Group Features             False\n",
      "49                       Feature Selection             False\n",
      "50            Features Selection Threshold              None\n",
      "51                     Feature Interaction             False\n",
      "52                           Feature Ratio             False\n",
      "53                   Interaction Threshold              None\n",
      "54                        Transform Target             False\n",
      "55                 Transform Target Method           box-cox\n",
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.004428  0.000030  0.005452  0.428567  0.005402  0.490822\n",
      "1     0.003676  0.000020  0.004496  0.585566  0.004441  0.400999\n",
      "2     0.004016  0.000025  0.005048  0.513545  0.004959  0.439861\n",
      "3     0.003762  0.000023  0.004750  0.552273  0.004693  0.424561\n",
      "4     0.003656  0.000020  0.004521  0.591405  0.004480  0.383951\n",
      "5     0.003900  0.000023  0.004798  0.542523  0.004743  0.480470\n",
      "6     0.004272  0.000027  0.005214  0.455208  0.005157  0.469261\n",
      "7     0.003683  0.000022  0.004719  0.530577  0.004681  0.435163\n",
      "8     0.004106  0.000025  0.004997  0.453292  0.004953  0.464209\n",
      "9     0.004242  0.000028  0.005339  0.430228  0.005277  0.467636\n",
      "Mean  0.003974  0.000024  0.004933  0.508318  0.004879  0.445693\n",
      "SD    0.000267  0.000003  0.000314  0.058993  0.000311  0.033207\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:   22.1s\n",
      "[Parallel(n_jobs=-1)]: Done 482 tasks      | elapsed:   39.9s\n",
      "[Parallel(n_jobs=-1)]: Done 832 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1282 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1832 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.003886  0.000023  0.004755  0.565279  0.004712  0.400906\n",
      "1     0.003606  0.000019  0.004398  0.603586  0.004360  0.359253\n",
      "2     0.003973  0.000024  0.004892  0.543188  0.004847  0.381307\n",
      "3     0.003491  0.000018  0.004271  0.638007  0.004234  0.342616\n",
      "4     0.003667  0.000020  0.004491  0.596764  0.004452  0.336659\n",
      "5     0.003893  0.000022  0.004656  0.569163  0.004612  0.438578\n",
      "6     0.003730  0.000021  0.004556  0.584106  0.004517  0.389821\n",
      "7     0.003902  0.000021  0.004594  0.555057  0.004558  0.448085\n",
      "8     0.003770  0.000021  0.004530  0.550668  0.004492  0.385968\n",
      "9     0.003852  0.000022  0.004718  0.554975  0.004679  0.355682\n",
      "Mean  0.003777  0.000021  0.004586  0.576079  0.004546  0.383887\n",
      "SD    0.000145  0.000002  0.000171  0.028042  0.000169  0.035755\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.366, max_delta_step=0, max_depth=1,\n",
      "             min_child_weight=4, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=130, n_jobs=-1, num_parallel_tree=1,\n",
      "             objective='reg:squarederror', random_state=123, reg_alpha=0.0001,\n",
      "             reg_lambda=1e-07, scale_pos_weight=28.6, subsample=1,\n",
      "             tree_method='auto', validate_parameters=1, verbosity=0)\n",
      "Transformation Pipeline and Model Succesfully Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a89360b0a241a6a55fbffb78dac421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=\"Following data types have been inferred automatically, if they are correct press enter to continue"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cv</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Type\n",
       "0    Numeric\n",
       "1    Numeric\n",
       "2    Numeric\n",
       "3    Numeric\n",
       "4    Numeric\n",
       "5    Numeric\n",
       "6    Numeric\n",
       "7    Numeric\n",
       "8    Numeric\n",
       "9    Numeric\n",
       "10   Numeric\n",
       "11   Numeric\n",
       "12   Numeric\n",
       "13   Numeric\n",
       "14   Numeric\n",
       "15   Numeric\n",
       "16   Numeric\n",
       "17   Numeric\n",
       "18   Numeric\n",
       "19   Numeric\n",
       "20   Numeric\n",
       "21   Numeric\n",
       "22   Numeric\n",
       "23   Numeric\n",
       "24   Numeric\n",
       "25   Numeric\n",
       "26   Numeric\n",
       "27   Numeric\n",
       "28   Numeric\n",
       "29   Numeric\n",
       "30   Numeric\n",
       "31   Numeric\n",
       "32   Numeric\n",
       "33   Numeric\n",
       "34   Numeric\n",
       "35   Numeric\n",
       "36   Numeric\n",
       "37   Numeric\n",
       "38   Numeric\n",
       "39   Numeric\n",
       "40   Numeric\n",
       "41   Numeric\n",
       "42   Numeric\n",
       "43   Numeric\n",
       "44   Numeric\n",
       "45   Numeric\n",
       "46   Numeric\n",
       "47   Numeric\n",
       "48   Numeric\n",
       "49   Numeric\n",
       "50   Numeric\n",
       "51   Numeric\n",
       "cv     Label"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup Succesfully Completed!\n",
      "                               Description             Value\n",
      "0                               session_id               123\n",
      "1                                   Target                cv\n",
      "2                            Original Data        (2531, 53)\n",
      "3                           Missing Values             False\n",
      "4                         Numeric Features                52\n",
      "5                     Categorical Features                 0\n",
      "6                         Ordinal Features             False\n",
      "7                High Cardinality Features             False\n",
      "8                  High Cardinality Method              None\n",
      "9                    Transformed Train Set        (2277, 11)\n",
      "10                    Transformed Test Set         (254, 11)\n",
      "11                      Shuffle Train-Test              True\n",
      "12                     Stratify Train-Test             False\n",
      "13                          Fold Generator             KFold\n",
      "14                             Fold Number                10\n",
      "15                                CPU Jobs                -1\n",
      "16                                 Use GPU             False\n",
      "17                          Log Experiment             False\n",
      "18                         Experiment Name  reg-default-name\n",
      "19                                     USI              b2db\n",
      "20                         Imputation Type            simple\n",
      "21          Iterative Imputation Iteration              None\n",
      "22                         Numeric Imputer              mean\n",
      "23      Iterative Imputation Numeric Model              None\n",
      "24                     Categorical Imputer          constant\n",
      "25  Iterative Imputation Categorical Model              None\n",
      "26           Unknown Categoricals Handling    least_frequent\n",
      "27                               Normalize              True\n",
      "28                        Normalize Method            minmax\n",
      "29                          Transformation             False\n",
      "30                   Transformation Method              None\n",
      "31                                     PCA             False\n",
      "32                              PCA Method              None\n",
      "33                          PCA Components              None\n",
      "34                     Ignore Low Variance             False\n",
      "35                     Combine Rare Levels             False\n",
      "36                    Rare Level Threshold              None\n",
      "37                         Numeric Binning             False\n",
      "38                         Remove Outliers             False\n",
      "39                      Outliers Threshold              None\n",
      "40                Remove Multicollinearity             False\n",
      "41             Multicollinearity Threshold              None\n",
      "42                              Clustering             False\n",
      "43                    Clustering Iteration              None\n",
      "44                     Polynomial Features             False\n",
      "45                       Polynomial Degree              None\n",
      "46                    Trignometry Features             False\n",
      "47                    Polynomial Threshold              None\n",
      "48                          Group Features             False\n",
      "49                       Feature Selection             False\n",
      "50            Features Selection Threshold              None\n",
      "51                     Feature Interaction             False\n",
      "52                           Feature Ratio             False\n",
      "53                   Interaction Threshold              None\n",
      "54                        Transform Target             False\n",
      "55                 Transform Target Method           box-cox\n",
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.004064  0.000027  0.005152  0.504254  0.005101  0.423878\n",
      "1     0.004295  0.000030  0.005509  0.391566  0.005452  0.456266\n",
      "2     0.004622  0.000034  0.005827  0.403766  0.005774  0.494620\n",
      "3     0.004120  0.000027  0.005170  0.414031  0.005082  0.518447\n",
      "4     0.003954  0.000026  0.005060  0.470351  0.004974  0.513907\n",
      "5     0.004312  0.000031  0.005539  0.453886  0.005484  0.403249\n",
      "6     0.004157  0.000028  0.005246  0.486539  0.005184  0.453462\n",
      "7     0.004106  0.000028  0.005282  0.419724  0.005240  0.515179\n",
      "8     0.004165  0.000028  0.005244  0.463099  0.005183  0.416394\n",
      "9     0.004274  0.000028  0.005328  0.468445  0.005272  0.460966\n",
      "Mean  0.004207  0.000029  0.005336  0.447566  0.005275  0.465637\n",
      "SD    0.000174  0.000002  0.000217  0.035949  0.000224  0.040905\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=-1)]: Done 466 tasks      | elapsed:   50.6s\n",
      "[Parallel(n_jobs=-1)]: Done 816 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1266 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1816 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.003830  0.000022  0.004706  0.586359  0.004663  0.376820\n",
      "1     0.004089  0.000025  0.004971  0.504490  0.004927  0.411395\n",
      "2     0.004363  0.000029  0.005410  0.486009  0.005359  0.402909\n",
      "3     0.003774  0.000021  0.004602  0.535705  0.004563  0.426907\n",
      "4     0.003672  0.000020  0.004499  0.581290  0.004460  0.395153\n",
      "5     0.004356  0.000031  0.005602  0.441395  0.005545  0.362402\n",
      "6     0.004075  0.000024  0.004935  0.545738  0.004890  0.400750\n",
      "7     0.004064  0.000024  0.004870  0.506748  0.004829  0.761211\n",
      "8     0.003991  0.000024  0.004921  0.527314  0.004873  0.365757\n",
      "9     0.004147  0.000026  0.005053  0.522037  0.005005  0.404344\n",
      "Mean  0.004036  0.000025  0.004957  0.523708  0.004911  0.430765\n",
      "SD    0.000217  0.000003  0.000322  0.040914  0.000317  0.111820\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=0.7, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.042, max_delta_step=0, max_depth=2,\n",
      "             min_child_weight=3, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=270, n_jobs=-1, num_parallel_tree=1,\n",
      "             objective='reg:squarederror', random_state=123, reg_alpha=1e-06,\n",
      "             reg_lambda=0.01, scale_pos_weight=42.2, subsample=0.2,\n",
      "             tree_method='auto', validate_parameters=1, verbosity=0)\n",
      "Transformation Pipeline and Model Succesfully Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f19fb3de6544239d9918f6a761b1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=\"Following data types have been inferred automatically, if they are correct press enter to continue"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cv</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Type\n",
       "0    Numeric\n",
       "1    Numeric\n",
       "2    Numeric\n",
       "3    Numeric\n",
       "4    Numeric\n",
       "5    Numeric\n",
       "6    Numeric\n",
       "7    Numeric\n",
       "8    Numeric\n",
       "9    Numeric\n",
       "10   Numeric\n",
       "11   Numeric\n",
       "12   Numeric\n",
       "13   Numeric\n",
       "14   Numeric\n",
       "15   Numeric\n",
       "16   Numeric\n",
       "17   Numeric\n",
       "18   Numeric\n",
       "19   Numeric\n",
       "20   Numeric\n",
       "21   Numeric\n",
       "22   Numeric\n",
       "23   Numeric\n",
       "24   Numeric\n",
       "25   Numeric\n",
       "26   Numeric\n",
       "27   Numeric\n",
       "28   Numeric\n",
       "29   Numeric\n",
       "30   Numeric\n",
       "31   Numeric\n",
       "32   Numeric\n",
       "33   Numeric\n",
       "34   Numeric\n",
       "35   Numeric\n",
       "36   Numeric\n",
       "37   Numeric\n",
       "38   Numeric\n",
       "39   Numeric\n",
       "40   Numeric\n",
       "41   Numeric\n",
       "42   Numeric\n",
       "43   Numeric\n",
       "44   Numeric\n",
       "45   Numeric\n",
       "46   Numeric\n",
       "47   Numeric\n",
       "48   Numeric\n",
       "49   Numeric\n",
       "50   Numeric\n",
       "51   Numeric\n",
       "52   Numeric\n",
       "53   Numeric\n",
       "54   Numeric\n",
       "cv     Label"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup Succesfully Completed!\n",
      "                               Description             Value\n",
      "0                               session_id               123\n",
      "1                                   Target                cv\n",
      "2                            Original Data        (2949, 56)\n",
      "3                           Missing Values             False\n",
      "4                         Numeric Features                55\n",
      "5                     Categorical Features                 0\n",
      "6                         Ordinal Features             False\n",
      "7                High Cardinality Features             False\n",
      "8                  High Cardinality Method              None\n",
      "9                    Transformed Train Set         (2654, 8)\n",
      "10                    Transformed Test Set          (295, 8)\n",
      "11                      Shuffle Train-Test              True\n",
      "12                     Stratify Train-Test             False\n",
      "13                          Fold Generator             KFold\n",
      "14                             Fold Number                10\n",
      "15                                CPU Jobs                -1\n",
      "16                                 Use GPU             False\n",
      "17                          Log Experiment             False\n",
      "18                         Experiment Name  reg-default-name\n",
      "19                                     USI              e3a1\n",
      "20                         Imputation Type            simple\n",
      "21          Iterative Imputation Iteration              None\n",
      "22                         Numeric Imputer              mean\n",
      "23      Iterative Imputation Numeric Model              None\n",
      "24                     Categorical Imputer          constant\n",
      "25  Iterative Imputation Categorical Model              None\n",
      "26           Unknown Categoricals Handling    least_frequent\n",
      "27                               Normalize              True\n",
      "28                        Normalize Method            minmax\n",
      "29                          Transformation             False\n",
      "30                   Transformation Method              None\n",
      "31                                     PCA             False\n",
      "32                              PCA Method              None\n",
      "33                          PCA Components              None\n",
      "34                     Ignore Low Variance             False\n",
      "35                     Combine Rare Levels             False\n",
      "36                    Rare Level Threshold              None\n",
      "37                         Numeric Binning             False\n",
      "38                         Remove Outliers             False\n",
      "39                      Outliers Threshold              None\n",
      "40                Remove Multicollinearity             False\n",
      "41             Multicollinearity Threshold              None\n",
      "42                              Clustering             False\n",
      "43                    Clustering Iteration              None\n",
      "44                     Polynomial Features             False\n",
      "45                       Polynomial Degree              None\n",
      "46                    Trignometry Features             False\n",
      "47                    Polynomial Threshold              None\n",
      "48                          Group Features             False\n",
      "49                       Feature Selection             False\n",
      "50            Features Selection Threshold              None\n",
      "51                     Feature Interaction             False\n",
      "52                           Feature Ratio             False\n",
      "53                   Interaction Threshold              None\n",
      "54                        Transform Target             False\n",
      "55                 Transform Target Method           box-cox\n",
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.005080  0.000037  0.006098  0.433528  0.006032  0.459589\n",
      "1     0.004753  0.000035  0.005901  0.347983  0.005844  0.504576\n",
      "2     0.004762  0.000035  0.005933  0.313106  0.005877  0.491811\n",
      "3     0.004569  0.000031  0.005608  0.450370  0.005554  0.464042\n",
      "4     0.005003  0.000036  0.006039  0.334148  0.005981  0.548774\n",
      "5     0.004493  0.000031  0.005524  0.355184  0.005466  0.462377\n",
      "6     0.004349  0.000031  0.005586  0.431421  0.005532  0.479106\n",
      "7     0.004732  0.000034  0.005797  0.328265  0.005739  0.536378\n",
      "8     0.004775  0.000036  0.005964  0.325706  0.005907  0.497359\n",
      "9     0.004770  0.000034  0.005848  0.396916  0.005772  0.517056\n",
      "Mean  0.004729  0.000034  0.005830  0.371663  0.005771  0.496107\n",
      "SD    0.000207  0.000002  0.000188  0.048882  0.000186  0.029520\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done 466 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=-1)]: Done 816 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1266 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1816 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  4.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.004553  0.000029  0.005425  0.551779  0.005370  0.394740\n",
      "1     0.004672  0.000032  0.005655  0.401328  0.005599  0.441285\n",
      "2     0.004597  0.000031  0.005591  0.389995  0.005539  0.434428\n",
      "3     0.004470  0.000029  0.005356  0.498622  0.005300  0.434388\n",
      "4     0.004661  0.000032  0.005623  0.422676  0.005568  0.458175\n",
      "5     0.004399  0.000029  0.005358  0.393254  0.005308  0.416704\n",
      "6     0.004226  0.000027  0.005210  0.505454  0.005158  0.421218\n",
      "7     0.004519  0.000028  0.005336  0.430838  0.005290  0.440070\n",
      "8     0.004644  0.000033  0.005703  0.383398  0.005651  0.406757\n",
      "9     0.004462  0.000029  0.005393  0.487023  0.005341  0.418225\n",
      "Mean  0.004520  0.000030  0.005465  0.446437  0.005412  0.426599\n",
      "SD    0.000131  0.000002  0.000157  0.056375  0.000156  0.017669\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=0.7, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.042, max_delta_step=0, max_depth=2,\n",
      "             min_child_weight=3, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=270, n_jobs=-1, num_parallel_tree=1,\n",
      "             objective='reg:squarederror', random_state=123, reg_alpha=1e-06,\n",
      "             reg_lambda=0.01, scale_pos_weight=42.2, subsample=0.2,\n",
      "             tree_method='auto', validate_parameters=1, verbosity=0)\n",
      "Transformation Pipeline and Model Succesfully Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4e516844184672a9a63808e3a33e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=\"Following data types have been inferred automatically, if they are correct press enter to continue"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>Numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cv</td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Type\n",
       "0    Numeric\n",
       "1    Numeric\n",
       "2    Numeric\n",
       "3    Numeric\n",
       "4    Numeric\n",
       "5    Numeric\n",
       "6    Numeric\n",
       "7    Numeric\n",
       "8    Numeric\n",
       "9    Numeric\n",
       "10   Numeric\n",
       "11   Numeric\n",
       "12   Numeric\n",
       "13   Numeric\n",
       "14   Numeric\n",
       "15   Numeric\n",
       "16   Numeric\n",
       "17   Numeric\n",
       "18   Numeric\n",
       "19   Numeric\n",
       "20   Numeric\n",
       "21   Numeric\n",
       "22   Numeric\n",
       "23   Numeric\n",
       "24   Numeric\n",
       "25   Numeric\n",
       "26   Numeric\n",
       "27   Numeric\n",
       "28   Numeric\n",
       "29   Numeric\n",
       "30   Numeric\n",
       "31   Numeric\n",
       "32   Numeric\n",
       "33   Numeric\n",
       "34   Numeric\n",
       "35   Numeric\n",
       "36   Numeric\n",
       "37   Numeric\n",
       "38   Numeric\n",
       "39   Numeric\n",
       "40   Numeric\n",
       "41   Numeric\n",
       "42   Numeric\n",
       "43   Numeric\n",
       "44   Numeric\n",
       "45   Numeric\n",
       "46   Numeric\n",
       "47   Numeric\n",
       "48   Numeric\n",
       "49   Numeric\n",
       "50   Numeric\n",
       "51   Numeric\n",
       "52   Numeric\n",
       "53   Numeric\n",
       "54   Numeric\n",
       "55   Numeric\n",
       "56   Numeric\n",
       "57   Numeric\n",
       "cv     Label"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup Succesfully Completed!\n",
      "                               Description             Value\n",
      "0                               session_id               123\n",
      "1                                   Target                cv\n",
      "2                            Original Data        (3540, 59)\n",
      "3                           Missing Values             False\n",
      "4                         Numeric Features                58\n",
      "5                     Categorical Features                 0\n",
      "6                         Ordinal Features             False\n",
      "7                High Cardinality Features             False\n",
      "8                  High Cardinality Method              None\n",
      "9                    Transformed Train Set         (3186, 6)\n",
      "10                    Transformed Test Set          (354, 6)\n",
      "11                      Shuffle Train-Test              True\n",
      "12                     Stratify Train-Test             False\n",
      "13                          Fold Generator             KFold\n",
      "14                             Fold Number                10\n",
      "15                                CPU Jobs                -1\n",
      "16                                 Use GPU             False\n",
      "17                          Log Experiment             False\n",
      "18                         Experiment Name  reg-default-name\n",
      "19                                     USI              78a8\n",
      "20                         Imputation Type            simple\n",
      "21          Iterative Imputation Iteration              None\n",
      "22                         Numeric Imputer              mean\n",
      "23      Iterative Imputation Numeric Model              None\n",
      "24                     Categorical Imputer          constant\n",
      "25  Iterative Imputation Categorical Model              None\n",
      "26           Unknown Categoricals Handling    least_frequent\n",
      "27                               Normalize              True\n",
      "28                        Normalize Method            minmax\n",
      "29                          Transformation             False\n",
      "30                   Transformation Method              None\n",
      "31                                     PCA             False\n",
      "32                              PCA Method              None\n",
      "33                          PCA Components              None\n",
      "34                     Ignore Low Variance             False\n",
      "35                     Combine Rare Levels             False\n",
      "36                    Rare Level Threshold              None\n",
      "37                         Numeric Binning             False\n",
      "38                         Remove Outliers             False\n",
      "39                      Outliers Threshold              None\n",
      "40                Remove Multicollinearity             False\n",
      "41             Multicollinearity Threshold              None\n",
      "42                              Clustering             False\n",
      "43                    Clustering Iteration              None\n",
      "44                     Polynomial Features             False\n",
      "45                       Polynomial Degree              None\n",
      "46                    Trignometry Features             False\n",
      "47                    Polynomial Threshold              None\n",
      "48                          Group Features             False\n",
      "49                       Feature Selection             False\n",
      "50            Features Selection Threshold              None\n",
      "51                     Feature Interaction             False\n",
      "52                           Feature Ratio             False\n",
      "53                   Interaction Threshold              None\n",
      "54                        Transform Target             False\n",
      "55                 Transform Target Method           box-cox\n",
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.005136  0.000039  0.006231  0.314942  0.006168  0.444121\n",
      "1     0.005269  0.000044  0.006622  0.261966  0.006556  0.443275\n",
      "2     0.005459  0.000044  0.006665  0.180594  0.006583  0.512543\n",
      "3     0.004972  0.000039  0.006255  0.264630  0.006190  0.566830\n",
      "4     0.005334  0.000045  0.006712  0.251594  0.006625  0.478442\n",
      "5     0.005430  0.000044  0.006657  0.231016  0.006593  0.471042\n",
      "6     0.004672  0.000034  0.005850  0.325002  0.005794  0.459126\n",
      "7     0.004870  0.000038  0.006162  0.330499  0.006091  0.485027\n",
      "8     0.005159  0.000043  0.006568  0.232766  0.006494  0.478593\n",
      "9     0.004944  0.000039  0.006262  0.306550  0.006193  0.486151\n",
      "Mean  0.005124  0.000041  0.006399  0.269956  0.006329  0.482515\n",
      "SD    0.000244  0.000003  0.000272  0.046231  0.000266  0.034285\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=-1)]: Done 466 tasks      | elapsed:   57.8s\n",
      "[Parallel(n_jobs=-1)]: Done 816 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1266 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1816 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE       MSE      RMSE        R2     RMSLE      MAPE\n",
      "0     0.005001  0.000036  0.006025  0.359437  0.005964  0.407159\n",
      "1     0.004934  0.000038  0.006128  0.368003  0.006067  0.395627\n",
      "2     0.004779  0.000035  0.005937  0.349902  0.005877  0.406062\n",
      "3     0.004809  0.000036  0.005976  0.328930  0.005918  0.482281\n",
      "4     0.005355  0.000042  0.006510  0.296054  0.006442  0.450607\n",
      "5     0.004934  0.000036  0.005989  0.377571  0.005930  0.410808\n",
      "6     0.004489  0.000030  0.005472  0.409454  0.005420  0.413787\n",
      "7     0.004629  0.000031  0.005602  0.446595  0.005547  0.420985\n",
      "8     0.004965  0.000036  0.006039  0.351366  0.005979  0.429973\n",
      "9     0.004795  0.000035  0.005927  0.378850  0.005869  0.445525\n",
      "Mean  0.004869  0.000036  0.005960  0.366616  0.005901  0.426281\n",
      "SD    0.000221  0.000003  0.000267  0.039327  0.000263  0.024999\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=0.9, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.212, max_delta_step=0, max_depth=3,\n",
      "             min_child_weight=3, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=70, n_jobs=-1, num_parallel_tree=1,\n",
      "             objective='reg:squarederror', random_state=123, reg_alpha=0.01,\n",
      "             reg_lambda=5, scale_pos_weight=4.800000000000001, subsample=0.5,\n",
      "             tree_method='auto', validate_parameters=1, verbosity=0)\n",
      "Transformation Pipeline and Model Succesfully Saved\n",
      "Wall time: 38min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prc_xgb=Bermudan_swaption_xgboost(lockout,maturity,sim_rates,strike,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European swaption pirce: 0.006939140046653583\n"
     ]
    }
   ],
   "source": [
    "print('European swaption pirce: {}'.format(prc_xgb[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bermudan swaption pirce: 0.007626313294723181\n"
     ]
    }
   ],
   "source": [
    "print('Bermudan swaption pirce: {}'.format(prc_xgb[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excercise Probability Table\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_step</th>\n",
       "      <th>ex_prob_Euro</th>\n",
       "      <th>ex_prob_xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.4952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Time_step  ex_prob_Euro  ex_prob_xgb\n",
       "0           2         0.708       0.4952\n",
       "1           3         0.000       0.0854\n",
       "2           4         0.000       0.0386\n",
       "3           5         0.000       0.0150\n",
       "4           6         0.000       0.0104\n",
       "5           7         0.000       0.0070\n",
       "6           8         0.000       0.0084\n",
       "7           9         0.000       0.0086\n",
       "8          10         0.000       0.0058\n",
       "9          11         0.000       0.0040\n",
       "10         12         0.000       0.0032\n",
       "11         13         0.000       0.0044\n",
       "12         14         0.000       0.0038\n",
       "13         15         0.000       0.0046\n",
       "14         16         0.000       0.0042\n",
       "15         17         0.000       0.0062\n",
       "16         18         0.000       0.0066\n",
       "17         19         0.000       0.0098"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Excercise Probability Table')\n",
    "prc_xgb[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prc_xgb_fixed=Bermudan_swaption_xgboost_fixed(lockout,maturity,sim_rates,strike,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bermudan swaption pirce: 0.007768905718105953\n",
      "Excercise Probability Table\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_step</th>\n",
       "      <th>ex_prob_Euro</th>\n",
       "      <th>ex_prob_xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.5708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Time_step  ex_prob_Euro  ex_prob_xgb\n",
       "0           2         0.708       0.5708\n",
       "1           3         0.000       0.0844\n",
       "2           4         0.000       0.0308\n",
       "3           5         0.000       0.0142\n",
       "4           6         0.000       0.0090\n",
       "5           7         0.000       0.0048\n",
       "6           8         0.000       0.0052\n",
       "7           9         0.000       0.0054\n",
       "8          10         0.000       0.0048\n",
       "9          11         0.000       0.0024\n",
       "10         12         0.000       0.0038\n",
       "11         13         0.000       0.0036\n",
       "12         14         0.000       0.0040\n",
       "13         15         0.000       0.0042\n",
       "14         16         0.000       0.0036\n",
       "15         17         0.000       0.0040\n",
       "16         18         0.000       0.0058\n",
       "17         19         0.000       0.0062"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Bermudan swaption pirce: {}'.format(prc_xgb_fixed[1]))\n",
    "print('Excercise Probability Table')\n",
    "prc_xgb_fixed[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last time, our initial price from XGBoost is around 0.0090, much higher than this time, but closer to the estimated values from 50K and 100K simulation. Since it's so time consuming to tune the model at each time step, and the value is pretty close to the price attained from fixed parameter model, we will use the fixed model in the following step. As we did last week, we will simulate more paths to see the difference between each model. Then we will compare 'regress now' and 'regress later'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>European price</th>\n",
       "      <th>Bermudan price</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LSM</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>271 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>0.008788</td>\n",
       "      <td>39.4 s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>XGBoost_tuned</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>0.007626</td>\n",
       "      <td>38min23s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>XGBoost_fixed</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>0.007769</td>\n",
       "      <td>1.2 s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Algorithm   European price   Bermudan price       Time\n",
       "0            LSM         0.006939         0.007563     271 ms\n",
       "1             NN         0.006939         0.008788     39.4 s\n",
       "2  XGBoost_tuned         0.006939         0.007626  38min23s \n",
       "3  XGBoost_fixed         0.006939         0.007769      1.2 s"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_5000=pd.DataFrame({'Algorithm':['LSM','NN','XGBoost_tuned','XGBoost_fixed'],\n",
    "                          ' European price': [prc_lsm[0],prc_nn[0],prc_xgb[0],prc_xgb_fixed[0]],\n",
    "                          ' Bermudan price': [prc_lsm[1],prc_nn[1],0.007626313294723181,prc_xgb_fixed[1]],\n",
    "                          ' Time':['271 ms','39.4 s','38min23s ','1.2 s' ]})\n",
    "output_5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some output functions\n",
    "def print_result(prc):\n",
    "    print('European swaption pirce: {}'.format(prc[0]))\n",
    "    print('Bermudan swaption pirce: {}'.format(prc[1]))\n",
    "    print('Excercise Probability Table')\n",
    "    print(prc[2])\n",
    "    \n",
    "def make_table(prc_lsm,prc_nn,prc_xgb):\n",
    "    output=pd.DataFrame({'Algorithm':['LSM','NN','XGBoost'],\n",
    "                          ' European price': [prc_lsm[0],prc_nn[0],prc_xgb[0]],\n",
    "                          ' Bermudan price': [prc_lsm[1],prc_nn[1],prc_xgb[1]]})\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 439 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prc_lsm_10k=Bermudan_swaption_lsm(lockout,maturity,sim_rates_10k,strike,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European swaption pirce: 0.006946037983725924\n",
      "Bermudan swaption pirce: 0.007548136794892565\n",
      "Excercise Probability Table\n",
      "    Time_step  ex_prob_Euro  ex_prob_LSM\n",
      "0           2        0.7087       0.4488\n",
      "1           3        0.0000       0.0644\n",
      "2           4        0.0000       0.0287\n",
      "3           5        0.0000       0.0161\n",
      "4           6        0.0000       0.0111\n",
      "5           7        0.0000       0.0084\n",
      "6           8        0.0000       0.0048\n",
      "7           9        0.0000       0.0044\n",
      "8          10        0.0000       0.0042\n",
      "9          11        0.0000       0.0036\n",
      "10         12        0.0000       0.0045\n",
      "11         13        0.0000       0.0059\n",
      "12         14        0.0000       0.0051\n",
      "13         15        0.0000       0.0055\n",
      "14         16        0.0000       0.0050\n",
      "15         17        0.0000       0.0086\n",
      "16         18        0.0000       0.0162\n",
      "17         19        0.0000       0.0120\n"
     ]
    }
   ],
   "source": [
    "print_result(prc_lsm_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 18\n",
      "Epoch 1/30, train_loss: 0.00959, valid_loss: 0.00142\n",
      "Epoch 2/30, train_loss: 0.00686, valid_loss: 0.00123\n",
      "Epoch 3/30, train_loss: 0.00562, valid_loss: 0.00109\n",
      "Epoch 4/30, train_loss: 0.00488, valid_loss: 0.00102\n",
      "Epoch 5/30, train_loss: 0.00438, valid_loss: 0.00097\n",
      "Epoch 6/30, train_loss: 0.00401, valid_loss: 0.00094\n",
      "Epoch 7/30, train_loss: 0.00373, valid_loss: 0.00094\n",
      "Epoch 8/30, train_loss: 0.00350, valid_loss: 0.00092\n",
      "Epoch 9/30, train_loss: 0.00331, valid_loss: 0.00090\n",
      "Epoch 10/30, train_loss: 0.00315, valid_loss: 0.00089\n",
      "Epoch 11/30, train_loss: 0.00301, valid_loss: 0.00088\n",
      "Epoch 12/30, train_loss: 0.00289, valid_loss: 0.00089\n",
      "Epoch 13/30, train_loss: 0.00278, valid_loss: 0.00088\n",
      "Epoch 14/30, train_loss: 0.00269, valid_loss: 0.00088\n",
      "Epoch 15/30, train_loss: 0.00261, valid_loss: 0.00087\n",
      "Epoch 16/30, train_loss: 0.00253, valid_loss: 0.00086\n",
      "Epoch 17/30, train_loss: 0.00246, valid_loss: 0.00085\n",
      "Epoch 18/30, train_loss: 0.00240, valid_loss: 0.00087\n",
      "Epoch 19/30, train_loss: 0.00235, valid_loss: 0.00086\n",
      "Epoch 20/30, train_loss: 0.00229, valid_loss: 0.00086\n",
      "Epoch 21/30, train_loss: 0.00225, valid_loss: 0.00085\n",
      "Epoch 22/30, train_loss: 0.00220, valid_loss: 0.00085\n",
      "Epoch 23/30, train_loss: 0.00216, valid_loss: 0.00085\n",
      "Epoch 24/30, train_loss: 0.00212, valid_loss: 0.00085\n",
      "Epoch 25/30, train_loss: 0.00209, valid_loss: 0.00085\n",
      "Epoch 26/30, train_loss: 0.00206, valid_loss: 0.00086\n",
      "Epoch 27/30, train_loss: 0.00202, valid_loss: 0.00087\n",
      "Epoch 28/30, train_loss: 0.00199, valid_loss: 0.00086\n",
      "Epoch 29/30, train_loss: 0.00196, valid_loss: 0.00086\n",
      "Epoch 30/30, train_loss: 0.00194, valid_loss: 0.00086\n",
      "At step 17\n",
      "Epoch 1/30, train_loss: 0.01110, valid_loss: 0.00349\n",
      "Epoch 2/30, train_loss: 0.00801, valid_loss: 0.00267\n",
      "Epoch 3/30, train_loss: 0.00660, valid_loss: 0.00236\n",
      "Epoch 4/30, train_loss: 0.00576, valid_loss: 0.00220\n",
      "Epoch 5/30, train_loss: 0.00520, valid_loss: 0.00208\n",
      "Epoch 6/30, train_loss: 0.00478, valid_loss: 0.00201\n",
      "Epoch 7/30, train_loss: 0.00446, valid_loss: 0.00194\n",
      "Epoch 8/30, train_loss: 0.00421, valid_loss: 0.00188\n",
      "Epoch 9/30, train_loss: 0.00401, valid_loss: 0.00184\n",
      "Epoch 10/30, train_loss: 0.00383, valid_loss: 0.00180\n",
      "Epoch 11/30, train_loss: 0.00368, valid_loss: 0.00178\n",
      "Epoch 12/30, train_loss: 0.00354, valid_loss: 0.00176\n",
      "Epoch 13/30, train_loss: 0.00343, valid_loss: 0.00175\n",
      "Epoch 14/30, train_loss: 0.00333, valid_loss: 0.00176\n",
      "Epoch 15/30, train_loss: 0.00325, valid_loss: 0.00175\n",
      "Epoch 16/30, train_loss: 0.00318, valid_loss: 0.00180\n",
      "Epoch 17/30, train_loss: 0.00311, valid_loss: 0.00178\n",
      "Epoch 18/30, train_loss: 0.00304, valid_loss: 0.00178\n",
      "Epoch 19/30, train_loss: 0.00298, valid_loss: 0.00177\n",
      "Epoch 20/30, train_loss: 0.00292, valid_loss: 0.00179\n",
      "Epoch 21/30, train_loss: 0.00287, valid_loss: 0.00178\n",
      "Epoch 22/30, train_loss: 0.00282, valid_loss: 0.00176\n",
      "Epoch 23/30, train_loss: 0.00278, valid_loss: 0.00176\n",
      "Epoch 24/30, train_loss: 0.00274, valid_loss: 0.00174\n",
      "Epoch 25/30, train_loss: 0.00270, valid_loss: 0.00174\n",
      "Epoch 26/30, train_loss: 0.00267, valid_loss: 0.00173\n",
      "Epoch 27/30, train_loss: 0.00263, valid_loss: 0.00173\n",
      "Epoch 28/30, train_loss: 0.00260, valid_loss: 0.00174\n",
      "Epoch 29/30, train_loss: 0.00257, valid_loss: 0.00173\n",
      "Epoch 30/30, train_loss: 0.00255, valid_loss: 0.00172\n",
      "At step 16\n",
      "Epoch 1/30, train_loss: 0.00989, valid_loss: 0.00467\n",
      "Epoch 2/30, train_loss: 0.00726, valid_loss: 0.00382\n",
      "Epoch 3/30, train_loss: 0.00607, valid_loss: 0.00343\n",
      "Epoch 4/30, train_loss: 0.00538, valid_loss: 0.00320\n",
      "Epoch 5/30, train_loss: 0.00492, valid_loss: 0.00305\n",
      "Epoch 6/30, train_loss: 0.00459, valid_loss: 0.00293\n",
      "Epoch 7/30, train_loss: 0.00433, valid_loss: 0.00295\n",
      "Epoch 8/30, train_loss: 0.00413, valid_loss: 0.00288\n",
      "Epoch 9/30, train_loss: 0.00396, valid_loss: 0.00282\n",
      "Epoch 10/30, train_loss: 0.00382, valid_loss: 0.00279\n",
      "Epoch 11/30, train_loss: 0.00371, valid_loss: 0.00275\n",
      "Epoch 12/30, train_loss: 0.00362, valid_loss: 0.00271\n",
      "Epoch 13/30, train_loss: 0.00353, valid_loss: 0.00269\n",
      "Epoch 14/30, train_loss: 0.00345, valid_loss: 0.00267\n",
      "Epoch 15/30, train_loss: 0.00338, valid_loss: 0.00265\n",
      "Epoch 16/30, train_loss: 0.00332, valid_loss: 0.00262\n",
      "Epoch 17/30, train_loss: 0.00327, valid_loss: 0.00266\n",
      "Epoch 18/30, train_loss: 0.00324, valid_loss: 0.00270\n",
      "Epoch 19/30, train_loss: 0.00320, valid_loss: 0.00268\n",
      "Epoch 20/30, train_loss: 0.00316, valid_loss: 0.00266\n",
      "Epoch 21/30, train_loss: 0.00312, valid_loss: 0.00272\n",
      "Epoch 22/30, train_loss: 0.00309, valid_loss: 0.00270\n",
      "Epoch 23/30, train_loss: 0.00306, valid_loss: 0.00273\n",
      "Epoch 24/30, train_loss: 0.00303, valid_loss: 0.00277\n",
      "Epoch 25/30, train_loss: 0.00301, valid_loss: 0.00275\n",
      "Epoch 26/30, train_loss: 0.00299, valid_loss: 0.00272\n",
      "Epoch 27/30, train_loss: 0.00296, valid_loss: 0.00274\n",
      "Epoch 28/30, train_loss: 0.00294, valid_loss: 0.00273\n",
      "Epoch 29/30, train_loss: 0.00294, valid_loss: 0.00272\n",
      "Epoch 30/30, train_loss: 0.00293, valid_loss: 0.00278\n",
      "At step 15\n",
      "Epoch 1/30, train_loss: 0.02148, valid_loss: 0.00921\n",
      "Epoch 2/30, train_loss: 0.01550, valid_loss: 0.00682\n",
      "Epoch 3/30, train_loss: 0.01275, valid_loss: 0.00582\n",
      "Epoch 4/30, train_loss: 0.01113, valid_loss: 0.00524\n",
      "Epoch 5/30, train_loss: 0.01003, valid_loss: 0.00488\n",
      "Epoch 6/30, train_loss: 0.00922, valid_loss: 0.00461\n",
      "Epoch 7/30, train_loss: 0.00860, valid_loss: 0.00440\n",
      "Epoch 8/30, train_loss: 0.00810, valid_loss: 0.00424\n",
      "Epoch 9/30, train_loss: 0.00769, valid_loss: 0.00411\n",
      "Epoch 10/30, train_loss: 0.00734, valid_loss: 0.00404\n",
      "Epoch 11/30, train_loss: 0.00705, valid_loss: 0.00394\n",
      "Epoch 12/30, train_loss: 0.00679, valid_loss: 0.00386\n",
      "Epoch 13/30, train_loss: 0.00657, valid_loss: 0.00382\n",
      "Epoch 14/30, train_loss: 0.00637, valid_loss: 0.00376\n",
      "Epoch 15/30, train_loss: 0.00620, valid_loss: 0.00371\n",
      "Epoch 16/30, train_loss: 0.00604, valid_loss: 0.00366\n",
      "Epoch 17/30, train_loss: 0.00590, valid_loss: 0.00367\n",
      "Epoch 18/30, train_loss: 0.00577, valid_loss: 0.00362\n",
      "Epoch 19/30, train_loss: 0.00565, valid_loss: 0.00360\n",
      "Epoch 20/30, train_loss: 0.00554, valid_loss: 0.00358\n",
      "Epoch 21/30, train_loss: 0.00544, valid_loss: 0.00355\n",
      "Epoch 22/30, train_loss: 0.00534, valid_loss: 0.00352\n",
      "Epoch 23/30, train_loss: 0.00526, valid_loss: 0.00350\n",
      "Epoch 24/30, train_loss: 0.00518, valid_loss: 0.00348\n",
      "Epoch 25/30, train_loss: 0.00510, valid_loss: 0.00345\n",
      "Epoch 26/30, train_loss: 0.00503, valid_loss: 0.00343\n",
      "Epoch 27/30, train_loss: 0.00496, valid_loss: 0.00340\n",
      "Epoch 28/30, train_loss: 0.00490, valid_loss: 0.00338\n",
      "Epoch 29/30, train_loss: 0.00485, valid_loss: 0.00336\n",
      "Epoch 30/30, train_loss: 0.00479, valid_loss: 0.00336\n",
      "At step 14\n",
      "Epoch 1/30, train_loss: 0.01596, valid_loss: 0.00375\n",
      "Epoch 2/30, train_loss: 0.01161, valid_loss: 0.00353\n",
      "Epoch 3/30, train_loss: 0.00967, valid_loss: 0.00343\n",
      "Epoch 4/30, train_loss: 0.00854, valid_loss: 0.00339\n",
      "Epoch 5/30, train_loss: 0.00777, valid_loss: 0.00338\n",
      "Epoch 6/30, train_loss: 0.00723, valid_loss: 0.00337\n",
      "Epoch 7/30, train_loss: 0.00681, valid_loss: 0.00335\n",
      "Epoch 8/30, train_loss: 0.00647, valid_loss: 0.00335\n",
      "Epoch 9/30, train_loss: 0.00620, valid_loss: 0.00335\n",
      "Epoch 10/30, train_loss: 0.00598, valid_loss: 0.00334\n",
      "Epoch 11/30, train_loss: 0.00579, valid_loss: 0.00335\n",
      "Epoch 12/30, train_loss: 0.00562, valid_loss: 0.00334\n",
      "Epoch 13/30, train_loss: 0.00548, valid_loss: 0.00333\n",
      "Epoch 14/30, train_loss: 0.00536, valid_loss: 0.00333\n",
      "Epoch 15/30, train_loss: 0.00525, valid_loss: 0.00333\n",
      "Epoch 16/30, train_loss: 0.00515, valid_loss: 0.00332\n",
      "Epoch 17/30, train_loss: 0.00505, valid_loss: 0.00334\n",
      "Epoch 18/30, train_loss: 0.00497, valid_loss: 0.00334\n",
      "Epoch 19/30, train_loss: 0.00490, valid_loss: 0.00334\n",
      "Epoch 20/30, train_loss: 0.00483, valid_loss: 0.00334\n",
      "Epoch 21/30, train_loss: 0.00477, valid_loss: 0.00334\n",
      "Epoch 22/30, train_loss: 0.00471, valid_loss: 0.00335\n",
      "Epoch 23/30, train_loss: 0.00466, valid_loss: 0.00335\n",
      "Epoch 24/30, train_loss: 0.00461, valid_loss: 0.00334\n",
      "Epoch 25/30, train_loss: 0.00457, valid_loss: 0.00335\n",
      "Epoch 26/30, train_loss: 0.00452, valid_loss: 0.00334\n",
      "Epoch 27/30, train_loss: 0.00448, valid_loss: 0.00334\n",
      "Epoch 28/30, train_loss: 0.00444, valid_loss: 0.00334\n",
      "Epoch 29/30, train_loss: 0.00441, valid_loss: 0.00334\n",
      "Epoch 30/30, train_loss: 0.00438, valid_loss: 0.00333\n",
      "At step 13\n",
      "Epoch 1/30, train_loss: 0.01761, valid_loss: 0.00535\n",
      "Epoch 2/30, train_loss: 0.01291, valid_loss: 0.00489\n",
      "Epoch 3/30, train_loss: 0.01085, valid_loss: 0.00480\n",
      "Epoch 4/30, train_loss: 0.00965, valid_loss: 0.00469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, train_loss: 0.00885, valid_loss: 0.00460\n",
      "Epoch 6/30, train_loss: 0.00830, valid_loss: 0.00466\n",
      "Epoch 7/30, train_loss: 0.00790, valid_loss: 0.00467\n",
      "Epoch 8/30, train_loss: 0.00755, valid_loss: 0.00464\n",
      "Epoch 9/30, train_loss: 0.00726, valid_loss: 0.00463\n",
      "Epoch 10/30, train_loss: 0.00702, valid_loss: 0.00459\n",
      "Epoch 11/30, train_loss: 0.00683, valid_loss: 0.00457\n",
      "Epoch 12/30, train_loss: 0.00665, valid_loss: 0.00453\n",
      "Epoch 13/30, train_loss: 0.00649, valid_loss: 0.00451\n",
      "Epoch 14/30, train_loss: 0.00635, valid_loss: 0.00449\n",
      "Epoch 15/30, train_loss: 0.00624, valid_loss: 0.00451\n",
      "Epoch 16/30, train_loss: 0.00615, valid_loss: 0.00467\n",
      "Epoch 17/30, train_loss: 0.00608, valid_loss: 0.00469\n",
      "Epoch 18/30, train_loss: 0.00601, valid_loss: 0.00466\n",
      "Epoch 19/30, train_loss: 0.00593, valid_loss: 0.00465\n",
      "Epoch 20/30, train_loss: 0.00585, valid_loss: 0.00472\n",
      "Epoch 21/30, train_loss: 0.00578, valid_loss: 0.00469\n",
      "Epoch 22/30, train_loss: 0.00572, valid_loss: 0.00468\n",
      "Epoch 23/30, train_loss: 0.00566, valid_loss: 0.00465\n",
      "Epoch 24/30, train_loss: 0.00561, valid_loss: 0.00463\n",
      "Epoch 25/30, train_loss: 0.00555, valid_loss: 0.00460\n",
      "Epoch 26/30, train_loss: 0.00550, valid_loss: 0.00461\n",
      "Epoch 27/30, train_loss: 0.00546, valid_loss: 0.00460\n",
      "Epoch 28/30, train_loss: 0.00542, valid_loss: 0.00462\n",
      "Epoch 29/30, train_loss: 0.00539, valid_loss: 0.00464\n",
      "Epoch 30/30, train_loss: 0.00536, valid_loss: 0.00466\n",
      "At step 12\n",
      "Epoch 1/30, train_loss: 0.01309, valid_loss: 0.00754\n",
      "Epoch 2/30, train_loss: 0.01003, valid_loss: 0.00637\n",
      "Epoch 3/30, train_loss: 0.00863, valid_loss: 0.00622\n",
      "Epoch 4/30, train_loss: 0.00786, valid_loss: 0.00620\n",
      "Epoch 5/30, train_loss: 0.00737, valid_loss: 0.00595\n",
      "Epoch 6/30, train_loss: 0.00700, valid_loss: 0.00581\n",
      "Epoch 7/30, train_loss: 0.00672, valid_loss: 0.00579\n",
      "Epoch 8/30, train_loss: 0.00650, valid_loss: 0.00569\n",
      "Epoch 9/30, train_loss: 0.00633, valid_loss: 0.00562\n",
      "Epoch 10/30, train_loss: 0.00623, valid_loss: 0.00598\n",
      "Epoch 11/30, train_loss: 0.00618, valid_loss: 0.00589\n",
      "Epoch 12/30, train_loss: 0.00608, valid_loss: 0.00579\n",
      "Epoch 13/30, train_loss: 0.00599, valid_loss: 0.00571\n",
      "Epoch 14/30, train_loss: 0.00591, valid_loss: 0.00563\n",
      "Epoch 15/30, train_loss: 0.00583, valid_loss: 0.00557\n",
      "Epoch 16/30, train_loss: 0.00577, valid_loss: 0.00551\n",
      "Epoch 17/30, train_loss: 0.00571, valid_loss: 0.00553\n",
      "Epoch 18/30, train_loss: 0.00565, valid_loss: 0.00554\n",
      "Epoch 19/30, train_loss: 0.00562, valid_loss: 0.00548\n",
      "Epoch 20/30, train_loss: 0.00557, valid_loss: 0.00544\n",
      "Epoch 21/30, train_loss: 0.00552, valid_loss: 0.00545\n",
      "Epoch 22/30, train_loss: 0.00548, valid_loss: 0.00545\n",
      "Epoch 23/30, train_loss: 0.00546, valid_loss: 0.00555\n",
      "Epoch 24/30, train_loss: 0.00545, valid_loss: 0.00551\n",
      "Epoch 25/30, train_loss: 0.00541, valid_loss: 0.00550\n",
      "Epoch 26/30, train_loss: 0.00539, valid_loss: 0.00551\n",
      "Epoch 27/30, train_loss: 0.00536, valid_loss: 0.00548\n",
      "Epoch 28/30, train_loss: 0.00533, valid_loss: 0.00557\n",
      "Epoch 29/30, train_loss: 0.00532, valid_loss: 0.00553\n",
      "Epoch 30/30, train_loss: 0.00529, valid_loss: 0.00550\n",
      "At step 11\n",
      "Epoch 1/30, train_loss: 0.02125, valid_loss: 0.00861\n",
      "Epoch 2/30, train_loss: 0.01559, valid_loss: 0.00715\n",
      "Epoch 3/30, train_loss: 0.01308, valid_loss: 0.00661\n",
      "Epoch 4/30, train_loss: 0.01162, valid_loss: 0.00632\n",
      "Epoch 5/30, train_loss: 0.01064, valid_loss: 0.00613\n",
      "Epoch 6/30, train_loss: 0.00994, valid_loss: 0.00602\n",
      "Epoch 7/30, train_loss: 0.00941, valid_loss: 0.00592\n",
      "Epoch 8/30, train_loss: 0.00899, valid_loss: 0.00585\n",
      "Epoch 9/30, train_loss: 0.00865, valid_loss: 0.00579\n",
      "Epoch 10/30, train_loss: 0.00837, valid_loss: 0.00575\n",
      "Epoch 11/30, train_loss: 0.00813, valid_loss: 0.00570\n",
      "Epoch 12/30, train_loss: 0.00792, valid_loss: 0.00569\n",
      "Epoch 13/30, train_loss: 0.00774, valid_loss: 0.00565\n",
      "Epoch 14/30, train_loss: 0.00759, valid_loss: 0.00564\n",
      "Epoch 15/30, train_loss: 0.00744, valid_loss: 0.00561\n",
      "Epoch 16/30, train_loss: 0.00732, valid_loss: 0.00559\n",
      "Epoch 17/30, train_loss: 0.00720, valid_loss: 0.00557\n",
      "Epoch 18/30, train_loss: 0.00710, valid_loss: 0.00555\n",
      "Epoch 19/30, train_loss: 0.00701, valid_loss: 0.00554\n",
      "Epoch 20/30, train_loss: 0.00692, valid_loss: 0.00552\n",
      "Epoch 21/30, train_loss: 0.00684, valid_loss: 0.00552\n",
      "Epoch 22/30, train_loss: 0.00677, valid_loss: 0.00552\n",
      "Epoch 23/30, train_loss: 0.00671, valid_loss: 0.00550\n",
      "Epoch 24/30, train_loss: 0.00665, valid_loss: 0.00548\n",
      "Epoch 25/30, train_loss: 0.00659, valid_loss: 0.00547\n",
      "Epoch 26/30, train_loss: 0.00654, valid_loss: 0.00545\n",
      "Epoch 27/30, train_loss: 0.00649, valid_loss: 0.00545\n",
      "Epoch 28/30, train_loss: 0.00645, valid_loss: 0.00546\n",
      "Epoch 29/30, train_loss: 0.00641, valid_loss: 0.00544\n",
      "Epoch 30/30, train_loss: 0.00636, valid_loss: 0.00542\n",
      "At step 10\n",
      "Epoch 1/30, train_loss: 0.02836, valid_loss: 0.00621\n",
      "Epoch 2/30, train_loss: 0.02059, valid_loss: 0.00613\n",
      "Epoch 3/30, train_loss: 0.01716, valid_loss: 0.00602\n",
      "Epoch 4/30, train_loss: 0.01515, valid_loss: 0.00596\n",
      "Epoch 5/30, train_loss: 0.01380, valid_loss: 0.00596\n",
      "Epoch 6/30, train_loss: 0.01283, valid_loss: 0.00592\n",
      "Epoch 7/30, train_loss: 0.01208, valid_loss: 0.00588\n",
      "Epoch 8/30, train_loss: 0.01149, valid_loss: 0.00586\n",
      "Epoch 9/30, train_loss: 0.01100, valid_loss: 0.00584\n",
      "Epoch 10/30, train_loss: 0.01060, valid_loss: 0.00585\n",
      "Epoch 11/30, train_loss: 0.01026, valid_loss: 0.00582\n",
      "Epoch 12/30, train_loss: 0.00997, valid_loss: 0.00580\n",
      "Epoch 13/30, train_loss: 0.00971, valid_loss: 0.00584\n",
      "Epoch 14/30, train_loss: 0.00949, valid_loss: 0.00586\n",
      "Epoch 15/30, train_loss: 0.00929, valid_loss: 0.00584\n",
      "Epoch 16/30, train_loss: 0.00911, valid_loss: 0.00582\n",
      "Epoch 17/30, train_loss: 0.00895, valid_loss: 0.00582\n",
      "Epoch 18/30, train_loss: 0.00880, valid_loss: 0.00580\n",
      "Epoch 19/30, train_loss: 0.00866, valid_loss: 0.00579\n",
      "Epoch 20/30, train_loss: 0.00854, valid_loss: 0.00578\n",
      "Epoch 21/30, train_loss: 0.00842, valid_loss: 0.00579\n",
      "Epoch 22/30, train_loss: 0.00832, valid_loss: 0.00577\n",
      "Epoch 23/30, train_loss: 0.00822, valid_loss: 0.00576\n",
      "Epoch 24/30, train_loss: 0.00812, valid_loss: 0.00575\n",
      "Epoch 25/30, train_loss: 0.00804, valid_loss: 0.00573\n",
      "Epoch 26/30, train_loss: 0.00796, valid_loss: 0.00572\n",
      "Epoch 27/30, train_loss: 0.00789, valid_loss: 0.00573\n",
      "Epoch 28/30, train_loss: 0.00781, valid_loss: 0.00571\n",
      "Epoch 29/30, train_loss: 0.00775, valid_loss: 0.00576\n",
      "Epoch 30/30, train_loss: 0.00769, valid_loss: 0.00574\n",
      "At step 9\n",
      "Epoch 1/30, train_loss: 0.01404, valid_loss: 0.00582\n",
      "Epoch 2/30, train_loss: 0.01089, valid_loss: 0.00588\n",
      "Epoch 3/30, train_loss: 0.00958, valid_loss: 0.00592\n",
      "Epoch 4/30, train_loss: 0.00886, valid_loss: 0.00597\n",
      "Epoch 5/30, train_loss: 0.00837, valid_loss: 0.00590\n",
      "Epoch 6/30, train_loss: 0.00802, valid_loss: 0.00593\n",
      "Epoch 7/30, train_loss: 0.00779, valid_loss: 0.00589\n",
      "Epoch 8/30, train_loss: 0.00761, valid_loss: 0.00587\n",
      "Epoch 9/30, train_loss: 0.00745, valid_loss: 0.00588\n",
      "Epoch 10/30, train_loss: 0.00731, valid_loss: 0.00584\n",
      "Epoch 11/30, train_loss: 0.00719, valid_loss: 0.00590\n",
      "Epoch 12/30, train_loss: 0.00710, valid_loss: 0.00594\n",
      "Epoch 13/30, train_loss: 0.00703, valid_loss: 0.00595\n",
      "Epoch 14/30, train_loss: 0.00698, valid_loss: 0.00593\n",
      "Epoch 15/30, train_loss: 0.00690, valid_loss: 0.00591\n",
      "Epoch 16/30, train_loss: 0.00684, valid_loss: 0.00589\n",
      "Epoch 17/30, train_loss: 0.00678, valid_loss: 0.00589\n",
      "Epoch 18/30, train_loss: 0.00673, valid_loss: 0.00586\n",
      "Epoch 19/30, train_loss: 0.00668, valid_loss: 0.00582\n",
      "Epoch 20/30, train_loss: 0.00664, valid_loss: 0.00580\n",
      "Epoch 21/30, train_loss: 0.00661, valid_loss: 0.00589\n",
      "Epoch 22/30, train_loss: 0.00657, valid_loss: 0.00587\n",
      "Epoch 23/30, train_loss: 0.00652, valid_loss: 0.00582\n",
      "Epoch 24/30, train_loss: 0.00647, valid_loss: 0.00579\n",
      "Epoch 25/30, train_loss: 0.00643, valid_loss: 0.00575\n",
      "Epoch 26/30, train_loss: 0.00639, valid_loss: 0.00572\n",
      "Epoch 27/30, train_loss: 0.00636, valid_loss: 0.00571\n",
      "Epoch 28/30, train_loss: 0.00632, valid_loss: 0.00568\n",
      "Epoch 29/30, train_loss: 0.00627, valid_loss: 0.00567\n",
      "Epoch 30/30, train_loss: 0.00623, valid_loss: 0.00563\n",
      "At step 8\n",
      "Epoch 1/30, train_loss: 0.01934, valid_loss: 0.00894\n",
      "Epoch 2/30, train_loss: 0.01441, valid_loss: 0.00773\n",
      "Epoch 3/30, train_loss: 0.01224, valid_loss: 0.00728\n",
      "Epoch 4/30, train_loss: 0.01101, valid_loss: 0.00710\n",
      "Epoch 5/30, train_loss: 0.01020, valid_loss: 0.00694\n",
      "Epoch 6/30, train_loss: 0.00960, valid_loss: 0.00683\n",
      "Epoch 7/30, train_loss: 0.00917, valid_loss: 0.00675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, train_loss: 0.00882, valid_loss: 0.00674\n",
      "Epoch 9/30, train_loss: 0.00855, valid_loss: 0.00667\n",
      "Epoch 10/30, train_loss: 0.00831, valid_loss: 0.00664\n",
      "Epoch 11/30, train_loss: 0.00812, valid_loss: 0.00658\n",
      "Epoch 12/30, train_loss: 0.00796, valid_loss: 0.00661\n",
      "Epoch 13/30, train_loss: 0.00784, valid_loss: 0.00656\n",
      "Epoch 14/30, train_loss: 0.00770, valid_loss: 0.00652\n",
      "Epoch 15/30, train_loss: 0.00758, valid_loss: 0.00647\n",
      "Epoch 16/30, train_loss: 0.00747, valid_loss: 0.00646\n",
      "Epoch 17/30, train_loss: 0.00738, valid_loss: 0.00642\n",
      "Epoch 18/30, train_loss: 0.00730, valid_loss: 0.00640\n",
      "Epoch 19/30, train_loss: 0.00722, valid_loss: 0.00639\n",
      "Epoch 20/30, train_loss: 0.00714, valid_loss: 0.00635\n",
      "Epoch 21/30, train_loss: 0.00707, valid_loss: 0.00633\n",
      "Epoch 22/30, train_loss: 0.00699, valid_loss: 0.00631\n",
      "Epoch 23/30, train_loss: 0.00694, valid_loss: 0.00628\n",
      "Epoch 24/30, train_loss: 0.00688, valid_loss: 0.00624\n",
      "Epoch 25/30, train_loss: 0.00682, valid_loss: 0.00620\n",
      "Epoch 26/30, train_loss: 0.00677, valid_loss: 0.00619\n",
      "Epoch 27/30, train_loss: 0.00672, valid_loss: 0.00616\n",
      "Epoch 28/30, train_loss: 0.00666, valid_loss: 0.00614\n",
      "Epoch 29/30, train_loss: 0.00661, valid_loss: 0.00611\n",
      "Epoch 30/30, train_loss: 0.00656, valid_loss: 0.00612\n",
      "At step 7\n",
      "Epoch 1/30, train_loss: 0.02166, valid_loss: 0.00730\n",
      "Epoch 2/30, train_loss: 0.01599, valid_loss: 0.00664\n",
      "Epoch 3/30, train_loss: 0.01357, valid_loss: 0.00655\n",
      "Epoch 4/30, train_loss: 0.01217, valid_loss: 0.00643\n",
      "Epoch 5/30, train_loss: 0.01127, valid_loss: 0.00644\n",
      "Epoch 6/30, train_loss: 0.01060, valid_loss: 0.00636\n",
      "Epoch 7/30, train_loss: 0.01010, valid_loss: 0.00634\n",
      "Epoch 8/30, train_loss: 0.00970, valid_loss: 0.00632\n",
      "Epoch 9/30, train_loss: 0.00938, valid_loss: 0.00626\n",
      "Epoch 10/30, train_loss: 0.00911, valid_loss: 0.00622\n",
      "Epoch 11/30, train_loss: 0.00888, valid_loss: 0.00623\n",
      "Epoch 12/30, train_loss: 0.00870, valid_loss: 0.00619\n",
      "Epoch 13/30, train_loss: 0.00852, valid_loss: 0.00616\n",
      "Epoch 14/30, train_loss: 0.00837, valid_loss: 0.00611\n",
      "Epoch 15/30, train_loss: 0.00823, valid_loss: 0.00606\n",
      "Epoch 16/30, train_loss: 0.00810, valid_loss: 0.00601\n",
      "Epoch 17/30, train_loss: 0.00799, valid_loss: 0.00599\n",
      "Epoch 18/30, train_loss: 0.00789, valid_loss: 0.00595\n",
      "Epoch 19/30, train_loss: 0.00779, valid_loss: 0.00591\n",
      "Epoch 20/30, train_loss: 0.00769, valid_loss: 0.00587\n",
      "Epoch 21/30, train_loss: 0.00760, valid_loss: 0.00595\n",
      "Epoch 22/30, train_loss: 0.00752, valid_loss: 0.00591\n",
      "Epoch 23/30, train_loss: 0.00744, valid_loss: 0.00587\n",
      "Epoch 24/30, train_loss: 0.00737, valid_loss: 0.00590\n",
      "Epoch 25/30, train_loss: 0.00729, valid_loss: 0.00590\n",
      "Epoch 26/30, train_loss: 0.00724, valid_loss: 0.00585\n",
      "Epoch 27/30, train_loss: 0.00718, valid_loss: 0.00581\n",
      "Epoch 28/30, train_loss: 0.00712, valid_loss: 0.00577\n",
      "Epoch 29/30, train_loss: 0.00708, valid_loss: 0.00573\n",
      "Epoch 30/30, train_loss: 0.00702, valid_loss: 0.00570\n",
      "At step 6\n",
      "Epoch 1/30, train_loss: 0.01422, valid_loss: 0.00685\n",
      "Epoch 2/30, train_loss: 0.01112, valid_loss: 0.00688\n",
      "Epoch 3/30, train_loss: 0.00988, valid_loss: 0.00687\n",
      "Epoch 4/30, train_loss: 0.00921, valid_loss: 0.00686\n",
      "Epoch 5/30, train_loss: 0.00876, valid_loss: 0.00683\n",
      "Epoch 6/30, train_loss: 0.00844, valid_loss: 0.00680\n",
      "Epoch 7/30, train_loss: 0.00821, valid_loss: 0.00678\n",
      "Epoch 8/30, train_loss: 0.00802, valid_loss: 0.00675\n",
      "Epoch 9/30, train_loss: 0.00786, valid_loss: 0.00673\n",
      "Epoch 10/30, train_loss: 0.00775, valid_loss: 0.00671\n",
      "Epoch 11/30, train_loss: 0.00765, valid_loss: 0.00667\n",
      "Epoch 12/30, train_loss: 0.00755, valid_loss: 0.00666\n",
      "Epoch 13/30, train_loss: 0.00746, valid_loss: 0.00663\n",
      "Epoch 14/30, train_loss: 0.00738, valid_loss: 0.00659\n",
      "Epoch 15/30, train_loss: 0.00730, valid_loss: 0.00658\n",
      "Epoch 16/30, train_loss: 0.00723, valid_loss: 0.00657\n",
      "Epoch 17/30, train_loss: 0.00716, valid_loss: 0.00652\n",
      "Epoch 18/30, train_loss: 0.00709, valid_loss: 0.00647\n",
      "Epoch 19/30, train_loss: 0.00702, valid_loss: 0.00645\n",
      "Epoch 20/30, train_loss: 0.00696, valid_loss: 0.00640\n",
      "Epoch 21/30, train_loss: 0.00690, valid_loss: 0.00634\n",
      "Epoch 22/30, train_loss: 0.00685, valid_loss: 0.00633\n",
      "Epoch 23/30, train_loss: 0.00679, valid_loss: 0.00633\n",
      "Epoch 24/30, train_loss: 0.00673, valid_loss: 0.00635\n",
      "Epoch 25/30, train_loss: 0.00668, valid_loss: 0.00629\n",
      "Epoch 26/30, train_loss: 0.00662, valid_loss: 0.00624\n",
      "Epoch 27/30, train_loss: 0.00656, valid_loss: 0.00619\n",
      "Epoch 28/30, train_loss: 0.00650, valid_loss: 0.00613\n",
      "Epoch 29/30, train_loss: 0.00646, valid_loss: 0.00617\n",
      "Epoch 30/30, train_loss: 0.00642, valid_loss: 0.00614\n",
      "At step 5\n",
      "Epoch 1/30, train_loss: 0.01318, valid_loss: 0.00757\n",
      "Epoch 2/30, train_loss: 0.01089, valid_loss: 0.00756\n",
      "Epoch 3/30, train_loss: 0.00995, valid_loss: 0.00757\n",
      "Epoch 4/30, train_loss: 0.00956, valid_loss: 0.00755\n",
      "Epoch 5/30, train_loss: 0.00922, valid_loss: 0.00758\n",
      "Epoch 6/30, train_loss: 0.00898, valid_loss: 0.00756\n",
      "Epoch 7/30, train_loss: 0.00881, valid_loss: 0.00754\n",
      "Epoch 8/30, train_loss: 0.00866, valid_loss: 0.00750\n",
      "Epoch 9/30, train_loss: 0.00854, valid_loss: 0.00748\n",
      "Epoch 10/30, train_loss: 0.00844, valid_loss: 0.00750\n",
      "Epoch 11/30, train_loss: 0.00835, valid_loss: 0.00746\n",
      "Epoch 12/30, train_loss: 0.00829, valid_loss: 0.00744\n",
      "Epoch 13/30, train_loss: 0.00823, valid_loss: 0.00740\n",
      "Epoch 14/30, train_loss: 0.00816, valid_loss: 0.00736\n",
      "Epoch 15/30, train_loss: 0.00809, valid_loss: 0.00741\n",
      "Epoch 16/30, train_loss: 0.00804, valid_loss: 0.00736\n",
      "Epoch 17/30, train_loss: 0.00798, valid_loss: 0.00730\n",
      "Epoch 18/30, train_loss: 0.00797, valid_loss: 0.00727\n",
      "Epoch 19/30, train_loss: 0.00791, valid_loss: 0.00725\n",
      "Epoch 20/30, train_loss: 0.00786, valid_loss: 0.00721\n",
      "Epoch 21/30, train_loss: 0.00781, valid_loss: 0.00715\n",
      "Epoch 22/30, train_loss: 0.00777, valid_loss: 0.00713\n",
      "Epoch 23/30, train_loss: 0.00771, valid_loss: 0.00707\n",
      "Epoch 24/30, train_loss: 0.00766, valid_loss: 0.00702\n",
      "Epoch 25/30, train_loss: 0.00760, valid_loss: 0.00697\n",
      "Epoch 26/30, train_loss: 0.00755, valid_loss: 0.00693\n",
      "Epoch 27/30, train_loss: 0.00751, valid_loss: 0.00688\n",
      "Epoch 28/30, train_loss: 0.00747, valid_loss: 0.00685\n",
      "Epoch 29/30, train_loss: 0.00742, valid_loss: 0.00680\n",
      "Epoch 30/30, train_loss: 0.00738, valid_loss: 0.00688\n",
      "At step 4\n",
      "Epoch 1/30, train_loss: 0.01991, valid_loss: 0.00803\n",
      "Epoch 2/30, train_loss: 0.01520, valid_loss: 0.00809\n",
      "Epoch 3/30, train_loss: 0.01323, valid_loss: 0.00813\n",
      "Epoch 4/30, train_loss: 0.01213, valid_loss: 0.00811\n",
      "Epoch 5/30, train_loss: 0.01141, valid_loss: 0.00809\n",
      "Epoch 6/30, train_loss: 0.01091, valid_loss: 0.00807\n",
      "Epoch 7/30, train_loss: 0.01053, valid_loss: 0.00806\n",
      "Epoch 8/30, train_loss: 0.01023, valid_loss: 0.00804\n",
      "Epoch 9/30, train_loss: 0.00999, valid_loss: 0.00803\n",
      "Epoch 10/30, train_loss: 0.00981, valid_loss: 0.00802\n",
      "Epoch 11/30, train_loss: 0.00965, valid_loss: 0.00800\n",
      "Epoch 12/30, train_loss: 0.00951, valid_loss: 0.00801\n",
      "Epoch 13/30, train_loss: 0.00938, valid_loss: 0.00800\n",
      "Epoch 14/30, train_loss: 0.00927, valid_loss: 0.00798\n",
      "Epoch 15/30, train_loss: 0.00918, valid_loss: 0.00799\n",
      "Epoch 16/30, train_loss: 0.00909, valid_loss: 0.00798\n",
      "Epoch 17/30, train_loss: 0.00901, valid_loss: 0.00798\n",
      "Epoch 18/30, train_loss: 0.00894, valid_loss: 0.00797\n",
      "Epoch 19/30, train_loss: 0.00887, valid_loss: 0.00795\n",
      "Epoch 20/30, train_loss: 0.00881, valid_loss: 0.00797\n",
      "Epoch 21/30, train_loss: 0.00876, valid_loss: 0.00794\n",
      "Epoch 22/30, train_loss: 0.00871, valid_loss: 0.00792\n",
      "Epoch 23/30, train_loss: 0.00866, valid_loss: 0.00792\n",
      "Epoch 24/30, train_loss: 0.00861, valid_loss: 0.00789\n",
      "Epoch 25/30, train_loss: 0.00856, valid_loss: 0.00786\n",
      "Epoch 26/30, train_loss: 0.00851, valid_loss: 0.00783\n",
      "Epoch 27/30, train_loss: 0.00847, valid_loss: 0.00787\n",
      "Epoch 28/30, train_loss: 0.00842, valid_loss: 0.00784\n",
      "Epoch 29/30, train_loss: 0.00838, valid_loss: 0.00784\n",
      "Epoch 30/30, train_loss: 0.00834, valid_loss: 0.00788\n",
      "At step 3\n",
      "Epoch 1/30, train_loss: 0.01564, valid_loss: 0.00850\n",
      "Epoch 2/30, train_loss: 0.01228, valid_loss: 0.00801\n",
      "Epoch 3/30, train_loss: 0.01090, valid_loss: 0.00841\n",
      "Epoch 4/30, train_loss: 0.01014, valid_loss: 0.00820\n",
      "Epoch 5/30, train_loss: 0.00963, valid_loss: 0.00807\n",
      "Epoch 6/30, train_loss: 0.00928, valid_loss: 0.00795\n",
      "Epoch 7/30, train_loss: 0.00900, valid_loss: 0.00810\n",
      "Epoch 8/30, train_loss: 0.00880, valid_loss: 0.00822\n",
      "Epoch 9/30, train_loss: 0.00867, valid_loss: 0.00809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, train_loss: 0.00852, valid_loss: 0.00799\n",
      "Epoch 11/30, train_loss: 0.00839, valid_loss: 0.00788\n",
      "Epoch 12/30, train_loss: 0.00827, valid_loss: 0.00778\n",
      "Epoch 13/30, train_loss: 0.00816, valid_loss: 0.00774\n",
      "Epoch 14/30, train_loss: 0.00807, valid_loss: 0.00775\n",
      "Epoch 15/30, train_loss: 0.00797, valid_loss: 0.00766\n",
      "Epoch 16/30, train_loss: 0.00789, valid_loss: 0.00759\n",
      "Epoch 17/30, train_loss: 0.00779, valid_loss: 0.00751\n",
      "Epoch 18/30, train_loss: 0.00775, valid_loss: 0.00798\n",
      "Epoch 19/30, train_loss: 0.00768, valid_loss: 0.00793\n",
      "Epoch 20/30, train_loss: 0.00759, valid_loss: 0.00786\n",
      "Epoch 21/30, train_loss: 0.00751, valid_loss: 0.00779\n",
      "Epoch 22/30, train_loss: 0.00744, valid_loss: 0.00775\n",
      "Epoch 23/30, train_loss: 0.00738, valid_loss: 0.00765\n",
      "Epoch 24/30, train_loss: 0.00731, valid_loss: 0.00758\n",
      "Epoch 25/30, train_loss: 0.00726, valid_loss: 0.00751\n",
      "Epoch 26/30, train_loss: 0.00721, valid_loss: 0.00752\n",
      "Epoch 27/30, train_loss: 0.00716, valid_loss: 0.00752\n",
      "Epoch 28/30, train_loss: 0.00711, valid_loss: 0.00748\n",
      "Epoch 29/30, train_loss: 0.00706, valid_loss: 0.00746\n",
      "Epoch 30/30, train_loss: 0.00701, valid_loss: 0.00739\n",
      "At step 2\n",
      "Epoch 1/30, train_loss: 0.00964, valid_loss: 0.00796\n",
      "Epoch 2/30, train_loss: 0.00880, valid_loss: 0.00777\n",
      "Epoch 3/30, train_loss: 0.00844, valid_loss: 0.00776\n",
      "Epoch 4/30, train_loss: 0.00822, valid_loss: 0.00759\n",
      "Epoch 5/30, train_loss: 0.00808, valid_loss: 0.00766\n",
      "Epoch 6/30, train_loss: 0.00796, valid_loss: 0.00757\n",
      "Epoch 7/30, train_loss: 0.00789, valid_loss: 0.00756\n",
      "Epoch 8/30, train_loss: 0.00781, valid_loss: 0.00750\n",
      "Epoch 9/30, train_loss: 0.00774, valid_loss: 0.00747\n",
      "Epoch 10/30, train_loss: 0.00768, valid_loss: 0.00741\n",
      "Epoch 11/30, train_loss: 0.00760, valid_loss: 0.00747\n",
      "Epoch 12/30, train_loss: 0.00752, valid_loss: 0.00738\n",
      "Epoch 13/30, train_loss: 0.00744, valid_loss: 0.00727\n",
      "Epoch 14/30, train_loss: 0.00738, valid_loss: 0.00719\n",
      "Epoch 15/30, train_loss: 0.00732, valid_loss: 0.00711\n",
      "Epoch 16/30, train_loss: 0.00726, valid_loss: 0.00711\n",
      "Epoch 17/30, train_loss: 0.00720, valid_loss: 0.00709\n",
      "Epoch 18/30, train_loss: 0.00716, valid_loss: 0.00702\n",
      "Epoch 19/30, train_loss: 0.00710, valid_loss: 0.00698\n",
      "Epoch 20/30, train_loss: 0.00705, valid_loss: 0.00698\n",
      "Epoch 21/30, train_loss: 0.00699, valid_loss: 0.00694\n",
      "Epoch 22/30, train_loss: 0.00695, valid_loss: 0.00690\n",
      "Epoch 23/30, train_loss: 0.00691, valid_loss: 0.00685\n",
      "Epoch 24/30, train_loss: 0.00686, valid_loss: 0.00683\n",
      "Epoch 25/30, train_loss: 0.00682, valid_loss: 0.00679\n",
      "Epoch 26/30, train_loss: 0.00679, valid_loss: 0.00675\n",
      "Epoch 27/30, train_loss: 0.00675, valid_loss: 0.00671\n",
      "Epoch 28/30, train_loss: 0.00672, valid_loss: 0.00668\n",
      "Epoch 29/30, train_loss: 0.00669, valid_loss: 0.00668\n",
      "Epoch 30/30, train_loss: 0.00666, valid_loss: 0.00666\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prc_nn_10k=Bermudan_swaption_nn(lockout,maturity,sim_rates_10k,strike,n_epochs,batch_size,learningrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European swaption pirce: 0.006946037983725924\n",
      "Bermudan swaption pirce: 0.008711608144623633\n",
      "Excercise Probability Table\n",
      "    Time_step  ex_prob_Euro  ex_prob_RLNN\n",
      "0           2        0.7087        0.4885\n",
      "1           3        0.0000        0.1802\n",
      "2           4        0.0000        0.0857\n",
      "3           5        0.0000        0.0186\n",
      "4           6        0.0000        0.0132\n",
      "5           7        0.0000        0.0094\n",
      "6           8        0.0000        0.0049\n",
      "7           9        0.0000        0.0019\n",
      "8          10        0.0000        0.0021\n",
      "9          11        0.0000        0.0030\n",
      "10         12        0.0000        0.0022\n",
      "11         13        0.0000        0.0019\n",
      "12         14        0.0000        0.0023\n",
      "13         15        0.0000        0.0037\n",
      "14         16        0.0000        0.0027\n",
      "15         17        0.0000        0.0029\n",
      "16         18        0.0000        0.0048\n",
      "17         19        0.0000        0.0063\n"
     ]
    }
   ],
   "source": [
    "print_result(prc_nn_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prc_xgb_10k=Bermudan_swaption_xgboost_fixed(lockout,maturity,sim_rates_10k,strike,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European swaption pirce: 0.006946037983725924\n",
      "Bermudan swaption pirce: 0.007692747802003234\n",
      "Excercise Probability Table\n",
      "    Time_step  ex_prob_Euro  ex_prob_xgb\n",
      "0           2        0.7087       0.6011\n",
      "1           3        0.0000       0.0691\n",
      "2           4        0.0000       0.0280\n",
      "3           5        0.0000       0.0155\n",
      "4           6        0.0000       0.0094\n",
      "5           7        0.0000       0.0064\n",
      "6           8        0.0000       0.0038\n",
      "7           9        0.0000       0.0026\n",
      "8          10        0.0000       0.0027\n",
      "9          11        0.0000       0.0024\n",
      "10         12        0.0000       0.0018\n",
      "11         13        0.0000       0.0033\n",
      "12         14        0.0000       0.0037\n",
      "13         15        0.0000       0.0031\n",
      "14         16        0.0000       0.0038\n",
      "15         17        0.0000       0.0052\n",
      "16         18        0.0000       0.0067\n",
      "17         19        0.0000       0.0073\n"
     ]
    }
   ],
   "source": [
    "print_result(prc_xgb_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prc_lsm_50k=Bermudan_swaption_lsm(lockout,maturity,sim_rates_50k,strike,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European swaption pirce: 0.006957211172997507\n",
      "Bermudan swaption pirce: 0.007512767003647237\n",
      "Excercise Probability Table\n",
      "    Time_step  ex_prob_Euro  ex_prob_LSM\n",
      "0           2       0.70758      0.44388\n",
      "1           3       0.00000      0.06182\n",
      "2           4       0.00000      0.02778\n",
      "3           5       0.00000      0.01508\n",
      "4           6       0.00000      0.01052\n",
      "5           7       0.00000      0.00688\n",
      "6           8       0.00000      0.00520\n",
      "7           9       0.00000      0.00460\n",
      "8          10       0.00000      0.00418\n",
      "9          11       0.00000      0.00362\n",
      "10         12       0.00000      0.00374\n",
      "11         13       0.00000      0.00436\n",
      "12         14       0.00000      0.00464\n",
      "13         15       0.00000      0.00502\n",
      "14         16       0.00000      0.00668\n",
      "15         17       0.00000      0.00956\n",
      "16         18       0.00000      0.01664\n",
      "17         19       0.00000      0.01096\n"
     ]
    }
   ],
   "source": [
    "print_result(prc_lsm_50k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 18\n",
      "Epoch 1/30, train_loss: 0.01677, valid_loss: 0.00090\n",
      "Epoch 2/30, train_loss: 0.01187, valid_loss: 0.00089\n",
      "Epoch 3/30, train_loss: 0.00971, valid_loss: 0.00089\n",
      "Epoch 4/30, train_loss: 0.00842, valid_loss: 0.00088\n",
      "Epoch 5/30, train_loss: 0.00754, valid_loss: 0.00090\n",
      "Epoch 6/30, train_loss: 0.00689, valid_loss: 0.00090\n",
      "Epoch 7/30, train_loss: 0.00639, valid_loss: 0.00090\n",
      "Epoch 8/30, train_loss: 0.00598, valid_loss: 0.00089\n",
      "Epoch 9/30, train_loss: 0.00565, valid_loss: 0.00089\n",
      "Epoch 10/30, train_loss: 0.00537, valid_loss: 0.00088\n",
      "Epoch 11/30, train_loss: 0.00512, valid_loss: 0.00088\n",
      "Epoch 12/30, train_loss: 0.00491, valid_loss: 0.00089\n",
      "Epoch 13/30, train_loss: 0.00473, valid_loss: 0.00089\n",
      "Epoch 14/30, train_loss: 0.00456, valid_loss: 0.00089\n",
      "Epoch 15/30, train_loss: 0.00441, valid_loss: 0.00088\n",
      "Epoch 16/30, train_loss: 0.00428, valid_loss: 0.00098\n",
      "Epoch 17/30, train_loss: 0.00416, valid_loss: 0.00100\n",
      "Epoch 18/30, train_loss: 0.00405, valid_loss: 0.00099\n",
      "Epoch 19/30, train_loss: 0.00395, valid_loss: 0.00100\n",
      "Epoch 20/30, train_loss: 0.00385, valid_loss: 0.00099\n",
      "Epoch 21/30, train_loss: 0.00377, valid_loss: 0.00099\n",
      "Epoch 22/30, train_loss: 0.00369, valid_loss: 0.00100\n",
      "Epoch 23/30, train_loss: 0.00361, valid_loss: 0.00104\n",
      "Epoch 24/30, train_loss: 0.00355, valid_loss: 0.00103\n",
      "Epoch 25/30, train_loss: 0.00350, valid_loss: 0.00189\n",
      "Epoch 26/30, train_loss: 0.00345, valid_loss: 0.00186\n",
      "Epoch 27/30, train_loss: 0.00339, valid_loss: 0.00184\n",
      "Epoch 28/30, train_loss: 0.00334, valid_loss: 0.00182\n",
      "Epoch 29/30, train_loss: 0.00328, valid_loss: 0.00180\n",
      "Epoch 30/30, train_loss: 0.00323, valid_loss: 0.00179\n",
      "At step 17\n",
      "Epoch 1/30, train_loss: 0.00740, valid_loss: 0.00186\n",
      "Epoch 2/30, train_loss: 0.00535, valid_loss: 0.00175\n",
      "Epoch 3/30, train_loss: 0.00446, valid_loss: 0.00209\n",
      "Epoch 4/30, train_loss: 0.00395, valid_loss: 0.00220\n",
      "Epoch 5/30, train_loss: 0.00360, valid_loss: 0.00261\n",
      "Epoch 6/30, train_loss: 0.00338, valid_loss: 0.00248\n",
      "Epoch 7/30, train_loss: 0.00319, valid_loss: 0.00275\n",
      "Epoch 8/30, train_loss: 0.00305, valid_loss: 0.00279\n",
      "Epoch 9/30, train_loss: 0.00292, valid_loss: 0.00268\n",
      "Epoch 10/30, train_loss: 0.00281, valid_loss: 0.00274\n",
      "Epoch 11/30, train_loss: 0.00274, valid_loss: 0.00282\n",
      "Epoch 12/30, train_loss: 0.00267, valid_loss: 0.00274\n",
      "Epoch 13/30, train_loss: 0.00260, valid_loss: 0.00283\n",
      "Epoch 14/30, train_loss: 0.00254, valid_loss: 0.00275\n",
      "Epoch 15/30, train_loss: 0.00249, valid_loss: 0.00268\n",
      "Epoch 16/30, train_loss: 0.00244, valid_loss: 0.00272\n",
      "Epoch 17/30, train_loss: 0.00240, valid_loss: 0.00272\n",
      "Epoch 18/30, train_loss: 0.00236, valid_loss: 0.00277\n",
      "Epoch 19/30, train_loss: 0.00233, valid_loss: 0.00271\n",
      "Epoch 20/30, train_loss: 0.00229, valid_loss: 0.00266\n",
      "Epoch 21/30, train_loss: 0.00226, valid_loss: 0.00269\n",
      "Epoch 22/30, train_loss: 0.00223, valid_loss: 0.00270\n",
      "Epoch 23/30, train_loss: 0.00220, valid_loss: 0.00270\n",
      "Epoch 24/30, train_loss: 0.00218, valid_loss: 0.00268\n",
      "Epoch 25/30, train_loss: 0.00215, valid_loss: 0.00265\n",
      "Epoch 26/30, train_loss: 0.00213, valid_loss: 0.00273\n",
      "Epoch 27/30, train_loss: 0.00211, valid_loss: 0.00274\n",
      "Epoch 28/30, train_loss: 0.00209, valid_loss: 0.00270\n",
      "Epoch 29/30, train_loss: 0.00207, valid_loss: 0.00272\n",
      "Epoch 30/30, train_loss: 0.00205, valid_loss: 0.00270\n",
      "At step 16\n",
      "Epoch 1/30, train_loss: 0.00540, valid_loss: 0.00210\n",
      "Epoch 2/30, train_loss: 0.00410, valid_loss: 0.00251\n",
      "Epoch 3/30, train_loss: 0.00358, valid_loss: 0.00371\n",
      "Epoch 4/30, train_loss: 0.00332, valid_loss: 0.00337\n",
      "Epoch 5/30, train_loss: 0.00312, valid_loss: 0.00363\n",
      "Epoch 6/30, train_loss: 0.00303, valid_loss: 0.00358\n",
      "Epoch 7/30, train_loss: 0.00294, valid_loss: 0.00344\n",
      "Epoch 8/30, train_loss: 0.00286, valid_loss: 0.00344\n",
      "Epoch 9/30, train_loss: 0.00280, valid_loss: 0.00334\n",
      "Epoch 10/30, train_loss: 0.00274, valid_loss: 0.00324\n",
      "Epoch 11/30, train_loss: 0.00269, valid_loss: 0.00316\n",
      "Epoch 12/30, train_loss: 0.00264, valid_loss: 0.00310\n",
      "Epoch 13/30, train_loss: 0.00260, valid_loss: 0.00303\n",
      "Epoch 14/30, train_loss: 0.00256, valid_loss: 0.00314\n",
      "Epoch 15/30, train_loss: 0.00254, valid_loss: 0.00311\n",
      "Epoch 16/30, train_loss: 0.00251, valid_loss: 0.00304\n",
      "Epoch 17/30, train_loss: 0.00248, valid_loss: 0.00302\n",
      "Epoch 18/30, train_loss: 0.00245, valid_loss: 0.00317\n",
      "Epoch 19/30, train_loss: 0.00243, valid_loss: 0.00313\n",
      "Epoch 20/30, train_loss: 0.00244, valid_loss: 0.00309\n",
      "Epoch 21/30, train_loss: 0.00242, valid_loss: 0.00310\n",
      "Epoch 22/30, train_loss: 0.00239, valid_loss: 0.00308\n",
      "Epoch 23/30, train_loss: 0.00237, valid_loss: 0.00304\n",
      "Epoch 24/30, train_loss: 0.00235, valid_loss: 0.00300\n",
      "Epoch 25/30, train_loss: 0.00232, valid_loss: 0.00295\n",
      "Epoch 26/30, train_loss: 0.00230, valid_loss: 0.00296\n",
      "Epoch 27/30, train_loss: 0.00228, valid_loss: 0.00292\n",
      "Epoch 28/30, train_loss: 0.00227, valid_loss: 0.00294\n",
      "Epoch 29/30, train_loss: 0.00225, valid_loss: 0.00292\n",
      "Epoch 30/30, train_loss: 0.00223, valid_loss: 0.00290\n",
      "At step 15\n",
      "Epoch 1/30, train_loss: 0.00951, valid_loss: 0.00284\n",
      "Epoch 2/30, train_loss: 0.00703, valid_loss: 0.00295\n",
      "Epoch 3/30, train_loss: 0.00598, valid_loss: 0.00299\n",
      "Epoch 4/30, train_loss: 0.00538, valid_loss: 0.00295\n",
      "Epoch 5/30, train_loss: 0.00500, valid_loss: 0.00311\n",
      "Epoch 6/30, train_loss: 0.00472, valid_loss: 0.00308\n",
      "Epoch 7/30, train_loss: 0.00451, valid_loss: 0.00306\n",
      "Epoch 8/30, train_loss: 0.00435, valid_loss: 0.00302\n",
      "Epoch 9/30, train_loss: 0.00421, valid_loss: 0.00300\n",
      "Epoch 10/30, train_loss: 0.00411, valid_loss: 0.00297\n",
      "Epoch 11/30, train_loss: 0.00401, valid_loss: 0.00295\n",
      "Epoch 12/30, train_loss: 0.00393, valid_loss: 0.00294\n",
      "Epoch 13/30, train_loss: 0.00386, valid_loss: 0.00300\n",
      "Epoch 14/30, train_loss: 0.00380, valid_loss: 0.00297\n",
      "Epoch 15/30, train_loss: 0.00374, valid_loss: 0.00294\n",
      "Epoch 16/30, train_loss: 0.00369, valid_loss: 0.00293\n",
      "Epoch 17/30, train_loss: 0.00364, valid_loss: 0.00293\n",
      "Epoch 18/30, train_loss: 0.00360, valid_loss: 0.00290\n",
      "Epoch 19/30, train_loss: 0.00355, valid_loss: 0.00287\n",
      "Epoch 20/30, train_loss: 0.00351, valid_loss: 0.00295\n",
      "Epoch 21/30, train_loss: 0.00347, valid_loss: 0.00293\n",
      "Epoch 22/30, train_loss: 0.00343, valid_loss: 0.00291\n",
      "Epoch 23/30, train_loss: 0.00339, valid_loss: 0.00293\n",
      "Epoch 24/30, train_loss: 0.00336, valid_loss: 0.00289\n",
      "Epoch 25/30, train_loss: 0.00332, valid_loss: 0.00289\n",
      "Epoch 26/30, train_loss: 0.00329, valid_loss: 0.00285\n",
      "Epoch 27/30, train_loss: 0.00326, valid_loss: 0.00282\n",
      "Epoch 28/30, train_loss: 0.00323, valid_loss: 0.00280\n",
      "Epoch 29/30, train_loss: 0.00320, valid_loss: 0.00277\n",
      "Epoch 30/30, train_loss: 0.00317, valid_loss: 0.00274\n",
      "At step 14\n",
      "Epoch 1/30, train_loss: 0.00787, valid_loss: 0.00357\n",
      "Epoch 2/30, train_loss: 0.00603, valid_loss: 0.00346\n",
      "Epoch 3/30, train_loss: 0.00529, valid_loss: 0.00344\n",
      "Epoch 4/30, train_loss: 0.00487, valid_loss: 0.00339\n",
      "Epoch 5/30, train_loss: 0.00459, valid_loss: 0.00335\n",
      "Epoch 6/30, train_loss: 0.00440, valid_loss: 0.00376\n",
      "Epoch 7/30, train_loss: 0.00427, valid_loss: 0.00376\n",
      "Epoch 8/30, train_loss: 0.00415, valid_loss: 0.00375\n",
      "Epoch 9/30, train_loss: 0.00403, valid_loss: 0.00371\n",
      "Epoch 10/30, train_loss: 0.00395, valid_loss: 0.00383\n",
      "Epoch 11/30, train_loss: 0.00390, valid_loss: 0.00374\n",
      "Epoch 12/30, train_loss: 0.00382, valid_loss: 0.00366\n",
      "Epoch 13/30, train_loss: 0.00375, valid_loss: 0.00366\n",
      "Epoch 14/30, train_loss: 0.00368, valid_loss: 0.00359\n",
      "Epoch 15/30, train_loss: 0.00362, valid_loss: 0.00365\n",
      "Epoch 16/30, train_loss: 0.00357, valid_loss: 0.00358\n",
      "Epoch 17/30, train_loss: 0.00352, valid_loss: 0.00352\n",
      "Epoch 18/30, train_loss: 0.00347, valid_loss: 0.00345\n",
      "Epoch 19/30, train_loss: 0.00342, valid_loss: 0.00339\n",
      "Epoch 20/30, train_loss: 0.00337, valid_loss: 0.00344\n",
      "Epoch 21/30, train_loss: 0.00333, valid_loss: 0.00341\n",
      "Epoch 22/30, train_loss: 0.00328, valid_loss: 0.00356\n",
      "Epoch 23/30, train_loss: 0.00325, valid_loss: 0.00350\n",
      "Epoch 24/30, train_loss: 0.00321, valid_loss: 0.00346\n",
      "Epoch 25/30, train_loss: 0.00318, valid_loss: 0.00347\n",
      "Epoch 26/30, train_loss: 0.00314, valid_loss: 0.00342\n",
      "Epoch 27/30, train_loss: 0.00311, valid_loss: 0.00343\n",
      "Epoch 28/30, train_loss: 0.00309, valid_loss: 0.00346\n",
      "Epoch 29/30, train_loss: 0.00306, valid_loss: 0.00341\n",
      "Epoch 30/30, train_loss: 0.00302, valid_loss: 0.00338\n",
      "At step 13\n",
      "Epoch 1/30, train_loss: 0.00927, valid_loss: 0.00418\n",
      "Epoch 2/30, train_loss: 0.00720, valid_loss: 0.00410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, train_loss: 0.00637, valid_loss: 0.00427\n",
      "Epoch 4/30, train_loss: 0.00592, valid_loss: 0.00420\n",
      "Epoch 5/30, train_loss: 0.00562, valid_loss: 0.00414\n",
      "Epoch 6/30, train_loss: 0.00540, valid_loss: 0.00406\n",
      "Epoch 7/30, train_loss: 0.00526, valid_loss: 0.00402\n",
      "Epoch 8/30, train_loss: 0.00513, valid_loss: 0.00402\n",
      "Epoch 9/30, train_loss: 0.00501, valid_loss: 0.00396\n",
      "Epoch 10/30, train_loss: 0.00490, valid_loss: 0.00393\n",
      "Epoch 11/30, train_loss: 0.00481, valid_loss: 0.00394\n",
      "Epoch 12/30, train_loss: 0.00473, valid_loss: 0.00390\n",
      "Epoch 13/30, train_loss: 0.00463, valid_loss: 0.00386\n",
      "Epoch 14/30, train_loss: 0.00455, valid_loss: 0.00380\n",
      "Epoch 15/30, train_loss: 0.00447, valid_loss: 0.00378\n",
      "Epoch 16/30, train_loss: 0.00440, valid_loss: 0.00373\n",
      "Epoch 17/30, train_loss: 0.00435, valid_loss: 0.00368\n",
      "Epoch 18/30, train_loss: 0.00430, valid_loss: 0.00366\n",
      "Epoch 19/30, train_loss: 0.00425, valid_loss: 0.00365\n",
      "Epoch 20/30, train_loss: 0.00419, valid_loss: 0.00362\n",
      "Epoch 21/30, train_loss: 0.00414, valid_loss: 0.00358\n",
      "Epoch 22/30, train_loss: 0.00409, valid_loss: 0.00354\n",
      "Epoch 23/30, train_loss: 0.00405, valid_loss: 0.00354\n",
      "Epoch 24/30, train_loss: 0.00401, valid_loss: 0.00352\n",
      "Epoch 25/30, train_loss: 0.00397, valid_loss: 0.00350\n",
      "Epoch 26/30, train_loss: 0.00394, valid_loss: 0.00355\n",
      "Epoch 27/30, train_loss: 0.00390, valid_loss: 0.00353\n",
      "Epoch 28/30, train_loss: 0.00387, valid_loss: 0.00350\n",
      "Epoch 29/30, train_loss: 0.00384, valid_loss: 0.00347\n",
      "Epoch 30/30, train_loss: 0.00381, valid_loss: 0.00345\n",
      "At step 12\n",
      "Epoch 1/30, train_loss: 0.00673, valid_loss: 0.00433\n",
      "Epoch 2/30, train_loss: 0.00570, valid_loss: 0.00428\n",
      "Epoch 3/30, train_loss: 0.00531, valid_loss: 0.00422\n",
      "Epoch 4/30, train_loss: 0.00510, valid_loss: 0.00425\n",
      "Epoch 5/30, train_loss: 0.00496, valid_loss: 0.00460\n",
      "Epoch 6/30, train_loss: 0.00485, valid_loss: 0.00458\n",
      "Epoch 7/30, train_loss: 0.00472, valid_loss: 0.00444\n",
      "Epoch 8/30, train_loss: 0.00461, valid_loss: 0.00446\n",
      "Epoch 9/30, train_loss: 0.00451, valid_loss: 0.00434\n",
      "Epoch 10/30, train_loss: 0.00442, valid_loss: 0.00422\n",
      "Epoch 11/30, train_loss: 0.00432, valid_loss: 0.00418\n",
      "Epoch 12/30, train_loss: 0.00423, valid_loss: 0.00416\n",
      "Epoch 13/30, train_loss: 0.00415, valid_loss: 0.00407\n",
      "Epoch 14/30, train_loss: 0.00410, valid_loss: 0.00398\n",
      "Epoch 15/30, train_loss: 0.00403, valid_loss: 0.00390\n",
      "Epoch 16/30, train_loss: 0.00396, valid_loss: 0.00383\n",
      "Epoch 17/30, train_loss: 0.00390, valid_loss: 0.00380\n",
      "Epoch 18/30, train_loss: 0.00385, valid_loss: 0.00378\n",
      "Epoch 19/30, train_loss: 0.00380, valid_loss: 0.00373\n",
      "Epoch 20/30, train_loss: 0.00374, valid_loss: 0.00368\n",
      "Epoch 21/30, train_loss: 0.00371, valid_loss: 0.00363\n",
      "Epoch 22/30, train_loss: 0.00367, valid_loss: 0.00358\n",
      "Epoch 23/30, train_loss: 0.00362, valid_loss: 0.00354\n",
      "Epoch 24/30, train_loss: 0.00359, valid_loss: 0.00350\n",
      "Epoch 25/30, train_loss: 0.00356, valid_loss: 0.00348\n",
      "Epoch 26/30, train_loss: 0.00352, valid_loss: 0.00345\n",
      "Epoch 27/30, train_loss: 0.00349, valid_loss: 0.00341\n",
      "Epoch 28/30, train_loss: 0.00346, valid_loss: 0.00338\n",
      "Epoch 29/30, train_loss: 0.00344, valid_loss: 0.00335\n",
      "Epoch 30/30, train_loss: 0.00342, valid_loss: 0.00333\n",
      "At step 11\n",
      "Epoch 1/30, train_loss: 0.01730, valid_loss: 0.00469\n",
      "Epoch 2/30, train_loss: 0.01267, valid_loss: 0.00471\n",
      "Epoch 3/30, train_loss: 0.01070, valid_loss: 0.00470\n",
      "Epoch 4/30, train_loss: 0.00956, valid_loss: 0.00467\n",
      "Epoch 5/30, train_loss: 0.00880, valid_loss: 0.00466\n",
      "Epoch 6/30, train_loss: 0.00826, valid_loss: 0.00468\n",
      "Epoch 7/30, train_loss: 0.00784, valid_loss: 0.00465\n",
      "Epoch 8/30, train_loss: 0.00751, valid_loss: 0.00465\n",
      "Epoch 9/30, train_loss: 0.00724, valid_loss: 0.00471\n",
      "Epoch 10/30, train_loss: 0.00702, valid_loss: 0.00471\n",
      "Epoch 11/30, train_loss: 0.00683, valid_loss: 0.00469\n",
      "Epoch 12/30, train_loss: 0.00666, valid_loss: 0.00465\n",
      "Epoch 13/30, train_loss: 0.00652, valid_loss: 0.00466\n",
      "Epoch 14/30, train_loss: 0.00639, valid_loss: 0.00463\n",
      "Epoch 15/30, train_loss: 0.00627, valid_loss: 0.00459\n",
      "Epoch 16/30, train_loss: 0.00616, valid_loss: 0.00455\n",
      "Epoch 17/30, train_loss: 0.00606, valid_loss: 0.00451\n",
      "Epoch 18/30, train_loss: 0.00597, valid_loss: 0.00453\n",
      "Epoch 19/30, train_loss: 0.00588, valid_loss: 0.00448\n",
      "Epoch 20/30, train_loss: 0.00579, valid_loss: 0.00447\n",
      "Epoch 21/30, train_loss: 0.00571, valid_loss: 0.00444\n",
      "Epoch 22/30, train_loss: 0.00564, valid_loss: 0.00439\n",
      "Epoch 23/30, train_loss: 0.00556, valid_loss: 0.00435\n",
      "Epoch 24/30, train_loss: 0.00549, valid_loss: 0.00430\n",
      "Epoch 25/30, train_loss: 0.00542, valid_loss: 0.00428\n",
      "Epoch 26/30, train_loss: 0.00535, valid_loss: 0.00430\n",
      "Epoch 27/30, train_loss: 0.00528, valid_loss: 0.00426\n",
      "Epoch 28/30, train_loss: 0.00523, valid_loss: 0.00422\n",
      "Epoch 29/30, train_loss: 0.00517, valid_loss: 0.00418\n",
      "Epoch 30/30, train_loss: 0.00511, valid_loss: 0.00414\n",
      "At step 10\n",
      "Epoch 1/30, train_loss: 0.00801, valid_loss: 0.00554\n",
      "Epoch 2/30, train_loss: 0.00688, valid_loss: 0.00595\n",
      "Epoch 3/30, train_loss: 0.00647, valid_loss: 0.00586\n",
      "Epoch 4/30, train_loss: 0.00625, valid_loss: 0.00591\n",
      "Epoch 5/30, train_loss: 0.00606, valid_loss: 0.00580\n",
      "Epoch 6/30, train_loss: 0.00593, valid_loss: 0.00570\n",
      "Epoch 7/30, train_loss: 0.00578, valid_loss: 0.00565\n",
      "Epoch 8/30, train_loss: 0.00568, valid_loss: 0.00558\n",
      "Epoch 9/30, train_loss: 0.00557, valid_loss: 0.00568\n",
      "Epoch 10/30, train_loss: 0.00547, valid_loss: 0.00553\n",
      "Epoch 11/30, train_loss: 0.00537, valid_loss: 0.00583\n",
      "Epoch 12/30, train_loss: 0.00530, valid_loss: 0.00580\n",
      "Epoch 13/30, train_loss: 0.00522, valid_loss: 0.00566\n",
      "Epoch 14/30, train_loss: 0.00514, valid_loss: 0.00561\n",
      "Epoch 15/30, train_loss: 0.00506, valid_loss: 0.00550\n",
      "Epoch 16/30, train_loss: 0.00499, valid_loss: 0.00542\n",
      "Epoch 17/30, train_loss: 0.00492, valid_loss: 0.00536\n",
      "Epoch 18/30, train_loss: 0.00486, valid_loss: 0.00532\n",
      "Epoch 19/30, train_loss: 0.00480, valid_loss: 0.00523\n",
      "Epoch 20/30, train_loss: 0.00475, valid_loss: 0.00515\n",
      "Epoch 21/30, train_loss: 0.00469, valid_loss: 0.00516\n",
      "Epoch 22/30, train_loss: 0.00466, valid_loss: 0.00510\n",
      "Epoch 23/30, train_loss: 0.00461, valid_loss: 0.00506\n",
      "Epoch 24/30, train_loss: 0.00457, valid_loss: 0.00500\n",
      "Epoch 25/30, train_loss: 0.00453, valid_loss: 0.00498\n",
      "Epoch 26/30, train_loss: 0.00450, valid_loss: 0.00496\n",
      "Epoch 27/30, train_loss: 0.00448, valid_loss: 0.00494\n",
      "Epoch 28/30, train_loss: 0.00445, valid_loss: 0.00492\n",
      "Epoch 29/30, train_loss: 0.00443, valid_loss: 0.00493\n",
      "Epoch 30/30, train_loss: 0.00440, valid_loss: 0.00490\n",
      "At step 9\n",
      "Epoch 1/30, train_loss: 0.01021, valid_loss: 0.00579\n",
      "Epoch 2/30, train_loss: 0.00830, valid_loss: 0.00566\n",
      "Epoch 3/30, train_loss: 0.00750, valid_loss: 0.00560\n",
      "Epoch 4/30, train_loss: 0.00705, valid_loss: 0.00551\n",
      "Epoch 5/30, train_loss: 0.00674, valid_loss: 0.00540\n",
      "Epoch 6/30, train_loss: 0.00648, valid_loss: 0.00566\n",
      "Epoch 7/30, train_loss: 0.00630, valid_loss: 0.00550\n",
      "Epoch 8/30, train_loss: 0.00610, valid_loss: 0.00537\n",
      "Epoch 9/30, train_loss: 0.00592, valid_loss: 0.00523\n",
      "Epoch 10/30, train_loss: 0.00580, valid_loss: 0.00511\n",
      "Epoch 11/30, train_loss: 0.00565, valid_loss: 0.00514\n",
      "Epoch 12/30, train_loss: 0.00552, valid_loss: 0.00503\n",
      "Epoch 13/30, train_loss: 0.00539, valid_loss: 0.00496\n",
      "Epoch 14/30, train_loss: 0.00528, valid_loss: 0.00487\n",
      "Epoch 15/30, train_loss: 0.00519, valid_loss: 0.00477\n",
      "Epoch 16/30, train_loss: 0.00510, valid_loss: 0.00470\n",
      "Epoch 17/30, train_loss: 0.00501, valid_loss: 0.00463\n",
      "Epoch 18/30, train_loss: 0.00494, valid_loss: 0.00456\n",
      "Epoch 19/30, train_loss: 0.00488, valid_loss: 0.00455\n",
      "Epoch 20/30, train_loss: 0.00482, valid_loss: 0.00449\n",
      "Epoch 21/30, train_loss: 0.00477, valid_loss: 0.00445\n",
      "Epoch 22/30, train_loss: 0.00472, valid_loss: 0.00440\n",
      "Epoch 23/30, train_loss: 0.00467, valid_loss: 0.00436\n",
      "Epoch 24/30, train_loss: 0.00463, valid_loss: 0.00432\n",
      "Epoch 25/30, train_loss: 0.00459, valid_loss: 0.00428\n",
      "Epoch 26/30, train_loss: 0.00455, valid_loss: 0.00428\n",
      "Epoch 27/30, train_loss: 0.00452, valid_loss: 0.00425\n",
      "Epoch 28/30, train_loss: 0.00448, valid_loss: 0.00422\n",
      "Epoch 29/30, train_loss: 0.00445, valid_loss: 0.00420\n",
      "Epoch 30/30, train_loss: 0.00442, valid_loss: 0.00417\n",
      "At step 8\n",
      "Epoch 1/30, train_loss: 0.00928, valid_loss: 0.00595\n",
      "Epoch 2/30, train_loss: 0.00786, valid_loss: 0.00586\n",
      "Epoch 3/30, train_loss: 0.00731, valid_loss: 0.00625\n",
      "Epoch 4/30, train_loss: 0.00695, valid_loss: 0.00605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, train_loss: 0.00676, valid_loss: 0.00589\n",
      "Epoch 6/30, train_loss: 0.00655, valid_loss: 0.00603\n",
      "Epoch 7/30, train_loss: 0.00637, valid_loss: 0.00585\n",
      "Epoch 8/30, train_loss: 0.00622, valid_loss: 0.00586\n",
      "Epoch 9/30, train_loss: 0.00611, valid_loss: 0.00572\n",
      "Epoch 10/30, train_loss: 0.00596, valid_loss: 0.00557\n",
      "Epoch 11/30, train_loss: 0.00582, valid_loss: 0.00545\n",
      "Epoch 12/30, train_loss: 0.00571, valid_loss: 0.00533\n",
      "Epoch 13/30, train_loss: 0.00560, valid_loss: 0.00524\n",
      "Epoch 14/30, train_loss: 0.00551, valid_loss: 0.00515\n",
      "Epoch 15/30, train_loss: 0.00544, valid_loss: 0.00506\n",
      "Epoch 16/30, train_loss: 0.00536, valid_loss: 0.00501\n",
      "Epoch 17/30, train_loss: 0.00530, valid_loss: 0.00494\n",
      "Epoch 18/30, train_loss: 0.00524, valid_loss: 0.00488\n",
      "Epoch 19/30, train_loss: 0.00519, valid_loss: 0.00484\n",
      "Epoch 20/30, train_loss: 0.00514, valid_loss: 0.00480\n",
      "Epoch 21/30, train_loss: 0.00509, valid_loss: 0.00475\n",
      "Epoch 22/30, train_loss: 0.00505, valid_loss: 0.00470\n",
      "Epoch 23/30, train_loss: 0.00501, valid_loss: 0.00466\n",
      "Epoch 24/30, train_loss: 0.00497, valid_loss: 0.00465\n",
      "Epoch 25/30, train_loss: 0.00493, valid_loss: 0.00461\n",
      "Epoch 26/30, train_loss: 0.00490, valid_loss: 0.00458\n",
      "Epoch 27/30, train_loss: 0.00486, valid_loss: 0.00455\n",
      "Epoch 28/30, train_loss: 0.00483, valid_loss: 0.00452\n",
      "Epoch 29/30, train_loss: 0.00480, valid_loss: 0.00450\n",
      "Epoch 30/30, train_loss: 0.00478, valid_loss: 0.00447\n",
      "At step 7\n",
      "Epoch 1/30, train_loss: 0.00869, valid_loss: 0.00671\n",
      "Epoch 2/30, train_loss: 0.00758, valid_loss: 0.00632\n",
      "Epoch 3/30, train_loss: 0.00721, valid_loss: 0.00632\n",
      "Epoch 4/30, train_loss: 0.00687, valid_loss: 0.00611\n",
      "Epoch 5/30, train_loss: 0.00661, valid_loss: 0.00588\n",
      "Epoch 6/30, train_loss: 0.00637, valid_loss: 0.00574\n",
      "Epoch 7/30, train_loss: 0.00617, valid_loss: 0.00556\n",
      "Epoch 8/30, train_loss: 0.00598, valid_loss: 0.00539\n",
      "Epoch 9/30, train_loss: 0.00581, valid_loss: 0.00527\n",
      "Epoch 10/30, train_loss: 0.00570, valid_loss: 0.00518\n",
      "Epoch 11/30, train_loss: 0.00558, valid_loss: 0.00522\n",
      "Epoch 12/30, train_loss: 0.00549, valid_loss: 0.00516\n",
      "Epoch 13/30, train_loss: 0.00541, valid_loss: 0.00509\n",
      "Epoch 14/30, train_loss: 0.00534, valid_loss: 0.00501\n",
      "Epoch 15/30, train_loss: 0.00526, valid_loss: 0.00495\n",
      "Epoch 16/30, train_loss: 0.00521, valid_loss: 0.00489\n",
      "Epoch 17/30, train_loss: 0.00516, valid_loss: 0.00483\n",
      "Epoch 18/30, train_loss: 0.00510, valid_loss: 0.00478\n",
      "Epoch 19/30, train_loss: 0.00505, valid_loss: 0.00473\n",
      "Epoch 20/30, train_loss: 0.00500, valid_loss: 0.00472\n",
      "Epoch 21/30, train_loss: 0.00496, valid_loss: 0.00474\n",
      "Epoch 22/30, train_loss: 0.00493, valid_loss: 0.00473\n",
      "Epoch 23/30, train_loss: 0.00489, valid_loss: 0.00469\n",
      "Epoch 24/30, train_loss: 0.00486, valid_loss: 0.00466\n",
      "Epoch 25/30, train_loss: 0.00483, valid_loss: 0.00463\n",
      "Epoch 26/30, train_loss: 0.00480, valid_loss: 0.00466\n",
      "Epoch 27/30, train_loss: 0.00477, valid_loss: 0.00464\n",
      "Epoch 28/30, train_loss: 0.00475, valid_loss: 0.00461\n",
      "Epoch 29/30, train_loss: 0.00472, valid_loss: 0.00458\n",
      "Epoch 30/30, train_loss: 0.00470, valid_loss: 0.00455\n",
      "At step 6\n",
      "Epoch 1/30, train_loss: 0.00931, valid_loss: 0.00692\n",
      "Epoch 2/30, train_loss: 0.00816, valid_loss: 0.00661\n",
      "Epoch 3/30, train_loss: 0.00763, valid_loss: 0.00635\n",
      "Epoch 4/30, train_loss: 0.00722, valid_loss: 0.00612\n",
      "Epoch 5/30, train_loss: 0.00694, valid_loss: 0.00647\n",
      "Epoch 6/30, train_loss: 0.00665, valid_loss: 0.00632\n",
      "Epoch 7/30, train_loss: 0.00644, valid_loss: 0.00636\n",
      "Epoch 8/30, train_loss: 0.00624, valid_loss: 0.00639\n",
      "Epoch 9/30, train_loss: 0.00609, valid_loss: 0.00639\n",
      "Epoch 10/30, train_loss: 0.00595, valid_loss: 0.00625\n",
      "Epoch 11/30, train_loss: 0.00585, valid_loss: 0.00613\n",
      "Epoch 12/30, train_loss: 0.00575, valid_loss: 0.00599\n",
      "Epoch 13/30, train_loss: 0.00566, valid_loss: 0.00600\n",
      "Epoch 14/30, train_loss: 0.00559, valid_loss: 0.00598\n",
      "Epoch 15/30, train_loss: 0.00553, valid_loss: 0.00589\n",
      "Epoch 16/30, train_loss: 0.00546, valid_loss: 0.00581\n",
      "Epoch 17/30, train_loss: 0.00540, valid_loss: 0.00572\n",
      "Epoch 18/30, train_loss: 0.00535, valid_loss: 0.00563\n",
      "Epoch 19/30, train_loss: 0.00531, valid_loss: 0.00559\n",
      "Epoch 20/30, train_loss: 0.00527, valid_loss: 0.00556\n",
      "Epoch 21/30, train_loss: 0.00523, valid_loss: 0.00551\n",
      "Epoch 22/30, train_loss: 0.00520, valid_loss: 0.00546\n",
      "Epoch 23/30, train_loss: 0.00516, valid_loss: 0.00541\n",
      "Epoch 24/30, train_loss: 0.00513, valid_loss: 0.00545\n",
      "Epoch 25/30, train_loss: 0.00511, valid_loss: 0.00545\n",
      "Epoch 26/30, train_loss: 0.00508, valid_loss: 0.00544\n",
      "Epoch 27/30, train_loss: 0.00506, valid_loss: 0.00539\n",
      "Epoch 28/30, train_loss: 0.00504, valid_loss: 0.00535\n",
      "Epoch 29/30, train_loss: 0.00501, valid_loss: 0.00532\n",
      "Epoch 30/30, train_loss: 0.00499, valid_loss: 0.00528\n",
      "At step 5\n",
      "Epoch 1/30, train_loss: 0.01070, valid_loss: 0.00773\n",
      "Epoch 2/30, train_loss: 0.00912, valid_loss: 0.00732\n",
      "Epoch 3/30, train_loss: 0.00849, valid_loss: 0.00703\n",
      "Epoch 4/30, train_loss: 0.00802, valid_loss: 0.00699\n",
      "Epoch 5/30, train_loss: 0.00765, valid_loss: 0.00692\n",
      "Epoch 6/30, train_loss: 0.00741, valid_loss: 0.00676\n",
      "Epoch 7/30, train_loss: 0.00716, valid_loss: 0.00656\n",
      "Epoch 8/30, train_loss: 0.00696, valid_loss: 0.00656\n",
      "Epoch 9/30, train_loss: 0.00680, valid_loss: 0.00640\n",
      "Epoch 10/30, train_loss: 0.00667, valid_loss: 0.00629\n",
      "Epoch 11/30, train_loss: 0.00655, valid_loss: 0.00624\n",
      "Epoch 12/30, train_loss: 0.00646, valid_loss: 0.00615\n",
      "Epoch 13/30, train_loss: 0.00637, valid_loss: 0.00608\n",
      "Epoch 14/30, train_loss: 0.00629, valid_loss: 0.00604\n",
      "Epoch 15/30, train_loss: 0.00622, valid_loss: 0.00596\n",
      "Epoch 16/30, train_loss: 0.00617, valid_loss: 0.00590\n",
      "Epoch 17/30, train_loss: 0.00611, valid_loss: 0.00587\n",
      "Epoch 18/30, train_loss: 0.00606, valid_loss: 0.00582\n",
      "Epoch 19/30, train_loss: 0.00602, valid_loss: 0.00577\n",
      "Epoch 20/30, train_loss: 0.00597, valid_loss: 0.00573\n",
      "Epoch 21/30, train_loss: 0.00594, valid_loss: 0.00570\n",
      "Epoch 22/30, train_loss: 0.00590, valid_loss: 0.00568\n",
      "Epoch 23/30, train_loss: 0.00587, valid_loss: 0.00565\n",
      "Epoch 24/30, train_loss: 0.00584, valid_loss: 0.00561\n",
      "Epoch 25/30, train_loss: 0.00581, valid_loss: 0.00558\n",
      "Epoch 26/30, train_loss: 0.00578, valid_loss: 0.00557\n",
      "Epoch 27/30, train_loss: 0.00575, valid_loss: 0.00556\n",
      "Epoch 28/30, train_loss: 0.00573, valid_loss: 0.00558\n",
      "Epoch 29/30, train_loss: 0.00570, valid_loss: 0.00555\n",
      "Epoch 30/30, train_loss: 0.00568, valid_loss: 0.00553\n",
      "At step 4\n",
      "Epoch 1/30, train_loss: 0.01061, valid_loss: 0.00724\n",
      "Epoch 2/30, train_loss: 0.00909, valid_loss: 0.00708\n",
      "Epoch 3/30, train_loss: 0.00837, valid_loss: 0.00678\n",
      "Epoch 4/30, train_loss: 0.00790, valid_loss: 0.00656\n",
      "Epoch 5/30, train_loss: 0.00752, valid_loss: 0.00653\n",
      "Epoch 6/30, train_loss: 0.00720, valid_loss: 0.00673\n",
      "Epoch 7/30, train_loss: 0.00695, valid_loss: 0.00648\n",
      "Epoch 8/30, train_loss: 0.00674, valid_loss: 0.00633\n",
      "Epoch 9/30, train_loss: 0.00655, valid_loss: 0.00617\n",
      "Epoch 10/30, train_loss: 0.00640, valid_loss: 0.00615\n",
      "Epoch 11/30, train_loss: 0.00628, valid_loss: 0.00601\n",
      "Epoch 12/30, train_loss: 0.00617, valid_loss: 0.00590\n",
      "Epoch 13/30, train_loss: 0.00608, valid_loss: 0.00579\n",
      "Epoch 14/30, train_loss: 0.00600, valid_loss: 0.00571\n",
      "Epoch 15/30, train_loss: 0.00592, valid_loss: 0.00563\n",
      "Epoch 16/30, train_loss: 0.00585, valid_loss: 0.00557\n",
      "Epoch 17/30, train_loss: 0.00579, valid_loss: 0.00550\n",
      "Epoch 18/30, train_loss: 0.00573, valid_loss: 0.00545\n",
      "Epoch 19/30, train_loss: 0.00568, valid_loss: 0.00542\n",
      "Epoch 20/30, train_loss: 0.00563, valid_loss: 0.00539\n",
      "Epoch 21/30, train_loss: 0.00560, valid_loss: 0.00535\n",
      "Epoch 22/30, train_loss: 0.00556, valid_loss: 0.00531\n",
      "Epoch 23/30, train_loss: 0.00552, valid_loss: 0.00528\n",
      "Epoch 24/30, train_loss: 0.00549, valid_loss: 0.00527\n",
      "Epoch 25/30, train_loss: 0.00546, valid_loss: 0.00523\n",
      "Epoch 26/30, train_loss: 0.00543, valid_loss: 0.00521\n",
      "Epoch 27/30, train_loss: 0.00540, valid_loss: 0.00520\n",
      "Epoch 28/30, train_loss: 0.00537, valid_loss: 0.00517\n",
      "Epoch 29/30, train_loss: 0.00535, valid_loss: 0.00514\n",
      "Epoch 30/30, train_loss: 0.00533, valid_loss: 0.00512\n",
      "At step 3\n",
      "Epoch 1/30, train_loss: 0.00846, valid_loss: 0.00683\n",
      "Epoch 2/30, train_loss: 0.00781, valid_loss: 0.00656\n",
      "Epoch 3/30, train_loss: 0.00747, valid_loss: 0.00643\n",
      "Epoch 4/30, train_loss: 0.00719, valid_loss: 0.00618\n",
      "Epoch 5/30, train_loss: 0.00697, valid_loss: 0.00598\n",
      "Epoch 6/30, train_loss: 0.00676, valid_loss: 0.00597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, train_loss: 0.00660, valid_loss: 0.00585\n",
      "Epoch 8/30, train_loss: 0.00646, valid_loss: 0.00581\n",
      "Epoch 9/30, train_loss: 0.00634, valid_loss: 0.00575\n",
      "Epoch 10/30, train_loss: 0.00625, valid_loss: 0.00568\n",
      "Epoch 11/30, train_loss: 0.00616, valid_loss: 0.00560\n",
      "Epoch 12/30, train_loss: 0.00609, valid_loss: 0.00556\n",
      "Epoch 13/30, train_loss: 0.00602, valid_loss: 0.00550\n",
      "Epoch 14/30, train_loss: 0.00596, valid_loss: 0.00546\n",
      "Epoch 15/30, train_loss: 0.00591, valid_loss: 0.00548\n",
      "Epoch 16/30, train_loss: 0.00586, valid_loss: 0.00547\n",
      "Epoch 17/30, train_loss: 0.00583, valid_loss: 0.00543\n",
      "Epoch 18/30, train_loss: 0.00579, valid_loss: 0.00540\n",
      "Epoch 19/30, train_loss: 0.00576, valid_loss: 0.00539\n",
      "Epoch 20/30, train_loss: 0.00574, valid_loss: 0.00536\n",
      "Epoch 21/30, train_loss: 0.00571, valid_loss: 0.00533\n",
      "Epoch 22/30, train_loss: 0.00568, valid_loss: 0.00532\n",
      "Epoch 23/30, train_loss: 0.00566, valid_loss: 0.00530\n",
      "Epoch 24/30, train_loss: 0.00564, valid_loss: 0.00534\n",
      "Epoch 25/30, train_loss: 0.00562, valid_loss: 0.00531\n",
      "Epoch 26/30, train_loss: 0.00560, valid_loss: 0.00530\n",
      "Epoch 27/30, train_loss: 0.00558, valid_loss: 0.00528\n",
      "Epoch 28/30, train_loss: 0.00557, valid_loss: 0.00527\n",
      "Epoch 29/30, train_loss: 0.00555, valid_loss: 0.00525\n",
      "Epoch 30/30, train_loss: 0.00553, valid_loss: 0.00523\n",
      "At step 2\n",
      "Epoch 1/30, train_loss: 0.01042, valid_loss: 0.00803\n",
      "Epoch 2/30, train_loss: 0.00903, valid_loss: 0.00846\n",
      "Epoch 3/30, train_loss: 0.00836, valid_loss: 0.00780\n",
      "Epoch 4/30, train_loss: 0.00794, valid_loss: 0.00737\n",
      "Epoch 5/30, train_loss: 0.00762, valid_loss: 0.00725\n",
      "Epoch 6/30, train_loss: 0.00736, valid_loss: 0.00697\n",
      "Epoch 7/30, train_loss: 0.00717, valid_loss: 0.00701\n",
      "Epoch 8/30, train_loss: 0.00699, valid_loss: 0.00682\n",
      "Epoch 9/30, train_loss: 0.00686, valid_loss: 0.00683\n",
      "Epoch 10/30, train_loss: 0.00676, valid_loss: 0.00669\n",
      "Epoch 11/30, train_loss: 0.00666, valid_loss: 0.00660\n",
      "Epoch 12/30, train_loss: 0.00658, valid_loss: 0.00655\n",
      "Epoch 13/30, train_loss: 0.00651, valid_loss: 0.00658\n",
      "Epoch 14/30, train_loss: 0.00645, valid_loss: 0.00651\n",
      "Epoch 15/30, train_loss: 0.00639, valid_loss: 0.00644\n",
      "Epoch 16/30, train_loss: 0.00634, valid_loss: 0.00637\n",
      "Epoch 17/30, train_loss: 0.00630, valid_loss: 0.00631\n",
      "Epoch 18/30, train_loss: 0.00626, valid_loss: 0.00630\n",
      "Epoch 19/30, train_loss: 0.00622, valid_loss: 0.00624\n",
      "Epoch 20/30, train_loss: 0.00618, valid_loss: 0.00620\n",
      "Epoch 21/30, train_loss: 0.00615, valid_loss: 0.00616\n",
      "Epoch 22/30, train_loss: 0.00612, valid_loss: 0.00612\n",
      "Epoch 23/30, train_loss: 0.00610, valid_loss: 0.00609\n",
      "Epoch 24/30, train_loss: 0.00607, valid_loss: 0.00606\n",
      "Epoch 25/30, train_loss: 0.00605, valid_loss: 0.00604\n",
      "Epoch 26/30, train_loss: 0.00602, valid_loss: 0.00602\n",
      "Epoch 27/30, train_loss: 0.00600, valid_loss: 0.00599\n",
      "Epoch 28/30, train_loss: 0.00598, valid_loss: 0.00596\n",
      "Epoch 29/30, train_loss: 0.00597, valid_loss: 0.00594\n",
      "Epoch 30/30, train_loss: 0.00595, valid_loss: 0.00592\n",
      "Wall time: 7min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prc_nn_50k=Bermudan_swaption_nn(lockout,maturity,sim_rates_50k,strike,n_epochs,batch_size,learningrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European swaption pirce: 0.006957211172997507\n",
      "Bermudan swaption pirce: 0.008736022270762402\n",
      "Excercise Probability Table\n",
      "    Time_step  ex_prob_Euro  ex_prob_RLNN\n",
      "0           2       0.70758       0.47896\n",
      "1           3       0.00000       0.18346\n",
      "2           4       0.00000       0.07664\n",
      "3           5       0.00000       0.03104\n",
      "4           6       0.00000       0.01172\n",
      "5           7       0.00000       0.00696\n",
      "6           8       0.00000       0.00464\n",
      "7           9       0.00000       0.00294\n",
      "8          10       0.00000       0.00278\n",
      "9          11       0.00000       0.00214\n",
      "10         12       0.00000       0.00210\n",
      "11         13       0.00000       0.00260\n",
      "12         14       0.00000       0.00198\n",
      "13         15       0.00000       0.00318\n",
      "14         16       0.00000       0.00240\n",
      "15         17       0.00000       0.00340\n",
      "16         18       0.00000       0.00386\n",
      "17         19       0.00000       0.00538\n"
     ]
    }
   ],
   "source": [
    "print_result(prc_nn_50k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prc_xgb_50k=Bermudan_swaption_xgboost_fixed(lockout,maturity,sim_rates_50k,strike,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European swaption pirce: 0.006957211172997507\n",
      "Bermudan swaption pirce: 0.007610787242401477\n",
      "Excercise Probability Table\n",
      "    Time_step  ex_prob_Euro  ex_prob_xgb\n",
      "0           2       0.70758      0.59854\n",
      "1           3       0.00000      0.06252\n",
      "2           4       0.00000      0.02670\n",
      "3           5       0.00000      0.01256\n",
      "4           6       0.00000      0.00900\n",
      "5           7       0.00000      0.00542\n",
      "6           8       0.00000      0.00374\n",
      "7           9       0.00000      0.00276\n",
      "8          10       0.00000      0.00274\n",
      "9          11       0.00000      0.00226\n",
      "10         12       0.00000      0.00264\n",
      "11         13       0.00000      0.00244\n",
      "12         14       0.00000      0.00324\n",
      "13         15       0.00000      0.00320\n",
      "14         16       0.00000      0.00438\n",
      "15         17       0.00000      0.00484\n",
      "16         18       0.00000      0.00658\n",
      "17         19       0.00000      0.00814\n"
     ]
    }
   ],
   "source": [
    "print_result(prc_xgb_50k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prc_xgb_100k=Bermudan_swaption_xgboost_fixed(lockout,maturity,sim_rates_100k,strike,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European swaption pirce: 0.006951267551339664\n",
      "Bermudan swaption pirce: 0.00759590453251837\n",
      "Excercise Probability Table\n",
      "    Time_step  ex_prob_Euro  ex_prob_xgb\n",
      "0           2       0.70762      0.60643\n",
      "1           3       0.00000      0.05901\n",
      "2           4       0.00000      0.02438\n",
      "3           5       0.00000      0.01325\n",
      "4           6       0.00000      0.00858\n",
      "5           7       0.00000      0.00575\n",
      "6           8       0.00000      0.00388\n",
      "7           9       0.00000      0.00301\n",
      "8          10       0.00000      0.00269\n",
      "9          11       0.00000      0.00207\n",
      "10         12       0.00000      0.00255\n",
      "11         13       0.00000      0.00276\n",
      "12         14       0.00000      0.00297\n",
      "13         15       0.00000      0.00331\n",
      "14         16       0.00000      0.00437\n",
      "15         17       0.00000      0.00443\n",
      "16         18       0.00000      0.00657\n",
      "17         19       0.00000      0.00835\n"
     ]
    }
   ],
   "source": [
    "print_result(prc_xgb_100k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prc_lsm_100k=Bermudan_swaption_lsm(lockout,maturity,sim_rates_100k,strike,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European swaption pirce: 0.006951267551339664\n",
      "Bermudan swaption pirce: 0.0075140211438522115\n",
      "Excercise Probability Table\n",
      "    Time_step  ex_prob_Euro  ex_prob_LSM\n",
      "0           2       0.70762      0.44322\n",
      "1           3       0.00000      0.06226\n",
      "2           4       0.00000      0.02828\n",
      "3           5       0.00000      0.01571\n",
      "4           6       0.00000      0.01034\n",
      "5           7       0.00000      0.00733\n",
      "6           8       0.00000      0.00581\n",
      "7           9       0.00000      0.00491\n",
      "8          10       0.00000      0.00370\n",
      "9          11       0.00000      0.00405\n",
      "10         12       0.00000      0.00407\n",
      "11         13       0.00000      0.00436\n",
      "12         14       0.00000      0.00515\n",
      "13         15       0.00000      0.00511\n",
      "14         16       0.00000      0.00648\n",
      "15         17       0.00000      0.00898\n",
      "16         18       0.00000      0.01666\n",
      "17         19       0.00000      0.01147\n"
     ]
    }
   ],
   "source": [
    "print_result(prc_lsm_100k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 18\n",
      "Epoch 1/30, train_loss: 0.00910, valid_loss: 0.00089\n",
      "Epoch 2/30, train_loss: 0.00647, valid_loss: 0.00094\n",
      "Epoch 3/30, train_loss: 0.00531, valid_loss: 0.00094\n",
      "Epoch 4/30, train_loss: 0.00462, valid_loss: 0.00096\n",
      "Epoch 5/30, train_loss: 0.00415, valid_loss: 0.00096\n",
      "Epoch 6/30, train_loss: 0.00381, valid_loss: 0.00107\n",
      "Epoch 7/30, train_loss: 0.00355, valid_loss: 0.00106\n",
      "Epoch 8/30, train_loss: 0.00334, valid_loss: 0.00103\n",
      "Epoch 9/30, train_loss: 0.00318, valid_loss: 0.00121\n",
      "Epoch 10/30, train_loss: 0.00304, valid_loss: 0.00120\n",
      "Epoch 11/30, train_loss: 0.00292, valid_loss: 0.00124\n",
      "Epoch 12/30, train_loss: 0.00282, valid_loss: 0.00131\n",
      "Epoch 13/30, train_loss: 0.00273, valid_loss: 0.00131\n",
      "Epoch 14/30, train_loss: 0.00265, valid_loss: 0.00137\n",
      "Epoch 15/30, train_loss: 0.00258, valid_loss: 0.00135\n",
      "Epoch 16/30, train_loss: 0.00251, valid_loss: 0.00132\n",
      "Epoch 17/30, train_loss: 0.00245, valid_loss: 0.00133\n",
      "Epoch 18/30, train_loss: 0.00239, valid_loss: 0.00132\n",
      "Epoch 19/30, train_loss: 0.00234, valid_loss: 0.00129\n",
      "Epoch 20/30, train_loss: 0.00231, valid_loss: 0.00128\n",
      "Epoch 21/30, train_loss: 0.00226, valid_loss: 0.00125\n",
      "Epoch 22/30, train_loss: 0.00222, valid_loss: 0.00124\n",
      "Epoch 23/30, train_loss: 0.00217, valid_loss: 0.00122\n",
      "Epoch 24/30, train_loss: 0.00214, valid_loss: 0.00122\n",
      "Epoch 25/30, train_loss: 0.00210, valid_loss: 0.00121\n",
      "Epoch 26/30, train_loss: 0.00207, valid_loss: 0.00120\n",
      "Epoch 27/30, train_loss: 0.00203, valid_loss: 0.00119\n",
      "Epoch 28/30, train_loss: 0.00200, valid_loss: 0.00119\n",
      "Epoch 29/30, train_loss: 0.00197, valid_loss: 0.00118\n",
      "Epoch 30/30, train_loss: 0.00195, valid_loss: 0.00117\n",
      "At step 17\n",
      "Epoch 1/30, train_loss: 0.00388, valid_loss: 0.00147\n",
      "Epoch 2/30, train_loss: 0.00295, valid_loss: 0.00150\n",
      "Epoch 3/30, train_loss: 0.00256, valid_loss: 0.00179\n",
      "Epoch 4/30, train_loss: 0.00237, valid_loss: 0.00176\n",
      "Epoch 5/30, train_loss: 0.00224, valid_loss: 0.00168\n",
      "Epoch 6/30, train_loss: 0.00216, valid_loss: 0.00162\n",
      "Epoch 7/30, train_loss: 0.00208, valid_loss: 0.00162\n",
      "Epoch 8/30, train_loss: 0.00202, valid_loss: 0.00157\n",
      "Epoch 9/30, train_loss: 0.00196, valid_loss: 0.00153\n",
      "Epoch 10/30, train_loss: 0.00191, valid_loss: 0.00149\n",
      "Epoch 11/30, train_loss: 0.00187, valid_loss: 0.00145\n",
      "Epoch 12/30, train_loss: 0.00183, valid_loss: 0.00143\n",
      "Epoch 13/30, train_loss: 0.00179, valid_loss: 0.00142\n",
      "Epoch 14/30, train_loss: 0.00176, valid_loss: 0.00139\n",
      "Epoch 15/30, train_loss: 0.00172, valid_loss: 0.00137\n",
      "Epoch 16/30, train_loss: 0.00170, valid_loss: 0.00134\n",
      "Epoch 17/30, train_loss: 0.00167, valid_loss: 0.00132\n",
      "Epoch 18/30, train_loss: 0.00164, valid_loss: 0.00131\n",
      "Epoch 19/30, train_loss: 0.00161, valid_loss: 0.00130\n",
      "Epoch 20/30, train_loss: 0.00159, valid_loss: 0.00130\n",
      "Epoch 21/30, train_loss: 0.00157, valid_loss: 0.00129\n",
      "Epoch 22/30, train_loss: 0.00155, valid_loss: 0.00128\n",
      "Epoch 23/30, train_loss: 0.00154, valid_loss: 0.00129\n",
      "Epoch 24/30, train_loss: 0.00153, valid_loss: 0.00131\n",
      "Epoch 25/30, train_loss: 0.00152, valid_loss: 0.00131\n",
      "Epoch 26/30, train_loss: 0.00151, valid_loss: 0.00131\n",
      "Epoch 27/30, train_loss: 0.00151, valid_loss: 0.00130\n",
      "Epoch 28/30, train_loss: 0.00150, valid_loss: 0.00129\n",
      "Epoch 29/30, train_loss: 0.00149, valid_loss: 0.00129\n",
      "Epoch 30/30, train_loss: 0.00147, valid_loss: 0.00127\n",
      "At step 16\n",
      "Epoch 1/30, train_loss: 0.00413, valid_loss: 0.00216\n",
      "Epoch 2/30, train_loss: 0.00336, valid_loss: 0.00242\n",
      "Epoch 3/30, train_loss: 0.00310, valid_loss: 0.00238\n",
      "Epoch 4/30, train_loss: 0.00295, valid_loss: 0.00229\n",
      "Epoch 5/30, train_loss: 0.00284, valid_loss: 0.00243\n",
      "Epoch 6/30, train_loss: 0.00273, valid_loss: 0.00244\n",
      "Epoch 7/30, train_loss: 0.00265, valid_loss: 0.00236\n",
      "Epoch 8/30, train_loss: 0.00259, valid_loss: 0.00230\n",
      "Epoch 9/30, train_loss: 0.00254, valid_loss: 0.00230\n",
      "Epoch 10/30, train_loss: 0.00249, valid_loss: 0.00226\n",
      "Epoch 11/30, train_loss: 0.00245, valid_loss: 0.00220\n",
      "Epoch 12/30, train_loss: 0.00241, valid_loss: 0.00218\n",
      "Epoch 13/30, train_loss: 0.00237, valid_loss: 0.00213\n",
      "Epoch 14/30, train_loss: 0.00233, valid_loss: 0.00208\n",
      "Epoch 15/30, train_loss: 0.00229, valid_loss: 0.00204\n",
      "Epoch 16/30, train_loss: 0.00225, valid_loss: 0.00200\n",
      "Epoch 17/30, train_loss: 0.00221, valid_loss: 0.00198\n",
      "Epoch 18/30, train_loss: 0.00219, valid_loss: 0.00195\n",
      "Epoch 19/30, train_loss: 0.00215, valid_loss: 0.00196\n",
      "Epoch 20/30, train_loss: 0.00213, valid_loss: 0.00193\n",
      "Epoch 21/30, train_loss: 0.00210, valid_loss: 0.00194\n",
      "Epoch 22/30, train_loss: 0.00207, valid_loss: 0.00193\n",
      "Epoch 23/30, train_loss: 0.00205, valid_loss: 0.00191\n",
      "Epoch 24/30, train_loss: 0.00202, valid_loss: 0.00191\n",
      "Epoch 25/30, train_loss: 0.00200, valid_loss: 0.00190\n",
      "Epoch 26/30, train_loss: 0.00198, valid_loss: 0.00188\n",
      "Epoch 27/30, train_loss: 0.00196, valid_loss: 0.00185\n",
      "Epoch 28/30, train_loss: 0.00194, valid_loss: 0.00183\n",
      "Epoch 29/30, train_loss: 0.00192, valid_loss: 0.00181\n",
      "Epoch 30/30, train_loss: 0.00190, valid_loss: 0.00180\n",
      "At step 15\n",
      "Epoch 1/30, train_loss: 0.01859, valid_loss: 0.00288\n",
      "Epoch 2/30, train_loss: 0.01330, valid_loss: 0.00286\n",
      "Epoch 3/30, train_loss: 0.01098, valid_loss: 0.00285\n",
      "Epoch 4/30, train_loss: 0.00961, valid_loss: 0.00285\n",
      "Epoch 5/30, train_loss: 0.00869, valid_loss: 0.00283\n",
      "Epoch 6/30, train_loss: 0.00801, valid_loss: 0.00288\n",
      "Epoch 7/30, train_loss: 0.00749, valid_loss: 0.00286\n",
      "Epoch 8/30, train_loss: 0.00708, valid_loss: 0.00284\n",
      "Epoch 9/30, train_loss: 0.00673, valid_loss: 0.00282\n",
      "Epoch 10/30, train_loss: 0.00644, valid_loss: 0.00283\n",
      "Epoch 11/30, train_loss: 0.00620, valid_loss: 0.00281\n",
      "Epoch 12/30, train_loss: 0.00599, valid_loss: 0.00281\n",
      "Epoch 13/30, train_loss: 0.00580, valid_loss: 0.00278\n",
      "Epoch 14/30, train_loss: 0.00563, valid_loss: 0.00275\n",
      "Epoch 15/30, train_loss: 0.00548, valid_loss: 0.00272\n",
      "Epoch 16/30, train_loss: 0.00534, valid_loss: 0.00270\n",
      "Epoch 17/30, train_loss: 0.00521, valid_loss: 0.00268\n",
      "Epoch 18/30, train_loss: 0.00510, valid_loss: 0.00265\n",
      "Epoch 19/30, train_loss: 0.00499, valid_loss: 0.00264\n",
      "Epoch 20/30, train_loss: 0.00489, valid_loss: 0.00261\n",
      "Epoch 21/30, train_loss: 0.00480, valid_loss: 0.00258\n",
      "Epoch 22/30, train_loss: 0.00471, valid_loss: 0.00256\n",
      "Epoch 23/30, train_loss: 0.00463, valid_loss: 0.00254\n",
      "Epoch 24/30, train_loss: 0.00455, valid_loss: 0.00251\n",
      "Epoch 25/30, train_loss: 0.00447, valid_loss: 0.00250\n",
      "Epoch 26/30, train_loss: 0.00440, valid_loss: 0.00247\n",
      "Epoch 27/30, train_loss: 0.00434, valid_loss: 0.00245\n",
      "Epoch 28/30, train_loss: 0.00428, valid_loss: 0.00245\n",
      "Epoch 29/30, train_loss: 0.00422, valid_loss: 0.00244\n",
      "Epoch 30/30, train_loss: 0.00416, valid_loss: 0.00243\n",
      "At step 14\n",
      "Epoch 1/30, train_loss: 0.00554, valid_loss: 0.00323\n",
      "Epoch 2/30, train_loss: 0.00455, valid_loss: 0.00333\n",
      "Epoch 3/30, train_loss: 0.00416, valid_loss: 0.00329\n",
      "Epoch 4/30, train_loss: 0.00394, valid_loss: 0.00318\n",
      "Epoch 5/30, train_loss: 0.00377, valid_loss: 0.00309\n",
      "Epoch 6/30, train_loss: 0.00363, valid_loss: 0.00312\n",
      "Epoch 7/30, train_loss: 0.00351, valid_loss: 0.00332\n",
      "Epoch 8/30, train_loss: 0.00341, valid_loss: 0.00328\n",
      "Epoch 9/30, train_loss: 0.00329, valid_loss: 0.00316\n",
      "Epoch 10/30, train_loss: 0.00321, valid_loss: 0.00308\n",
      "Epoch 11/30, train_loss: 0.00313, valid_loss: 0.00303\n",
      "Epoch 12/30, train_loss: 0.00306, valid_loss: 0.00299\n",
      "Epoch 13/30, train_loss: 0.00299, valid_loss: 0.00292\n",
      "Epoch 14/30, train_loss: 0.00293, valid_loss: 0.00285\n",
      "Epoch 15/30, train_loss: 0.00288, valid_loss: 0.00282\n",
      "Epoch 16/30, train_loss: 0.00283, valid_loss: 0.00277\n",
      "Epoch 17/30, train_loss: 0.00278, valid_loss: 0.00271\n",
      "Epoch 18/30, train_loss: 0.00275, valid_loss: 0.00267\n",
      "Epoch 19/30, train_loss: 0.00271, valid_loss: 0.00269\n",
      "Epoch 20/30, train_loss: 0.00268, valid_loss: 0.00265\n",
      "Epoch 21/30, train_loss: 0.00265, valid_loss: 0.00261\n",
      "Epoch 22/30, train_loss: 0.00261, valid_loss: 0.00262\n",
      "Epoch 23/30, train_loss: 0.00259, valid_loss: 0.00259\n",
      "Epoch 24/30, train_loss: 0.00256, valid_loss: 0.00256\n",
      "Epoch 25/30, train_loss: 0.00254, valid_loss: 0.00256\n",
      "Epoch 26/30, train_loss: 0.00252, valid_loss: 0.00254\n",
      "Epoch 27/30, train_loss: 0.00250, valid_loss: 0.00253\n",
      "Epoch 28/30, train_loss: 0.00248, valid_loss: 0.00250\n",
      "Epoch 29/30, train_loss: 0.00246, valid_loss: 0.00248\n",
      "Epoch 30/30, train_loss: 0.00245, valid_loss: 0.00248\n",
      "At step 13\n",
      "Epoch 1/30, train_loss: 0.01405, valid_loss: 0.00410\n",
      "Epoch 2/30, train_loss: 0.01035, valid_loss: 0.00409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, train_loss: 0.00878, valid_loss: 0.00407\n",
      "Epoch 4/30, train_loss: 0.00788, valid_loss: 0.00404\n",
      "Epoch 5/30, train_loss: 0.00727, valid_loss: 0.00402\n",
      "Epoch 6/30, train_loss: 0.00683, valid_loss: 0.00397\n",
      "Epoch 7/30, train_loss: 0.00649, valid_loss: 0.00399\n",
      "Epoch 8/30, train_loss: 0.00621, valid_loss: 0.00392\n",
      "Epoch 9/30, train_loss: 0.00598, valid_loss: 0.00386\n",
      "Epoch 10/30, train_loss: 0.00578, valid_loss: 0.00379\n",
      "Epoch 11/30, train_loss: 0.00560, valid_loss: 0.00372\n",
      "Epoch 12/30, train_loss: 0.00544, valid_loss: 0.00364\n",
      "Epoch 13/30, train_loss: 0.00530, valid_loss: 0.00359\n",
      "Epoch 14/30, train_loss: 0.00517, valid_loss: 0.00355\n",
      "Epoch 15/30, train_loss: 0.00504, valid_loss: 0.00352\n",
      "Epoch 16/30, train_loss: 0.00494, valid_loss: 0.00349\n",
      "Epoch 17/30, train_loss: 0.00484, valid_loss: 0.00344\n",
      "Epoch 18/30, train_loss: 0.00475, valid_loss: 0.00339\n",
      "Epoch 19/30, train_loss: 0.00467, valid_loss: 0.00335\n",
      "Epoch 20/30, train_loss: 0.00460, valid_loss: 0.00333\n",
      "Epoch 21/30, train_loss: 0.00453, valid_loss: 0.00330\n",
      "Epoch 22/30, train_loss: 0.00446, valid_loss: 0.00329\n",
      "Epoch 23/30, train_loss: 0.00440, valid_loss: 0.00326\n",
      "Epoch 24/30, train_loss: 0.00434, valid_loss: 0.00323\n",
      "Epoch 25/30, train_loss: 0.00429, valid_loss: 0.00320\n",
      "Epoch 26/30, train_loss: 0.00424, valid_loss: 0.00318\n",
      "Epoch 27/30, train_loss: 0.00419, valid_loss: 0.00326\n",
      "Epoch 28/30, train_loss: 0.00414, valid_loss: 0.00325\n",
      "Epoch 29/30, train_loss: 0.00410, valid_loss: 0.00324\n",
      "Epoch 30/30, train_loss: 0.00406, valid_loss: 0.00322\n",
      "At step 12\n",
      "Epoch 1/30, train_loss: 0.01459, valid_loss: 0.00508\n",
      "Epoch 2/30, train_loss: 0.01083, valid_loss: 0.00484\n",
      "Epoch 3/30, train_loss: 0.00923, valid_loss: 0.00468\n",
      "Epoch 4/30, train_loss: 0.00830, valid_loss: 0.00465\n",
      "Epoch 5/30, train_loss: 0.00766, valid_loss: 0.00455\n",
      "Epoch 6/30, train_loss: 0.00718, valid_loss: 0.00446\n",
      "Epoch 7/30, train_loss: 0.00679, valid_loss: 0.00434\n",
      "Epoch 8/30, train_loss: 0.00647, valid_loss: 0.00422\n",
      "Epoch 9/30, train_loss: 0.00619, valid_loss: 0.00408\n",
      "Epoch 10/30, train_loss: 0.00596, valid_loss: 0.00396\n",
      "Epoch 11/30, train_loss: 0.00575, valid_loss: 0.00388\n",
      "Epoch 12/30, train_loss: 0.00556, valid_loss: 0.00384\n",
      "Epoch 13/30, train_loss: 0.00540, valid_loss: 0.00378\n",
      "Epoch 14/30, train_loss: 0.00525, valid_loss: 0.00370\n",
      "Epoch 15/30, train_loss: 0.00512, valid_loss: 0.00363\n",
      "Epoch 16/30, train_loss: 0.00501, valid_loss: 0.00358\n",
      "Epoch 17/30, train_loss: 0.00490, valid_loss: 0.00352\n",
      "Epoch 18/30, train_loss: 0.00480, valid_loss: 0.00346\n",
      "Epoch 19/30, train_loss: 0.00471, valid_loss: 0.00341\n",
      "Epoch 20/30, train_loss: 0.00463, valid_loss: 0.00337\n",
      "Epoch 21/30, train_loss: 0.00455, valid_loss: 0.00339\n",
      "Epoch 22/30, train_loss: 0.00448, valid_loss: 0.00335\n",
      "Epoch 23/30, train_loss: 0.00442, valid_loss: 0.00336\n",
      "Epoch 24/30, train_loss: 0.00436, valid_loss: 0.00336\n",
      "Epoch 25/30, train_loss: 0.00431, valid_loss: 0.00333\n",
      "Epoch 26/30, train_loss: 0.00425, valid_loss: 0.00331\n",
      "Epoch 27/30, train_loss: 0.00420, valid_loss: 0.00328\n",
      "Epoch 28/30, train_loss: 0.00415, valid_loss: 0.00326\n",
      "Epoch 29/30, train_loss: 0.00411, valid_loss: 0.00323\n",
      "Epoch 30/30, train_loss: 0.00407, valid_loss: 0.00322\n",
      "At step 11\n",
      "Epoch 1/30, train_loss: 0.00870, valid_loss: 0.00464\n",
      "Epoch 2/30, train_loss: 0.00699, valid_loss: 0.00459\n",
      "Epoch 3/30, train_loss: 0.00629, valid_loss: 0.00463\n",
      "Epoch 4/30, train_loss: 0.00589, valid_loss: 0.00454\n",
      "Epoch 5/30, train_loss: 0.00561, valid_loss: 0.00452\n",
      "Epoch 6/30, train_loss: 0.00538, valid_loss: 0.00443\n",
      "Epoch 7/30, train_loss: 0.00518, valid_loss: 0.00428\n",
      "Epoch 8/30, train_loss: 0.00499, valid_loss: 0.00419\n",
      "Epoch 9/30, train_loss: 0.00483, valid_loss: 0.00415\n",
      "Epoch 10/30, train_loss: 0.00469, valid_loss: 0.00404\n",
      "Epoch 11/30, train_loss: 0.00456, valid_loss: 0.00404\n",
      "Epoch 12/30, train_loss: 0.00445, valid_loss: 0.00396\n",
      "Epoch 13/30, train_loss: 0.00435, valid_loss: 0.00387\n",
      "Epoch 14/30, train_loss: 0.00426, valid_loss: 0.00379\n",
      "Epoch 15/30, train_loss: 0.00418, valid_loss: 0.00373\n",
      "Epoch 16/30, train_loss: 0.00411, valid_loss: 0.00367\n",
      "Epoch 17/30, train_loss: 0.00405, valid_loss: 0.00361\n",
      "Epoch 18/30, train_loss: 0.00399, valid_loss: 0.00357\n",
      "Epoch 19/30, train_loss: 0.00394, valid_loss: 0.00353\n",
      "Epoch 20/30, train_loss: 0.00389, valid_loss: 0.00349\n",
      "Epoch 21/30, train_loss: 0.00384, valid_loss: 0.00345\n",
      "Epoch 22/30, train_loss: 0.00380, valid_loss: 0.00341\n",
      "Epoch 23/30, train_loss: 0.00376, valid_loss: 0.00338\n",
      "Epoch 24/30, train_loss: 0.00373, valid_loss: 0.00335\n",
      "Epoch 25/30, train_loss: 0.00369, valid_loss: 0.00333\n",
      "Epoch 26/30, train_loss: 0.00366, valid_loss: 0.00330\n",
      "Epoch 27/30, train_loss: 0.00363, valid_loss: 0.00328\n",
      "Epoch 28/30, train_loss: 0.00361, valid_loss: 0.00326\n",
      "Epoch 29/30, train_loss: 0.00358, valid_loss: 0.00323\n",
      "Epoch 30/30, train_loss: 0.00355, valid_loss: 0.00321\n",
      "At step 10\n",
      "Epoch 1/30, train_loss: 0.00859, valid_loss: 0.00552\n",
      "Epoch 2/30, train_loss: 0.00722, valid_loss: 0.00535\n",
      "Epoch 3/30, train_loss: 0.00671, valid_loss: 0.00524\n",
      "Epoch 4/30, train_loss: 0.00635, valid_loss: 0.00509\n",
      "Epoch 5/30, train_loss: 0.00608, valid_loss: 0.00491\n",
      "Epoch 6/30, train_loss: 0.00582, valid_loss: 0.00473\n",
      "Epoch 7/30, train_loss: 0.00560, valid_loss: 0.00459\n",
      "Epoch 8/30, train_loss: 0.00543, valid_loss: 0.00443\n",
      "Epoch 9/30, train_loss: 0.00527, valid_loss: 0.00432\n",
      "Epoch 10/30, train_loss: 0.00512, valid_loss: 0.00426\n",
      "Epoch 11/30, train_loss: 0.00501, valid_loss: 0.00421\n",
      "Epoch 12/30, train_loss: 0.00490, valid_loss: 0.00414\n",
      "Epoch 13/30, train_loss: 0.00480, valid_loss: 0.00407\n",
      "Epoch 14/30, train_loss: 0.00472, valid_loss: 0.00403\n",
      "Epoch 15/30, train_loss: 0.00464, valid_loss: 0.00397\n",
      "Epoch 16/30, train_loss: 0.00457, valid_loss: 0.00397\n",
      "Epoch 17/30, train_loss: 0.00451, valid_loss: 0.00394\n",
      "Epoch 18/30, train_loss: 0.00445, valid_loss: 0.00392\n",
      "Epoch 19/30, train_loss: 0.00440, valid_loss: 0.00388\n",
      "Epoch 20/30, train_loss: 0.00435, valid_loss: 0.00383\n",
      "Epoch 21/30, train_loss: 0.00430, valid_loss: 0.00383\n",
      "Epoch 22/30, train_loss: 0.00427, valid_loss: 0.00380\n",
      "Epoch 23/30, train_loss: 0.00423, valid_loss: 0.00377\n",
      "Epoch 24/30, train_loss: 0.00419, valid_loss: 0.00374\n",
      "Epoch 25/30, train_loss: 0.00415, valid_loss: 0.00372\n",
      "Epoch 26/30, train_loss: 0.00412, valid_loss: 0.00369\n",
      "Epoch 27/30, train_loss: 0.00409, valid_loss: 0.00369\n",
      "Epoch 28/30, train_loss: 0.00407, valid_loss: 0.00366\n",
      "Epoch 29/30, train_loss: 0.00404, valid_loss: 0.00366\n",
      "Epoch 30/30, train_loss: 0.00401, valid_loss: 0.00364\n",
      "At step 9\n",
      "Epoch 1/30, train_loss: 0.00656, valid_loss: 0.00521\n",
      "Epoch 2/30, train_loss: 0.00591, valid_loss: 0.00526\n",
      "Epoch 3/30, train_loss: 0.00548, valid_loss: 0.00480\n",
      "Epoch 4/30, train_loss: 0.00513, valid_loss: 0.00451\n",
      "Epoch 5/30, train_loss: 0.00486, valid_loss: 0.00427\n",
      "Epoch 6/30, train_loss: 0.00466, valid_loss: 0.00422\n",
      "Epoch 7/30, train_loss: 0.00450, valid_loss: 0.00410\n",
      "Epoch 8/30, train_loss: 0.00440, valid_loss: 0.00401\n",
      "Epoch 9/30, train_loss: 0.00429, valid_loss: 0.00392\n",
      "Epoch 10/30, train_loss: 0.00422, valid_loss: 0.00385\n",
      "Epoch 11/30, train_loss: 0.00415, valid_loss: 0.00379\n",
      "Epoch 12/30, train_loss: 0.00409, valid_loss: 0.00377\n",
      "Epoch 13/30, train_loss: 0.00404, valid_loss: 0.00372\n",
      "Epoch 14/30, train_loss: 0.00399, valid_loss: 0.00368\n",
      "Epoch 15/30, train_loss: 0.00395, valid_loss: 0.00365\n",
      "Epoch 16/30, train_loss: 0.00391, valid_loss: 0.00361\n",
      "Epoch 17/30, train_loss: 0.00388, valid_loss: 0.00359\n",
      "Epoch 18/30, train_loss: 0.00385, valid_loss: 0.00364\n",
      "Epoch 19/30, train_loss: 0.00382, valid_loss: 0.00363\n",
      "Epoch 20/30, train_loss: 0.00380, valid_loss: 0.00364\n",
      "Epoch 21/30, train_loss: 0.00378, valid_loss: 0.00362\n",
      "Epoch 22/30, train_loss: 0.00375, valid_loss: 0.00359\n",
      "Epoch 23/30, train_loss: 0.00373, valid_loss: 0.00357\n",
      "Epoch 24/30, train_loss: 0.00372, valid_loss: 0.00356\n",
      "Epoch 25/30, train_loss: 0.00370, valid_loss: 0.00355\n",
      "Epoch 26/30, train_loss: 0.00369, valid_loss: 0.00353\n",
      "Epoch 27/30, train_loss: 0.00367, valid_loss: 0.00352\n",
      "Epoch 28/30, train_loss: 0.00365, valid_loss: 0.00351\n",
      "Epoch 29/30, train_loss: 0.00364, valid_loss: 0.00349\n",
      "Epoch 30/30, train_loss: 0.00363, valid_loss: 0.00349\n",
      "At step 8\n",
      "Epoch 1/30, train_loss: 0.00768, valid_loss: 0.00616\n",
      "Epoch 2/30, train_loss: 0.00704, valid_loss: 0.00639\n",
      "Epoch 3/30, train_loss: 0.00664, valid_loss: 0.00596\n",
      "Epoch 4/30, train_loss: 0.00633, valid_loss: 0.00579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, train_loss: 0.00607, valid_loss: 0.00558\n",
      "Epoch 6/30, train_loss: 0.00588, valid_loss: 0.00541\n",
      "Epoch 7/30, train_loss: 0.00570, valid_loss: 0.00533\n",
      "Epoch 8/30, train_loss: 0.00556, valid_loss: 0.00517\n",
      "Epoch 9/30, train_loss: 0.00542, valid_loss: 0.00509\n",
      "Epoch 10/30, train_loss: 0.00532, valid_loss: 0.00499\n",
      "Epoch 11/30, train_loss: 0.00524, valid_loss: 0.00490\n",
      "Epoch 12/30, train_loss: 0.00515, valid_loss: 0.00482\n",
      "Epoch 13/30, train_loss: 0.00508, valid_loss: 0.00476\n",
      "Epoch 14/30, train_loss: 0.00503, valid_loss: 0.00470\n",
      "Epoch 15/30, train_loss: 0.00497, valid_loss: 0.00474\n",
      "Epoch 16/30, train_loss: 0.00492, valid_loss: 0.00468\n",
      "Epoch 17/30, train_loss: 0.00488, valid_loss: 0.00464\n",
      "Epoch 18/30, train_loss: 0.00484, valid_loss: 0.00460\n",
      "Epoch 19/30, train_loss: 0.00480, valid_loss: 0.00459\n",
      "Epoch 20/30, train_loss: 0.00477, valid_loss: 0.00456\n",
      "Epoch 21/30, train_loss: 0.00473, valid_loss: 0.00455\n",
      "Epoch 22/30, train_loss: 0.00471, valid_loss: 0.00452\n",
      "Epoch 23/30, train_loss: 0.00468, valid_loss: 0.00449\n",
      "Epoch 24/30, train_loss: 0.00465, valid_loss: 0.00447\n",
      "Epoch 25/30, train_loss: 0.00462, valid_loss: 0.00444\n",
      "Epoch 26/30, train_loss: 0.00460, valid_loss: 0.00441\n",
      "Epoch 27/30, train_loss: 0.00458, valid_loss: 0.00441\n",
      "Epoch 28/30, train_loss: 0.00455, valid_loss: 0.00439\n",
      "Epoch 29/30, train_loss: 0.00453, valid_loss: 0.00437\n",
      "Epoch 30/30, train_loss: 0.00452, valid_loss: 0.00436\n",
      "At step 7\n",
      "Epoch 1/30, train_loss: 0.01158, valid_loss: 0.00678\n",
      "Epoch 2/30, train_loss: 0.00933, valid_loss: 0.00649\n",
      "Epoch 3/30, train_loss: 0.00837, valid_loss: 0.00619\n",
      "Epoch 4/30, train_loss: 0.00775, valid_loss: 0.00586\n",
      "Epoch 5/30, train_loss: 0.00725, valid_loss: 0.00559\n",
      "Epoch 6/30, train_loss: 0.00688, valid_loss: 0.00533\n",
      "Epoch 7/30, train_loss: 0.00656, valid_loss: 0.00514\n",
      "Epoch 8/30, train_loss: 0.00631, valid_loss: 0.00499\n",
      "Epoch 9/30, train_loss: 0.00610, valid_loss: 0.00488\n",
      "Epoch 10/30, train_loss: 0.00593, valid_loss: 0.00478\n",
      "Epoch 11/30, train_loss: 0.00578, valid_loss: 0.00471\n",
      "Epoch 12/30, train_loss: 0.00566, valid_loss: 0.00472\n",
      "Epoch 13/30, train_loss: 0.00555, valid_loss: 0.00465\n",
      "Epoch 14/30, train_loss: 0.00545, valid_loss: 0.00460\n",
      "Epoch 15/30, train_loss: 0.00535, valid_loss: 0.00456\n",
      "Epoch 16/30, train_loss: 0.00528, valid_loss: 0.00452\n",
      "Epoch 17/30, train_loss: 0.00521, valid_loss: 0.00449\n",
      "Epoch 18/30, train_loss: 0.00514, valid_loss: 0.00446\n",
      "Epoch 19/30, train_loss: 0.00508, valid_loss: 0.00442\n",
      "Epoch 20/30, train_loss: 0.00503, valid_loss: 0.00441\n",
      "Epoch 21/30, train_loss: 0.00498, valid_loss: 0.00437\n",
      "Epoch 22/30, train_loss: 0.00493, valid_loss: 0.00434\n",
      "Epoch 23/30, train_loss: 0.00489, valid_loss: 0.00432\n",
      "Epoch 24/30, train_loss: 0.00485, valid_loss: 0.00429\n",
      "Epoch 25/30, train_loss: 0.00481, valid_loss: 0.00427\n",
      "Epoch 26/30, train_loss: 0.00478, valid_loss: 0.00425\n",
      "Epoch 27/30, train_loss: 0.00475, valid_loss: 0.00423\n",
      "Epoch 28/30, train_loss: 0.00472, valid_loss: 0.00424\n",
      "Epoch 29/30, train_loss: 0.00469, valid_loss: 0.00422\n",
      "Epoch 30/30, train_loss: 0.00467, valid_loss: 0.00420\n",
      "At step 6\n",
      "Epoch 1/30, train_loss: 0.00755, valid_loss: 0.00712\n",
      "Epoch 2/30, train_loss: 0.00682, valid_loss: 0.00617\n",
      "Epoch 3/30, train_loss: 0.00632, valid_loss: 0.00617\n",
      "Epoch 4/30, train_loss: 0.00597, valid_loss: 0.00578\n",
      "Epoch 5/30, train_loss: 0.00571, valid_loss: 0.00548\n",
      "Epoch 6/30, train_loss: 0.00553, valid_loss: 0.00532\n",
      "Epoch 7/30, train_loss: 0.00539, valid_loss: 0.00517\n",
      "Epoch 8/30, train_loss: 0.00528, valid_loss: 0.00505\n",
      "Epoch 9/30, train_loss: 0.00521, valid_loss: 0.00523\n",
      "Epoch 10/30, train_loss: 0.00514, valid_loss: 0.00513\n",
      "Epoch 11/30, train_loss: 0.00507, valid_loss: 0.00505\n",
      "Epoch 12/30, train_loss: 0.00501, valid_loss: 0.00498\n",
      "Epoch 13/30, train_loss: 0.00495, valid_loss: 0.00491\n",
      "Epoch 14/30, train_loss: 0.00491, valid_loss: 0.00490\n",
      "Epoch 15/30, train_loss: 0.00487, valid_loss: 0.00491\n",
      "Epoch 16/30, train_loss: 0.00483, valid_loss: 0.00486\n",
      "Epoch 17/30, train_loss: 0.00480, valid_loss: 0.00483\n",
      "Epoch 18/30, train_loss: 0.00477, valid_loss: 0.00478\n",
      "Epoch 19/30, train_loss: 0.00474, valid_loss: 0.00474\n",
      "Epoch 20/30, train_loss: 0.00472, valid_loss: 0.00473\n",
      "Epoch 21/30, train_loss: 0.00469, valid_loss: 0.00469\n",
      "Epoch 22/30, train_loss: 0.00467, valid_loss: 0.00467\n",
      "Epoch 23/30, train_loss: 0.00465, valid_loss: 0.00464\n",
      "Epoch 24/30, train_loss: 0.00463, valid_loss: 0.00463\n",
      "Epoch 25/30, train_loss: 0.00462, valid_loss: 0.00461\n",
      "Epoch 26/30, train_loss: 0.00460, valid_loss: 0.00459\n",
      "Epoch 27/30, train_loss: 0.00458, valid_loss: 0.00458\n",
      "Epoch 28/30, train_loss: 0.00457, valid_loss: 0.00456\n",
      "Epoch 29/30, train_loss: 0.00456, valid_loss: 0.00454\n",
      "Epoch 30/30, train_loss: 0.00454, valid_loss: 0.00454\n",
      "At step 5\n",
      "Epoch 1/30, train_loss: 0.00732, valid_loss: 0.00666\n",
      "Epoch 2/30, train_loss: 0.00679, valid_loss: 0.00651\n",
      "Epoch 3/30, train_loss: 0.00631, valid_loss: 0.00589\n",
      "Epoch 4/30, train_loss: 0.00601, valid_loss: 0.00554\n",
      "Epoch 5/30, train_loss: 0.00577, valid_loss: 0.00533\n",
      "Epoch 6/30, train_loss: 0.00560, valid_loss: 0.00517\n",
      "Epoch 7/30, train_loss: 0.00546, valid_loss: 0.00512\n",
      "Epoch 8/30, train_loss: 0.00535, valid_loss: 0.00501\n",
      "Epoch 9/30, train_loss: 0.00527, valid_loss: 0.00493\n",
      "Epoch 10/30, train_loss: 0.00519, valid_loss: 0.00486\n",
      "Epoch 11/30, train_loss: 0.00513, valid_loss: 0.00488\n",
      "Epoch 12/30, train_loss: 0.00508, valid_loss: 0.00483\n",
      "Epoch 13/30, train_loss: 0.00504, valid_loss: 0.00485\n",
      "Epoch 14/30, train_loss: 0.00500, valid_loss: 0.00489\n",
      "Epoch 15/30, train_loss: 0.00496, valid_loss: 0.00485\n",
      "Epoch 16/30, train_loss: 0.00493, valid_loss: 0.00481\n",
      "Epoch 17/30, train_loss: 0.00490, valid_loss: 0.00479\n",
      "Epoch 18/30, train_loss: 0.00487, valid_loss: 0.00476\n",
      "Epoch 19/30, train_loss: 0.00484, valid_loss: 0.00473\n",
      "Epoch 20/30, train_loss: 0.00482, valid_loss: 0.00470\n",
      "Epoch 21/30, train_loss: 0.00480, valid_loss: 0.00468\n",
      "Epoch 22/30, train_loss: 0.00478, valid_loss: 0.00466\n",
      "Epoch 23/30, train_loss: 0.00476, valid_loss: 0.00464\n",
      "Epoch 24/30, train_loss: 0.00475, valid_loss: 0.00465\n",
      "Epoch 25/30, train_loss: 0.00473, valid_loss: 0.00463\n",
      "Epoch 26/30, train_loss: 0.00472, valid_loss: 0.00462\n",
      "Epoch 27/30, train_loss: 0.00470, valid_loss: 0.00460\n",
      "Epoch 28/30, train_loss: 0.00469, valid_loss: 0.00459\n",
      "Epoch 29/30, train_loss: 0.00468, valid_loss: 0.00459\n",
      "Epoch 30/30, train_loss: 0.00467, valid_loss: 0.00458\n",
      "At step 4\n",
      "Epoch 1/30, train_loss: 0.00758, valid_loss: 0.01083\n",
      "Epoch 2/30, train_loss: 0.00691, valid_loss: 0.01039\n",
      "Epoch 3/30, train_loss: 0.00644, valid_loss: 0.00912\n",
      "Epoch 4/30, train_loss: 0.00610, valid_loss: 0.00823\n",
      "Epoch 5/30, train_loss: 0.00588, valid_loss: 0.00770\n",
      "Epoch 6/30, train_loss: 0.00572, valid_loss: 0.00728\n",
      "Epoch 7/30, train_loss: 0.00560, valid_loss: 0.00696\n",
      "Epoch 8/30, train_loss: 0.00551, valid_loss: 0.00670\n",
      "Epoch 9/30, train_loss: 0.00543, valid_loss: 0.00670\n",
      "Epoch 10/30, train_loss: 0.00537, valid_loss: 0.00663\n",
      "Epoch 11/30, train_loss: 0.00532, valid_loss: 0.00656\n",
      "Epoch 12/30, train_loss: 0.00527, valid_loss: 0.00642\n",
      "Epoch 13/30, train_loss: 0.00522, valid_loss: 0.00632\n",
      "Epoch 14/30, train_loss: 0.00519, valid_loss: 0.00626\n",
      "Epoch 15/30, train_loss: 0.00515, valid_loss: 0.00619\n",
      "Epoch 16/30, train_loss: 0.00512, valid_loss: 0.00610\n",
      "Epoch 17/30, train_loss: 0.00510, valid_loss: 0.00606\n",
      "Epoch 18/30, train_loss: 0.00507, valid_loss: 0.00599\n",
      "Epoch 19/30, train_loss: 0.00505, valid_loss: 0.00592\n",
      "Epoch 20/30, train_loss: 0.00503, valid_loss: 0.00585\n",
      "Epoch 21/30, train_loss: 0.00501, valid_loss: 0.00590\n",
      "Epoch 22/30, train_loss: 0.00499, valid_loss: 0.00584\n",
      "Epoch 23/30, train_loss: 0.00498, valid_loss: 0.00580\n",
      "Epoch 24/30, train_loss: 0.00497, valid_loss: 0.00580\n",
      "Epoch 25/30, train_loss: 0.00495, valid_loss: 0.00581\n",
      "Epoch 26/30, train_loss: 0.00494, valid_loss: 0.00580\n",
      "Epoch 27/30, train_loss: 0.00493, valid_loss: 0.00581\n",
      "Epoch 28/30, train_loss: 0.00492, valid_loss: 0.00579\n",
      "Epoch 29/30, train_loss: 0.00490, valid_loss: 0.00575\n",
      "Epoch 30/30, train_loss: 0.00489, valid_loss: 0.00579\n",
      "At step 3\n",
      "Epoch 1/30, train_loss: 0.00851, valid_loss: 0.00676\n",
      "Epoch 2/30, train_loss: 0.00776, valid_loss: 0.00699\n",
      "Epoch 3/30, train_loss: 0.00735, valid_loss: 0.00667\n",
      "Epoch 4/30, train_loss: 0.00709, valid_loss: 0.00645\n",
      "Epoch 5/30, train_loss: 0.00688, valid_loss: 0.00631\n",
      "Epoch 6/30, train_loss: 0.00673, valid_loss: 0.00625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, train_loss: 0.00662, valid_loss: 0.00619\n",
      "Epoch 8/30, train_loss: 0.00652, valid_loss: 0.00614\n",
      "Epoch 9/30, train_loss: 0.00645, valid_loss: 0.00608\n",
      "Epoch 10/30, train_loss: 0.00639, valid_loss: 0.00602\n",
      "Epoch 11/30, train_loss: 0.00634, valid_loss: 0.00599\n",
      "Epoch 12/30, train_loss: 0.00629, valid_loss: 0.00598\n",
      "Epoch 13/30, train_loss: 0.00626, valid_loss: 0.00596\n",
      "Epoch 14/30, train_loss: 0.00622, valid_loss: 0.00593\n",
      "Epoch 15/30, train_loss: 0.00619, valid_loss: 0.00593\n",
      "Epoch 16/30, train_loss: 0.00616, valid_loss: 0.00591\n",
      "Epoch 17/30, train_loss: 0.00614, valid_loss: 0.00588\n",
      "Epoch 18/30, train_loss: 0.00611, valid_loss: 0.00585\n",
      "Epoch 19/30, train_loss: 0.00609, valid_loss: 0.00583\n",
      "Epoch 20/30, train_loss: 0.00607, valid_loss: 0.00581\n",
      "Epoch 21/30, train_loss: 0.00606, valid_loss: 0.00579\n",
      "Epoch 22/30, train_loss: 0.00604, valid_loss: 0.00579\n",
      "Epoch 23/30, train_loss: 0.00602, valid_loss: 0.00578\n",
      "Epoch 24/30, train_loss: 0.00601, valid_loss: 0.00578\n",
      "Epoch 25/30, train_loss: 0.00599, valid_loss: 0.00579\n",
      "Epoch 26/30, train_loss: 0.00598, valid_loss: 0.00579\n",
      "Epoch 27/30, train_loss: 0.00596, valid_loss: 0.00577\n",
      "Epoch 28/30, train_loss: 0.00595, valid_loss: 0.00576\n",
      "Epoch 29/30, train_loss: 0.00594, valid_loss: 0.00575\n",
      "Epoch 30/30, train_loss: 0.00593, valid_loss: 0.00578\n",
      "At step 2\n",
      "Epoch 1/30, train_loss: 0.00917, valid_loss: 0.00843\n",
      "Epoch 2/30, train_loss: 0.00831, valid_loss: 0.00761\n",
      "Epoch 3/30, train_loss: 0.00787, valid_loss: 0.00932\n",
      "Epoch 4/30, train_loss: 0.00755, valid_loss: 0.00869\n",
      "Epoch 5/30, train_loss: 0.00731, valid_loss: 0.00825\n",
      "Epoch 6/30, train_loss: 0.00716, valid_loss: 0.00804\n",
      "Epoch 7/30, train_loss: 0.00705, valid_loss: 0.00786\n",
      "Epoch 8/30, train_loss: 0.00694, valid_loss: 0.00772\n",
      "Epoch 9/30, train_loss: 0.00684, valid_loss: 0.00760\n",
      "Epoch 10/30, train_loss: 0.00677, valid_loss: 0.00745\n",
      "Epoch 11/30, train_loss: 0.00671, valid_loss: 0.00741\n",
      "Epoch 12/30, train_loss: 0.00666, valid_loss: 0.00729\n",
      "Epoch 13/30, train_loss: 0.00662, valid_loss: 0.00722\n",
      "Epoch 14/30, train_loss: 0.00658, valid_loss: 0.00732\n",
      "Epoch 15/30, train_loss: 0.00655, valid_loss: 0.00726\n",
      "Epoch 16/30, train_loss: 0.00652, valid_loss: 0.00718\n",
      "Epoch 17/30, train_loss: 0.00649, valid_loss: 0.00714\n",
      "Epoch 18/30, train_loss: 0.00646, valid_loss: 0.00710\n",
      "Epoch 19/30, train_loss: 0.00644, valid_loss: 0.00704\n",
      "Epoch 20/30, train_loss: 0.00642, valid_loss: 0.00698\n",
      "Epoch 21/30, train_loss: 0.00640, valid_loss: 0.00694\n",
      "Epoch 22/30, train_loss: 0.00638, valid_loss: 0.00693\n",
      "Epoch 23/30, train_loss: 0.00637, valid_loss: 0.00689\n",
      "Epoch 24/30, train_loss: 0.00635, valid_loss: 0.00685\n",
      "Epoch 25/30, train_loss: 0.00634, valid_loss: 0.00686\n",
      "Epoch 26/30, train_loss: 0.00632, valid_loss: 0.00683\n",
      "Epoch 27/30, train_loss: 0.00631, valid_loss: 0.00684\n",
      "Epoch 28/30, train_loss: 0.00630, valid_loss: 0.00681\n",
      "Epoch 29/30, train_loss: 0.00629, valid_loss: 0.00679\n",
      "Epoch 30/30, train_loss: 0.00628, valid_loss: 0.00678\n",
      "Wall time: 12min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prc_nn_100k=Bermudan_swaption_nn(lockout,maturity,sim_rates_100k,strike,n_epochs,batch_size,learningrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European swaption pirce: 0.006951267551339664\n",
      "Bermudan swaption pirce: 0.008664989835594633\n",
      "Excercise Probability Table\n",
      "    Time_step  ex_prob_Euro  ex_prob_RLNN\n",
      "0           2       0.70762       0.50279\n",
      "1           3       0.00000       0.17675\n",
      "2           4       0.00000       0.03828\n",
      "3           5       0.00000       0.04673\n",
      "4           6       0.00000       0.01729\n",
      "5           7       0.00000       0.00791\n",
      "6           8       0.00000       0.00495\n",
      "7           9       0.00000       0.00280\n",
      "8          10       0.00000       0.00290\n",
      "9          11       0.00000       0.00218\n",
      "10         12       0.00000       0.00235\n",
      "11         13       0.00000       0.00263\n",
      "12         14       0.00000       0.00203\n",
      "13         15       0.00000       0.00305\n",
      "14         16       0.00000       0.00264\n",
      "15         17       0.00000       0.00303\n",
      "16         18       0.00000       0.00419\n",
      "17         19       0.00000       0.00517\n"
     ]
    }
   ],
   "source": [
    "print_result(prc_nn_100k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### what worths more attention is the training time for NN decrease significantly, even now the epochs is just 10, the results  are pretty rebust\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=make_table(prc_lsm,prc_nn,prc_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.007563\n",
       "1    0.008788\n",
       "2    0.007769\n",
       "Name:  Bermudan price, dtype: float64"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Bermudan 10k']=make_table(prc_lsm_10k,prc_nn_10k,prc_xgb_10k).iloc[:,2]\n",
    "df['Bermudan 50k']=make_table(prc_lsm_50k,prc_nn_50k,prc_xgb_50k).iloc[:,2]\n",
    "df['Bermudan 100k']=make_table(prc_lsm_100k,prc_nn_100k,prc_xgb_100k).iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>European price</th>\n",
       "      <th>Bermudan price</th>\n",
       "      <th>Bermudan 10k</th>\n",
       "      <th>Bermudan 50k</th>\n",
       "      <th>Bermudan 100k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LSM</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>0.007548</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.007514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>0.008788</td>\n",
       "      <td>0.008712</td>\n",
       "      <td>0.008736</td>\n",
       "      <td>0.008665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>0.007769</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>0.007611</td>\n",
       "      <td>0.007596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algorithm   European price   Bermudan price  Bermudan 10k  Bermudan 50k  \\\n",
       "0       LSM         0.006939         0.007563      0.007548      0.007513   \n",
       "1        NN         0.006939         0.008788      0.008712      0.008736   \n",
       "2   XGBoost         0.006939         0.007769      0.007693      0.007611   \n",
       "\n",
       "   Bermudan 100k  \n",
       "0       0.007514  \n",
       "1       0.008665  \n",
       "2       0.007596  "
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>0.008788</td>\n",
       "      <td>0.007769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.007548</td>\n",
       "      <td>0.008712</td>\n",
       "      <td>0.007693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.008736</td>\n",
       "      <td>0.007611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.008665</td>\n",
       "      <td>0.007596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  0.007563  0.008788  0.007769\n",
       "1  0.007548  0.008712  0.007693\n",
       "2  0.007513  0.008736  0.007611\n",
       "3  0.007514  0.008665  0.007596"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_table=pd.DataFrame(df.iloc[:,2:].to_numpy().T)\n",
    "output_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_table.columns=df['Algorithm'].values\n",
    "output_table.index=np.array([5000,10000,50000,100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSM</th>\n",
       "      <th>NN</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>0.008788</td>\n",
       "      <td>0.007769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.007548</td>\n",
       "      <td>0.008712</td>\n",
       "      <td>0.007693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.008736</td>\n",
       "      <td>0.007611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.008665</td>\n",
       "      <td>0.007596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LSM        NN   XGBoost\n",
       "5000    0.007563  0.008788  0.007769\n",
       "10000   0.007548  0.008712  0.007693\n",
       "50000   0.007513  0.008736  0.007611\n",
       "100000  0.007514  0.008665  0.007596"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAFXCAYAAADK0sabAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeVyVZf7/8dfhHPZNUUFcMKPIlETEHFfK1HJvJr65lDmVRptOuVBaM6NNuGVpSWQ5M+3N1Px0qkFzySw1pQUETXJJJfcVRTlsBzj37w/zpKWght7AeT8fjx6Pzrnv674/95V53ue+r3NdFsMwDEREREQugIfZBYiIiEjtoeAgIiIiF0zBQURERC6YgoOIiIhcMAUHERERuWAKDiIiInLBFBxEaoi9e/dy/fXXc/vtt7v+GTRoEAsWLDjn/p999hnJycnVcu4DBw4wYMAAbr/9drKysqrlmOeTk5NDXFwc3333neu9Y8eO0atXL7744gvXewsWLODOO++kX79+9OrVi/vuu48NGza4tt9zzz3ccsstrn7q27cvL7/88mWpeePGjfz1r3+9LMcWqW1sZhcgIj/z8fHh448/dr0+dOgQAwYMIDo6mlatWp21b8+ePenZs2e1nPfrr7+mYcOGvPnmm9VyvMq0adOGpKQkHnvsMT788EP8/f15/PHHSUhI4OabbwZg9uzZfPvtt7z44os0bdoUgPT0dB588EH++9//0qRJEwCeeOIJ+vTpA8DJkyfp168fnTt3Ji4urlpr3r59O4cOHarWY4rUVgoOIjVYWFgYLVq04Mcff+T7779nwYIFFBcXExAQwB/+8AeWLVvGa6+9xpEjR5g8eTI7d+7Ew8ODoUOHMmLECAoKCpg6dSrbtm2jrKyMzp0788QTT2Cz/fy//ldffcWLL75IQUEB99xzD6NHj2bq1Kn4+flRWFjIwoUL+fDDD3nnnXfw8PCgYcOG/OUvf6Fly5ZMnDgRHx8ftm3bRl5eHrfccgv16tXj888/58iRIyQnJ9O5c+dfXdfQoUPJzMzkqaeeIiIigqCgIB566CEAjh49yltvvcWnn35KaGioq03nzp2ZOHEixcXF5+yrwsJCAOrXrw/ADz/8wN/+9jfy8/OxWCzcf//9/P73vwfggw8+OOf1ZGRkMGPGDJxOJwAPPvggbdu2Ze7cuRQUFDBp0iSmT59eDf9lRWoxQ0RqhD179hjt2rU7673169cbN954o7F//35j4cKFxo033mgUFBQYhmEYCxcuNBITEw3DMIxHH33UmDlzpmEYhnHy5Emjf//+xo8//mhMnDjRePvttw3DMIzy8nJjwoQJxvz583917jOP9dVXXxmtWrUy9u7daxiGYaxbt87o1auXkZeX59q3b9++htPpNJ588knjzjvvNBwOh3H48GEjKirKdb4333zTuO+++857vYWFhUbv3r2NHj16GHa73fX+p59+avzhD3+osr+GDx9u9OjRwxg0aJDRr18/o02bNkZSUpLhdDqNsrIyo2fPnsayZcsMwzCMgwcPGt27dzfWr19f6fWMGDHCWLRokWEYhrF582ZjypQpv+ofEXenOw4iNUhJSQm33347ABUVFdSvX59Zs2YRHh4OwHXXXUdAQMCv2q1bt46kpCQAAgMDWbRoEQBffPEF3333nWucRElJyQXVER4e7npEsGbNGvr160dISAgAd9xxB1OnTmXv3r0A9OjRA09PTxo1aoSfnx/du3cHICIigvz8/POeIzc3l8LCQkpLS8nJyaFjx44AGL+YBd9ut3P33XcDUFRURN++fRk3bhxw9qOKY8eOkZiYyPz58+nZsyelpaXceuutwKk7N7feeitr1qyhpKTkvNfTt29f/va3v7Fy5Uq6dOniOo+I/EzBQaQG+eUYh1/y8/M75/s2mw2LxeJ6vWfPHurXr4/T6eSll14iMjISODUO4Mz9LuQ8p2/bn8kwDMrLywHw8vL6VS1VOXbsGGPGjGHSpEmUlpYybtw4PvzwQxo1akTbtm3Jzc3l+PHj1K9fn4CAAFefpKSkcPz48XMeMyQkhAEDBvDll19y8803/+o6T9dc2fUMHTqUHj16sHbtWtasWcPLL7/M0qVLq7weEXeiX1WI1AGdO3dm4cKFABQUFPDHP/6RH3/8kW7duvHmm29iGAYOh4OHH36Yd99996KO3b17dz755BOOHTsGwMKFC6lXrx4tWrS4pForKioYO3YsPXr0YMCAASQkJNC9e3fGjh1LRUUFYWFhjBgxgscee4z9+/e72u3bt4/169fj4XHuv7bKyspYu3Ytbdu25eqrr8Zms7F8+XLg1CDTZcuW0aVLl0qvZ+jQoWzevJk77riDZ599lpMnT3LkyBGsVqsrKIm4O91xEKkD/vrXvzJlyhQGDhyIYRg8+OCDREdH8/TTTzN16lQGDhxIWVkZXbp0YdSoURd17K5du3Lvvffyxz/+EafTSUhICK+99tp5P8Cr8txzz1FcXMyTTz55Vv2DBw9m9uzZJCUlMXbsWP73v/8xfvx4iouLKSgoIDg4mH79+rkeW5w+1rx587BYLBQXF9OpUyceeughPD09eeWVV0hOTiYlJYWKigoeffRROnXqBHDe65kwYQLTpk3jxRdfxGKxMHr0aJo1a0ZFRQWpqamMHj36sv3kU6S2sBi/fKAoIiIich56VCEiIiIXTMFBRERELpiCg4iIiFwwBQcRERG5YHX6VxVOp5PCwkI8PT0v6LfrIiIitZ1hGJSVleHv73/Jv36qTJ0ODoWFhWzbts3sMkRERK64qKgoAgMDq/24VQYHp9PJlClT2Lp1K15eXiQnJ5818cvKlStJTU3FZrORkJDA4MGDz9tm7NixHD16FDg1mUtMTAyJiYlMmzbNdbzs7GxSU1PZsmULa9asAU7Ndnf06FHWrl3L8uXLee6551xT8I4ZM8Y1Ve0veXp6Aqc675ez2wls2rSJ6Ohos8twO+p3c6jfzaF+v/IcDgfbtm1zfQZWtyqDw4oVK3A4HHzwwQdkZ2czY8YM5s2bB5yaqW369OksWLAAX19fhg0bRo8ePcjKyjpnmzlz5gBw4sQJRowYwaRJkwgNDeWdd94BYMmSJYSGhhIfH098fDyJiYnAqRXqJkyYAEBOTg5JSUncdtttVV7c6ccTXl5eeHt7X0L31H3qF3Oo382hfjeH+t0cl+sRfZXBITMz07VoTbt27di0aZNr244dO4iIiCA4OBiAuLg4MjIyyM7OPm8bODXf/PDhw89aMreoqIiUlJRfTYe7fPlygoKCXMfLyclh8+bNvPXWW7Rt25YJEyZc0Nz4IiIi8ttV+Ylrt9vPWo3v9JztNpsNu91+1vMTf39/7HZ7pW3y8vJIT09n0qRJZ51nwYIF9OnTx7Vi3WmvvfYas2fPdr3u2rUrvXr1olmzZkyePJn333+f4cOHV3oNvwwu8rPMzEyzS3BL6ndzqN/NoX6vW6oMDgEBARQWFrpeO51O1zf8X24rLCwkMDCw0jZLly5lwIABWK3Ws86TlpbG3Llzz3pv+/btBAUFnTWmIiEhgaCgIAB69uzJsmXLqrzI6Oho3So7h8zMTOLi4swuw+2o382hfjeH+v3KKy0tvaxfmKv8nUb79u1ZvXo1cGrgYlRUlGtbZGQku3btIj8/H4fDQUZGBrGxsZW2SU9PJz4+/qxzFBQU4HA4XAMeT1u3bt1Z+xqGwaBBgzh48KDrWG3atLnYaxYREZFLVOUdh969e7N27VqGDh2KYRhMmzaNtLQ0ioqKGDJkCBMnTmTkyJEYhkFCQgJhYWHnbHNabm4uzZs3P+scubm5NG3a9Ffnzs3NpWvXrq7XFouF5ORkRo8ejY+PD5GRkQwePPi3XL+IiIhchDq9Oubp2zV6VHFuuoVoDvW7OdTv5lC/X3mX+7NPP0cQERE5w9q1a5k5cyb/+c9/8PHx4dChQ4waNYp//OMfZGRk8N577wGnBv63atWKpKQkvLy8uOWWWwgPD8disVBUVERCQgJ33313tdT06aef0rZtW8LCwqrleL+F1qoQERE5Q9euXenWrRszZsygrKyMsWPHMnHiRLZs2cJ//vMfXn31Vf71r3/x9ttvY7FY+Oijj1xtX3/9dd59913ef/993njjDfLy8qqlprfffhu73V4tx/qtdMdBRERqpCfSMlmwYVe1HvP/Ylrw3MCqH52MHTuWu+66i0ceeYQuXbrQtWtXRo0axRNPPOH6ZZ/FYmHSpEnnnGippKQEb29vAgMDKSsr46mnnmLPnj1UVFRw33330a9fP77//nueffZZrFYr3t7ePPvsszRo0IDHHnsMu91OSUkJSUlJFBcXs3nzZp588kn+9a9/mT4TslsEhzo8jENERC4DT09PBg8ezJQpU3jmmWcA2Lt3r2t6gKysLGbPnk1ZWRnh4eGumZHvv/9+LBYLO3fupFevXnh6evLee+9Rv359Zs2ahd1u54477qBTp078+c9/ZurUqVx//fWsWLGCGTNmMGbMGI4ePcqbb75JXl4eP/74IzfffDPXX389U6ZMMT00gJsEh6x9x+kcGV71jiIiUmM8NzDugu4OXA779u3jH//4B0lJSSQlJfH2228THh7O3r17adWqFbGxsbzzzjvs2LGDKVOmuNq9/vrreHt743A4SExM5H//+x87duygS5cuwKn5jyIjI9mzZw+HDx/m+uuvB+DGG2/khRde4Nprr+Xuu+9m3LhxlJeXc88995hx+ZVyizEO3x04ZnYJIiJSSzgcDh5//HGeeuop7r33XsLDw3n55ZcZPnw4zz33HAUFBa59v/nmm3Mew8vLiwYNGlBWVkZkZCQZGRnAqdmYt23bRrNmzQgNDWXLli0AfPvtt1x11VVs3bqVwsJC5s+fz4wZM3j22WeBU49Fasrdc7e447DpwAmzSxARkVpi5syZxMXFcdNNNwEwZcoU1+OFIUOG8MgjjwCnZktu1aoVM2fOdLW9//778fDwwOl00rhxYwYNGgTAX/7yF4YNG0ZpaSmjR4+mQYMGJCcn8+yzz2IYBlarlWnTphEaGkpqaiofffQRnp6e/OlPfwIgNjaWJ554gtdff5169epd4R45m1vM4/BE+iE+G93P7HJqHP2+2hzqd3Oo382hfr/yLvc8Dm7xqOKHowUUl5WbXYaIiEit5xbBwek02Lj/uNlliIiI1HpuERwA1u/TAEkREZHfym2CQ9ZeBQcREZHfyi2Cg7fVg/UKDiIiIr+ZWwSHVmFBbDqYT2l5hdmliIiI1GpuERzaNK5PWYWTnIP5ZpciIiJSq7lFcIhufGqyjEw9rhAREflN3CI4tAkPBjRAUkRE5Ldyi+AQ1SgIT6sHWfuqZ110ERERd+UWwcHLauWG8Hps2H+csgqn2eWIiIjUWm4RHABim4ZQWu5k8yEteCUiInKp3Cc4NAsB0HwOIiIiv4HbBIf2TU8FB41zEBERuXRuExzaNqmP1cOiX1aIiIj8Bm4THHw9bbQOCyZr/zEqnBogKSIicincJjjAqQGSRY4Kth0pMLsUERGRWsmtgkN71wBJjXMQERG5FG4WHBoAkLVP4xxEREQuhVsFh5gm9bFY9JNMERGRS+VWwSHA25PrGgWRte8YTqdhdjkiIiK1jlsFBzg1QPJkSRk7j2mApIiIyMVyu+AQ1/zUOIfMPXpcISIicrFsVe3gdDqZMmUKW7duxcvLi+TkZFq0aOHavnLlSlJTU7HZbCQkJDB48ODzthk7dixHjx4FYN++fcTExJCYmMi0adNcx8vOziY1NZXu3bsTHx/PVVddBUC7du0YP3482dnZTJ06FavVSrdu3Rg9evRFXXCsawbJYwyJveqi2oqIiLi7KoPDihUrcDgcfPDBB2RnZzNjxgzmzZsHQFlZGdOnT2fBggX4+voybNgwevToQVZW1jnbzJkzB4ATJ04wYsQIJk2aRGhoKO+88w4AS5YsITQ0lPj4eHbt2kWbNm149dVXz6pn8uTJpKSk0Lx5cxITE8nJyaFNmzYXfMGng4N+kikiInLxqnxUkZmZSffu3YFT3/o3bdrk2rZjxw4iIiIIDg7Gy8uLuLg4MjIyKm0DkJKSwvDhwwkNDXW9V1RUREpKCk8//TQAOTk5HDp0iHvuuYcHHniAnTt3YrfbcTgcREREYLFY6NatG+np6Rd1wcG+XlzTMJCsfccwDA2QFBERuRhV3nGw2+0EBAS4XlutVsrLy7HZbNjtdgIDA13b/P39sdvtlbbJy8sjPT2dSZMmnXWeBQsW0KdPH0JCTt0RaNSoEYmJifTt25eMjAySkpJITU0967j+/v7s2bOnyov8ZXC5ys/C9qMOFq3+iiYBXlW2r8syMzPNLsEtqd/NoX43h/q9bqkyOAQEBFBYWOh67XQ6sdls59xWWFhIYGBgpW2WLl3KgAEDsFqtZ50nLS2NuXPnul5HR0e79unQoQOHDh3C39//V+cLCgqq8iKjo6Px9vZ2ve55wpsVu7Moq9+UuLYRVbavqzIzM4mLizO7DLejfjeH+t0c6vcrr7S09FdfmKtTlY8q2rdvz+rVq4FTAxejoqJc2yIjI9m1axf5+fk4HA4yMjKIjY2ttE16ejrx8fFnnaOgoACHw0F4eLjrvZdffpm33noLgC1bttCkSRMCAwPx9PRk9+7dGIbBl19+SYcOHS76omO1xLaIiMglqfKOQ+/evVm7di1Dhw7FMAymTZtGWloaRUVFDBkyhIkTJzJy5EgMwyAhIYGwsLBztjktNzeX5s2bn3WO3NxcmjZtetZ7iYmJJCUlsWrVKqxWK9OnTwfgmWeeYcKECVRUVNCtWzdiYmIu+qJPTz2tGSRFREQujsWowyMET9+u+eWjCoCrk/9LcVkF+6f8HxaLxaQKzaVbiOZQv5tD/W4O9fuVV9lnX3VwuwmgTottFsJhewn7TxabXYqIiEit4bbBob3mcxAREblo7hscNM5BRETkorlxcDh9x0HBQURE5EK5bXAIC/SlSZAvWfsUHERERC6U2wYHODVAct+JIg4VaICkiIjIhXDr4BCncQ4iIiIXxa2Dw5lLbIuIiEjV3Do4aICkiIjIxXHr4NA02I/QAB+tWSEiInKB3Do4WCwWYpuF8OOxQvIKS80uR0REpMZz6+AAP88gqXEOIiIiVXP74BD70ziHLI1zEBERqZLbBwfXTzI1zkFERKRKbh8cWtT3p76vl35ZISIicgHcPjhYLBbaNwth+9ECThQ7zC5HRESkRnP74AA/TwSVvf+4yZWIiIjUbAoOnLnEtsY5iIiIVEbBAc0gKSIicqEUHIDIBoEEentqLgcREZEqKDgAHh6nBkhuOXyCwtIys8sRERGpsRQcfhLbNATD0ABJERGRyig4/EQzSIqIiFRNweEnp9esWK9xDiIiIuel4PCT60KD8POy6o6DiIhIJRQcfmL18KBdkxByDuVTXFZudjkiIiI1koLDGWKbhlDhNPjuQL7ZpYiIiNRICg5niNVEUCIiIpVScDjD6SW2s7TEtoiIyDkpOJzh+rBgvG0euuMgIiJyHgoOZ/C0etA2vD7fHcjHUV5hdjkiIiI1jq2qHZxOJ1OmTGHr1q14eXmRnJxMixYtXNtXrlxJamoqNpuNhIQEBg8efN42Y8eO5ejRowDs27ePmJgYEhMTmTZtmut42dnZpKamEhsbS1JSEna7nbKyMiZOnEhsbCzLly/nueeeIzw8HIAxY8bQsWPHauuQ2GYhfLsnj5yDJ1xjHkREROSUKoPDihUrcDgcfPDBB2RnZzNjxgzmzZsHQFlZGdOnT2fBggX4+voybNgwevToQVZW1jnbzJkzB4ATJ04wYsQIJk2aRGhoKO+88w4AS5YsITQ0lPj4eObOnUunTp2499572blzJ+PHj+fDDz8kJyeHpKQkbrvttsvSIaeW2P6BzL15Cg4iIiK/UGVwyMzMpHv37gC0a9eOTZs2ubbt2LGDiIgIgoODAYiLiyMjI4Ps7OzztgFISUlh+PDhhIaGut4rKioiJSWFd999F4B7770XLy8vACoqKvD29gYgJyeHzZs389Zbb9G2bVsmTJiAzVblZVyw0zNIaqVMERGRX6vyE9dutxMQEOB6bbVaKS8vx2azYbfbCQwMdG3z9/fHbrdX2iYvL4/09HQmTZp01nkWLFhAnz59CAk59cEdFBQEwJEjR0hKSuKpp54CoGvXrvTq1YtmzZoxefJk3n//fYYPH17pNfwyuFTGUeHE5gFfbt1DZmb1BZKaKjMz0+wS3JL63Rzqd3Oo3+uWKj8ZAwICKCwsdL12Op2ub/i/3FZYWEhgYGClbZYuXcqAAQOwWq1nnSctLY25c+ee9d7WrVsZN24cTzzxhGscQ0JCgitU9OzZk2XLllV5kdHR0a47Fhfihi8Ps/nQCWLaxWKz1t3xo5mZmcTFxZldhttRv5tD/W4O9fuVV1paelFfmC9WlZ+K7du3Z/Xq1cCpgYtRUVGubZGRkezatYv8/HwcDgcZGRnExsZW2iY9PZ34+PizzlFQUIDD4XANeATYvn07jz32GC+88AI33XQTAIZhMGjQIA4ePOg6Vps2bS712s8rtmkIJeUVbD58otqPLSIiUptVecehd+/erF27lqFDh2IYBtOmTSMtLY2ioiKGDBnCxIkTGTlyJIZhkJCQQFhY2DnbnJabm0vz5s3POkdubi5NmzY9670XXngBh8PB1KlTgVN3N+bNm0dycjKjR4/Gx8eHyMhIBg8eXB39cJb2zUJ4/ZtTM0jeEF6/2o8vIiJSW1kMwzDMLuJyOX275mIfVXy16whd5y5lTPdWvPj7Gy9jhebSLURzqN/NoX43h/r9yrvUz74LVXcf4P8GMU3qY/WwaIltERGRX1BwOAdfTxvXhwaTte8YFU6n2eWIiIjUGAoO5xHbLIRCRzk/HCkwuxQREZEaQ8HhPE5PBLVeE0GJiIi4KDicR/vTS2xrnIOIiIiLgsN5xDSpj8UC6/fmmV2KiIhIjaHgcB6BPp5ENQxi/b5jOJ119herIiIiF0XBoRKxzUI4WVJG7jG72aWIiIjUCAoOlYj7aZxDph5XiIiIAAoOlYpt9tMS2xogKSIiAig4VCpWP8kUERE5i4JDJer5ehHZIJCsvceow0t6iIiIXDAFhyrENgshr6iU3ccLzS5FRETEdAoOVdAMkiIiIj9TcKiCBkiKiIj8TMGhCrrjICIi8jMFhyo0DPAhor4/6/fmaYCkiIi4PQWHCxDbNIRDBSUcOFlsdikiIiKmUnC4AO2b6XGFiIgIKDhckNNLbK/fo6mnRUTEvSk4XAANkBQRETlFweECNA7yJTzIVz/JFBERt6fgcIFim4aw90QRhws0QFJERNyXgsMFOr3Eth5XiIiIO1NwuECaQVJERETB4YJpgKSIiIiCwwVrVs+PRgHeuuMgIiJuTcHhAlksFmKbNiD3mJ1jRaVmlyMiImIKBYeL0F7jHERExM0pOFyE2J/GOWRpnIOIiLgpBYeLEHd6zQrdcRARETel4HARrgoJoJ6vF+v3as0KERFxT7aqdnA6nUyZMoWtW7fi5eVFcnIyLVq0cG1fuXIlqamp2Gw2EhISGDx48HnbjB07lqNHjwKwb98+YmJiSExMZNq0aa7jZWdnk5qaSseOHUlKSiIvLw9/f39mzpxJSEgI2dnZTJ06FavVSrdu3Rg9evRl6JZzs1gstG8awsrtBzlZ4iDIx+uKnVtERKQmqDI4rFixAofDwQcffEB2djYzZsxg3rx5AJSVlTF9+nQWLFiAr68vw4YNo0ePHmRlZZ2zzZw5cwA4ceIEI0aMYNKkSYSGhvLOO+8AsGTJEkJDQ4mPj+eNN94gKiqKMWPGsHjxYl555RX+/Oc/M3nyZFJSUmjevDmJiYnk5OTQpk2by9hFZ4ttdio4ZO87Tnxk2BU7r4iISE1Q5aOKzMxMunfvDkC7du3YtGmTa9uOHTuIiIggODgYLy8v4uLiyMjIqLQNQEpKCsOHDyc0NNT1XlFRESkpKTz99NO/Om98fDzp6enY7XYcDgcRERFYLBa6detGenr6b+yCi9PeNc5BjytERMT9VHnHwW63ExAQ4HpttVopLy/HZrNht9sJDAx0bfP398dut1faJi8vj/T0dCZNmnTWeRYsWECfPn0ICQlxnff0sf39/SkoKPjVcf39/dmzZ0+VF/nL4PJbeJ08NYfDio3b6R5Q+xe8yszMNLsEt6R+N4f63Rzq97qlyuAQEBBAYWGh67XT6cRms51zW2FhIYGBgZW2Wbp0KQMGDMBqtZ51nrS0NObOnXvO8xYWFhIUFHTO8wUFBVV5kdHR0Xh7e1e534WIdRoEfrqbXcUQFxdXLcc0S2ZmZq2/htpI/W4O9bs51O9XXmlpabV+Yf6lKh9VtG/fntWrVwOnBi5GRUW5tkVGRrJr1y7y8/NxOBxkZGQQGxtbaZv09HTi4+PPOkdBQQEOh4Pw8PCzzrtq1SoAVq9eTVxcHAEBAXh6erJ7924Mw+DLL7+kQ4cOv+HyL56Hh4XYpvXZcvgkhaVlV/TcIiIiZqvyjkPv3r1Zu3YtQ4cOxTAMpk2bRlpaGkVFRQwZMoSJEycycuRIDMMgISGBsLCwc7Y5LTc3l+bNm591jtzcXJo2bXrWe8OGDePJJ59k2LBheHp68sILLwDwzDPPMGHCBCoqKujWrRsxMTHV0Q8XJbZZCKt3HmbD/uN0aRladQMREZE6wmIYhmF2EZfL6ds11fmoAuCdjJ3c+++1zP3DjTzarVW1HfdK0y1Ec6jfzaF+N4f6/cq7XJ99p2kCqEvQXjNIioiIm1JwuAStQoPw9bRqzQoREXE7Cg6XwOrhQbsmIeQczKekrMLsckRERK4YBYdLFNsshHKnwXcHjptdioiIyBWj4HCJTi+xvV6PK0RExI0oOFyiuOangkNazl5Ky/W4QkRE3IOCwyVqE1aPtuH1WbJ5H7978ROydedBRETcgILDJbJZPVgz5jYe6hLFdwfy6fTSEqat+I7yCqfZpYmIiFw2Cg6/QYC3J6kJv+OTB3rSyN+bvyzJJv7lZWw7ctLs0kRERC4LBYdqcFurJmxMGshd7Vvy9dVbfNIAACAASURBVO6jtH9hEalfbsHprLOTcoqIiJtScKgm9f28eefubnwwIh4/Txt/+vBb+sxfwZ7jhVU3FhERqSUUHKrZ/8W0YGPSQPq3bspnPxyk7fNpvJ2xgzq8JIiIiLgRBYfLoHGQLx/f34O/D+6MYcB9/15HwpurOFxQbHZpIiIiv4mCw2VisVi4/3fXkD1hADdFhvHxpj20fT6ND7/bbXZpIiIil0zB4TK7KiSAFQ/1ZvbtHSgoKef/3lzFvf9ey4lih9mliYiIXDQFhyvAw8PCY/HXkzGuPx2aN+CdjJ3EPJ/GZ9sOmF2aiIjIRVFwuIKuDwvmyzF9mHxrWw6cLObW11bwp/9+Q5Gj3OzSRERELoiCwxXmafXgr7fFsO5PfWkdFkzq2q3EzV7M17uOmF2aiIhIlRQcTBLXvAHfju3PuJta88PRk3RLWcZflmTh0IJZIiJSgyk4mMjH08qsQXF89vCtRNT3Y9qKTXR+aQnfHThudmkiIiLnpOBQA9wUGUb2+IGM/N01ZO8/Tsc5nzBrZQ4VTi2YJSIiNYuCQw0R6OPJ/MGd+d/IHoT4eTNx8Xp6pC5nx9ECs0sTERFxUXCoYfq3bsbGpIHcGdOCtT8eIfaFRby6bpumrBYRkRpBwaEGauDvzfsj4nlveDe8rB48uvBr+v19JftOFJldmoiIuDkFhxpsaGxLNiYN5LZWTVi+dT9tZ6Xxr/W5uvsgIiKmUXCo4ZoE+7F41C288n+/o6zCyT3vfcmQt1dz1F5idmkiIuKGFBxqAYvFwoOdo8gaP4BuLUNZuHE3bZ9PY9H3e80uTURE3IyCQy0S2TCQlY/05rkB7Tle5OD2f37OAx+kc7JEC2aJiMiVoeBQy1g9PBjfow3fju1HbNMQXv9mO+2eX8QX2w+aXZqIiLgBBYdaKjq8Puv+1Iene93A3hNF9Jz3KeM+/pbiMi2YJSIil4+CQy3mZbPyt77t+HJMH6IaBfHS6i10mL2YjD15ZpcmIiJ1lK2qHZxOJ1OmTGHr1q14eXmRnJxMixYtXNtXrlxJamoqNpuNhIQEBg8efN42Y8eO5ejRowDs27ePmJgY5syZw6pVq0hNTQWgdevWTJ48mb///e+sWbMGgJMnT3L06FHWrl3L8uXLee655wgPDwdgzJgxdOzYsdo7pjbpGNGQzHH9eeqTLFLWbKHL3CU83esGnup1A55WZUMREalGRhWWLVtmPPnkk4ZhGEZWVpbx0EMPubY5HA6jV69eRn5+vlFaWmrccccdxuHDhyttYxiGkZ+fbwwaNMg4dOiQUVBQYPTv39/Iy8szDMMw5s+f7/r30xITE43Vq1cbhmEYs2fPNpYuXVpV2YZhGEZJSYmRkZFhlJSUXND+dcFn2/YbVz270PAY97Zx4+xFRs6B4+fdNyMj4wpWJqep382hfjeH+v3Ku9yffVV+Hc3MzKR79+4AtGvXjk2bNrm27dixg4iICIKDg/Hy8iIuLo6MjIxK2wCkpKQwfPhwQkNDycrKIioqipkzZ3LXXXfRsGFDQkJCXPsuX76coKAg1/FycnJYuHAhd911FzNmzKC8XM/0z3TLteFkjx/AH2+MJHPvMTrMWcycVd/jdGrSKBER+e2qfFRht9sJCAhwvbZarZSXl2Oz2bDb7QQGBrq2+fv7Y7fbK22Tl5dHeno6kyZNAuD48eN8/fXXfPTRR/j5+XH33XfTrl07WrZsCcBrr73G7NmzXcfq2rUrvXr1olmzZkyePJn333+f4cOHV3oNvwwu7uDRa72J9m3O9G/2M+F/mbz31Wb+2qkJTQO8ztovMzPTpArdm/rdHOp3c6jf65Yqg0NAQACFhYWu106nE5vNds5thYWFBAYGVtpm6dKlDBgwAKvVCkC9evW44YYbaNSoEQAdOnRg8+bNtGzZku3btxMUFHTWmIqEhASCgoIA6NmzJ8uWLavyIqOjo/H29q5yv7omLg7u6VnCwwu+5sPvdnPPsh95YVAHRv7uGiwWC5mZmcTFxZldpttRv5tD/W4O9fuVV1paelm/MFf5qKJ9+/asXr0agOzsbKKiolzbIiMj2bVrF/n5+TgcDjIyMoiNja20TXp6OvHx8a7X0dHRbNu2jWPHjlFeXs6GDRu45pprAFi3bt1Z+xqGwaBBgzh48KDrWG3atPkt11/nNQrw4f/9MZ637uqK1WLhwf/3FYP++TkHTmrBLBERuXhV3nHo3bs3a9euZejQoRiGwbRp00hLS6OoqIghQ4YwceJERo4ciWEYJCQkEBYWds42p+Xm5tK8eXPX65CQEMaPH8+oUaMA6NOnjyto5Obm0rVrV9e+FouF5ORkRo8ejY+PD5GRkQwePLjaOqOuslgsDI+7mpuuDmPkB+v4ZPM+2s5KY3xsI/RFQERELobFMOruUounb9e466OKc3E6DV5dt40nFmVSXFbBkHZX8XJCR0L81D9Xim7dmkP9bg71+5V3uT/79CN/N+PhYeGRbteRNX4A0Q18+SD7R9rOSmPpln1mlyYiIrWAgoOburZREPN7X8XUfu04WlhK/7+v5OEFX2EvLTO7NBERqcEUHNyYzcPCxJ438PXjfbkhvB7z038g9oVFfLnzsNmliYhIDaXgIMQ0CeHrx/vx5C1t+PFYITe/sown0zIpKaswuzQREalhFBwEAG+blWn927Pq0Vu5OiSQ57/4no4vLiZr7zGzSxMRkRpEwUHO0qVlKFnj+/NwlyhyDp6g00ufMPXTjZRXOM0uTUREagAFB/kVf29PXk74HUsSexIW6Mtfl26g+8tL2Xr4hNmliYiIyRQc5Lxuva4JGyYM4O64lnyzO4+42YtJWbNZC2aJiLgxBQepVH0/b96+qxv/+WM8fp42Hv8og9teW8Hu44VVNxYRkTpHwUEuSELbFnz3xEAGtG7Gyu0HiXk+jbe+3UEdnnhURETOQcFBLlhYoC8f3X8z/xjSGcOA+99fxx1vfMHhgmKzSxMRkStEwUEuisVi4b6O17BhwgBujgzjfzl7uWFWGv/duNvs0kRE5ApQcJBL0iIkgE8f6s2c2ztgLy3nzrdW8cd/rSW/2GF2aSIichkpOMgl8/Cw8Kf468kc158bmzfg3cydxMxK49Ot+80uTURELhMFB/nNWoUF8+WYPjzTJ4aDBcX0mf8ZY/77DYVaMEtEpM5RcJBqYbN68OfebUl/rC+tw4J5Ze1W2s9eTPqPR8wuTUREqpGCg1Sr9s0a8O3Y/oy7qTU78gqIf3kZT3+ShaNcC2aJiNQFCg5S7Xw8rcwaFMfKh2+lRX1/Zny2iU4vLWHj/uNmlyYiIr+RgoNcNvGRYWSNH8ADna5lw/7jdHzxE55buYkKpxbMEhGprRQc5LIK9PHk1Ts7kTbqFhr6ezNpcRY3py5n+9GTZpcmIiKXQMFBroh+1zdlw4SBDG7XgnU/HiH2hUXMW7tVU1aLiNQyCg5yxTTw9+bf98Tz3vBueFutjP7vN/Sd/xl787VglohIbaHgIFfc0NiWbEwaSJ9WTfh02wFinl/Ee5k7dfdBRKQWUHAQUzQJ9mPRqFt49c5OlDudjPjXWga/vZoj9hKzSxMRkUooOIhpLBYLD3S6lqzxA+h+dSj/3bibtrPS+N+mPWaXJiIi56HgIKa7ukEgnz3cm+cGtCe/2MEf3viCke+v42SJFswSEalpFBykRrB6eDC+RxsyxvWnfbMQ3vx2B+2eX8Tn2w+aXZqIiJxBwUFqlDaN67HuT335S++27D1RRK95nzL2o28pLis3uzQREUHBQWogT6sHU/rE8OWYPlzXKIi5a7bQYfZivt191OzSRETcnoKD1FgdIxqSOb4/f+reii2HT9I1ZSmTl2ZTVqEpq0VEzKLgIDWar6eNOb+/kRUP96ZpsB/Jn35Hl7lLyDmYb3ZpIiJuyVbVDk6nkylTprB161a8vLxITk6mRYsWru0rV64kNTUVm81GQkICgwcPPm+bsWPHcvToqdvN+/btIyYmhjlz5rBq1SpSU1MBaN26NZMnTwYgPj6eq666CoB27doxfvx4srOzmTp1KlarlW7dujF69Ojq7hOpgXpc05js8QMY93EGb367gxvnLCa5byyPxbfC6qH8KyJyxRhVWLZsmfHkk08ahmEYWVlZxkMPPeTa5nA4jF69ehn5+flGaWmpcccddxiHDx+utI1hGEZ+fr4xaNAg49ChQ0ZBQYHRv39/Iy8vzzAMw5g/f76Rl5dn/Pjjj8aDDz74q3oGDRpk7Nq1y3A6ncaoUaOMTZs2nbf2kpISIyMjwygpKanqMt1SRkaG2SVcko+/2200/ut/DI9xbxs3vbzU2HH0pNklXZTa2u+1nfrdHOr3K+9yf/ZV+VUtMzOT7t27A6e+9W/atMm1bceOHURERBAcHIyXlxdxcXFkZGRU2gYgJSWF4cOHExoaSlZWFlFRUcycOZO77rqLhg0bEhISQk5ODocOHeKee+7hgQceYOfOndjtdhwOBxEREVgsFrp160Z6enp15iipBQZFN2dj0kD+cEMEa3Yept3zi5ifvk1TVouIXAFVPqqw2+0EBAS4XlutVsrLy7HZbNjtdgIDA13b/P39sdvtlbbJy8sjPT2dSZMmAXD8+HG+/vprPvroI/z8/Lj77rtp164djRo1IjExkb59+5KRkUFSUhKpqalnHdff3589e6qeZfCXwUV+lpmZaXYJl2xitD/tApowK+MgDy/4mnfW5vDnTuE09PU0u7Qq1eZ+r83U7+ZQv9ctVQaHgIAACgt/Xr3Q6XRis9nOua2wsJDAwMBK2yxdupQBAwZgtVoBqFevHjfccAONGjUCoEOHDmzevJkePXq49unQoQOHDh3C39//V+cLCgqq8iKjo6Px9vaucj93k5mZSVxcnNll/CYdOsC9vQoZ+UE6K7YdYPiyXbx8x+8YEnuV2aWdV13o99pI/W4O9fuVV1paelm/MFf5qKJ9+/asXr0agOzsbKKiolzbIiMj2bVrF/n5+TgcDjIyMoiNja20TXp6OvHx8a7X0dHRbNu2jWPHjlFeXs6GDRu45pprePnll3nrrbcA2LJlC02aNCEwMBBPT092796NYRh8+eWXdOjQoXp6QmqtZvX8WZrYk5cTOlJSXsFd765h2DurySssNbs0EZE6p8o7Dr1792bt2rUMHToUwzCYNm0aaWlpFBUVMWTIECZOnMjIkSMxDIOEhATCwsLO2ea03Nxcmjdv7nodEhLC+PHjGTVqFAB9+vQhKiqKxMREkpKSWLVqFVarlenTpwPwzDPPMGHCBCoqKujWrRsxMTHV3SdSC1ksFh7uch29rg3nvn+v4z/Zu1iz8zB/H9yZvtc3Nbs8EZE6w2LU4RFlp2/X6FHFudXVW4gVTifPf/49k5dtoKzCyahO1/D8wA4E+tSMsQ91td9rOvW7OdTvV97l/uzTD+ClzrF6ePBkz2i+ebwfbcPr84+vthP7wiLW7DxkdmkiIrWegoPUWW2b1Oerx/sysWc0u44X0uOV5TyRlklJWYXZpYmI1FoKDlKnedusTO0Xy+rRtxHZIJAXvvieji8uZv3ePLNLExGplRQcxC10vqoR68f155Gu15Fz8ASdX1pC8qcbKdeCWSIiF0XBQdyGv7cnKXd0ZGliT8ICfZm8dAPdUpay5dAJs0sTEak1FBzE7fS+rgkbkwYyPO5qvt2TR9zsxcxdvRmns87+wEhEpNooOIhbqufrxVt3deX//fEmArxtjP04g1tf+5Rdx+xmlyYiUqMpOIhbu6NtBBuTBjKoTTM+336ImOcX8cY327VglojIeSg4iNsLC/Tlv/fdzD+HdMFigVEfpPOHN77gUEGx2aWJiNQ4Cg4inJqy+t6OkWyYMJBbrmlMWs5e2s5KY+HGXWaXJiJSoyg4iJwhor4/yx7sxYu/74C9tJzBb61mxL++JL/YYXZpIiI1goKDyC94eFgY0/16Msf1p2NEA97LzKXtrDSWb91vdmkiIqZTcBA5j1ZhwawZ3Ye/9YnhUEExfed/xuiFX1NYWmZ2aSIiplFwEKmEzerB073bkv5YX9o0Dmbeum20n72YdbmHzS5NRMQUCg4iF6B9swZ883h/Jtzcmh15BdyUupynFq+ntFwLZomIe1FwELlAPp5WZg6M4/NHbqVFfX9mrsyh04tL2LD/mNmliYhcMQoOIhep+9VhZI0fwAOdrmXjgeP87sUlzPjsOy2YJSJuQcFB5BIE+njy6p2dWDTqFhr6e/P0J9ncnLqcH46cNLs0EZHLSsFB5Dfoe31TNiYNZGjsVaTvOkL72Yt45cutWjBLROosBQeR3yjEz5v3hnfn3/d0x8dmZcyH39D375+xN7/Q7NJERKqdgoNINRnc7io2Jg2k7/VNWbHtAG1npfFOxk4tmCUidYqCg0g1Cg/yI21kD167sxMVhsG9/17LnW+t5oi9xOzSRESqhYKDSDWzWCyM6nQt2eMHEH91KB9+t5u2s9L4eNMes0sTEfnNFBxELpOWDQL57OFbeX5QHCdKHNzxxhfc//467A5NGiUitZeCg8hl5OFhYexNrckY25/2zUJ469sd3PXJTlb+cMDs0kRELomCg8gV0LpxPdb9qS9/6d2WI8Vl9H51BY9/9C1FjnKzSxMRuSgKDiJXiKfVgyl9YvjnrS1pFRpEypotxM1ezDe7j5pdmojIBVNwELnCWjfwJWNcfx6Pv55tR07SLWUpf12SjUMLZolILaDgIGICX08bL9zegc8e7k2zYD+mrviOLnOXsunAcbNLExGplIKDiIluvqYx2RMGcF/HSLL2HePGOZ/w/Oc5VDi1YJaI1EwKDiImC/Lx4h9DuvDR/TdT38+LJxet55ZXPmVnXoHZpYmI/Iqtqh2cTidTpkxh69ateHl5kZycTIsWLVzbV65cSWpqKjabjYSEBAYPHnzeNmPHjuXo0VMDwfbt20dMTAxz5sxh1apVpKamAtC6dWsmT56M3W4nKSkJu91OWVkZEydOJDY2luXLl/Pcc88RHh4OwJgxY+jYsePl6BuRK2pgm+Z0btGIRxZ+zcKNu2n3/CJmDYojsdO1WCwWs8sTETnFqMKyZcuMJ5980jAMw8jKyjIeeugh1zaHw2H06tXLyM/PN0pLS4077rjDOHz4cKVtDMMw8vPzjUGDBhmHDh0yCgoKjP79+xt5eXmGYRjG/Pnzjby8POOll14y3njjDcMwDGPHjh3G73//e8MwDGP27NnG0qVLqyrbMAzDKCkpMTIyMoySkpIL2t/dZGRkmF2CW6qq351Op/Fe5k4j5On3DY9xbxt9568w9uUXXqHq6i79eTeH+v3Ku9yffVU+qsjMzKR79+4AtGvXjk2bNrm27dixg4iICIKDg/Hy8iIuLo6MjIxK2wCkpKQwfPhwQkNDycrKIioqipkzZ3LXXXfRsGFDQkJCuPfeexk6dCgAFRUVeHt7A5CTk8PChQu56667mDFjBuXl+h281C0Wi4W72rdkY9JAekeFs2zLftrOSuP9rFyzSxMRqfpRhd1uJyAgwPXaarVSXl6OzWbDbrcTGBjo2ubv74/dbq+0TV5eHunp6UyaNAmA48eP8/XXX/PRRx/h5+fH3XffTbt27WjZsiUAR44cISkpiaeeegqArl270qtXL5o1a8bkyZN5//33GT58eKXX8MvgIj/LzMw0uwS3dKH9nhxXj9hgg7nrD3H3u1/yxuqNPHFjY+p5V/m/rpyD/rybQ/1et1T5t09AQACFhYWu106nE5vNds5thYWFBAYGVtpm6dKlDBgwAKvVCkC9evW44YYbaNSoEQAdOnRg8+bNtGzZkq1btzJu3DieeOIJ1ziGhIQEgoKCAOjZsyfLli2r8iKjo6NddyzkZ5mZmcTFxZldhtu52H7v0AFG9jrJff9ex4ofj7DpeBnzB3eif+tml7HKukd/3s2hfr/ySktLL+sX5iofVbRv357Vq1cDkJ2dTVRUlGtbZGQku3btIj8/H4fDQUZGBrGxsZW2SU9PJz4+3vU6Ojqabdu2cezYMcrLy9mwYQPXXHMN27dv57HHHuOFF17gpptuAsAwDAYNGsTBgwddx2rTpk01dINIzXZNwyC+ePRWZvRvz7GiUgb983MS/5NOQUmZ2aWJiJup8o5D7969Wbt2LUOHDsUwDKZNm0ZaWhpFRUUMGTKEiRMnMnLkSAzDICEhgbCwsHO2OS03N5fmzZu7XoeEhDB+/HhGjRoFQJ8+fYiKiuLhhx/G4XAwdepU4NTdjXnz5pGcnMzo0aPx8fEhMjKSwYMHV3efiNRIVg8Pkm5pQ5/rm/DHf63ln19v57MfDvD60K7cFBlmdnki4iYshmEYZhdxuZy+XaNHFeemW4jmqI5+d5RX8LflG5m5MgcDg8fjrye5byw+ntZqqrLu0Z93c6jfr7zL/dmnCaBEaiEvm5XkfrGsGXMb1zQIZM6qzdw4ZzGZe/LMLk1E6jgFB5FarFOLRmSO68+jXa/j+0Mn6DJ3CX9btoGyCk1ZLSKXh4KDSC3n7+3J3Ds6suzBXjQO9OWZ5RvplrKUzYdOmF2aiNRBCg4idUSvqHA2JA3kng5Xk7Enjw6zF/PS6s04nXV2GJOImEDBQaQOqefrxZvDurLg3psI9LEx7uMMer/6KT8es5tdmojUEQoOInXQH26IYOOEgdwe3Zwvdhyi3fOLeP3r7dThH1GJyBWi4CBSR4UG+rLw3pt4Y1gXLBZ44D/p3P765xw8WWx2aSJSiyk4iNRhFouFER0i2TBhID2vbczi7/fRdlYaCzbsMrs0EamlFBxE3EBEfX+WJvbipd/fSFFZOUPeXs3wd9dwvKjU7NJEpJZRcBBxEx4eFkZ3b8X68QP4XURD/p31IzHPL2LZlv1mlyYitYiCg4ibiWoUxOrRt/Fs33YcKiim398/45EFX2Mv1YJZIlI1BQcRN2SzevBUrxv46rF+RDeux2vp22j/wmLW5h42uzQRqeEUHETcWGyzEL4Z24+kHm3YeayAm1OXM2nRekrLK8wuTURqKAUHETfnbbMyY0B7vnjkNq4K8ee5z3P43YufkL3vmNmliUgNpOAgIgB0uzqUrPEDeLBzFN8dyKfTS0uYvuI7yrVgloicQcFBRFwCvD155f9+x+IHbqGRvzd/XpLNTanL2HbkpNmliUgNoeAgIr/Sp1VTNiQNZGjsVXy16yjtX1jEy2u2aMEsEcFmdgEiUjOF+Hnz3vDu/P6GCB5d8DWPffQtE9IyaRzoQ5MgPxoH+dIkyJfwIF/Cg/wID/KlSbAv4YG+NPT3wcPDYvYliMhloOAgIpW6M6YF3VuG8tel2eQczGf/yWLW7ztG2e7zj32weVhoHHgqSDQOPBUsTv97k2A/wn/a1kgBQ6TWUXAQkSo1DvJl/uDOrtdOp8GxolIOFBSz/0QxB04Wc+BkEQdOFrP/ZDEHTxaz/2QR2fuO46jIO+9xrT8FjPCgn//55d2MJkF+NArwxuqhJ6siNYGCg4hcNA8PCw0DfGgY4MMN4fXPu59hGBwrcnDgZBH7T54dMM7857sDx8nYU3nACAvwOfuxSJAvjc8IF+FBvoQG+GCzKmCIXE4KDiJy2VgsFhr4e9PA35voKgJGfrHDFS72nyz66a7FT+HiRBEHCorJOXiCzL3nn1/Cw2IhNMDnjMcivoQH+hEe7EvR4QKM0DzCg3wJU8AQuWQKDiJiOovFQn0/b+r7edOmcb3z7mcYBidKyth/4tePRc68g7H50AnWnytgrN7z0/k4FTDOM8jz9B2NsEBfPBUwRM6i4CAitYbFYqGerxf1fL1oXUXAOFlS5rp7ceBkMd9+/wPWoAZn3c3YeuQEWZXMkGmxQCN/n1+NwTjXmAwFDHEXCg4iUudYLBaCfb0I9vWiVVgwAK04Tlxc3Fn7GYZBQWmZ6+7FmY9F9p8o5mBBMftPFLEjr4AN+49Xes5GAd6uxyLhv3hMEh506r3GQb5426yX7bpFrgQFBxFxWxaLhSAfL4J8vLguNLjSfQtKyjhQ8NMYjBNFP4WKswd75h6zs/FA5QGjgZ/32T9NPWOg55l3MxQwpKZScBARuQCBPp4E+ngS1Sio0v3sP93BOOcgz59Cxq7jhXx3IL/S44T4eZ3zp6m/HJPh46mAIVeWgoOISDUK8Pbk2kaeXFtFwCgsPfMOxs+PRQ4UFLvCxt4TRWw6WHnAqO/rdcaYC7+fQ8UZE22FB/ni66m/7qV66E+SiIgJ/L09ucbbk2saVh4wihzlPz8WKfhpDIbrLsbPj0m+P3Si0uPU+ylgnOuxyJmDPv289LEgldOfEBGRGszPy8bVDQK5ukFgpfsVl5Wf87HI6denf7a6uYqAEeTj+es1SH4RNpoE+eLv7Vmdlym1iIKDiEgd4Otpo2WDQFpWETBKyio4WHDuMRhnDvrccrjypdQDvc8MGOdYj+SnX5JI3aPgICLiRnw8rVwVEsBVIQGV7ldaXsHBk8U//zT1jDkxzpx4a+uRygOGn82Dpsv30CTY74zZPH8ag3HGQM9Ab08sFi14VhtUGRycTidTpkxh69ateHl5kZycTIsWLVzbV65cSWpqKjabjYSEBAYPHnzeNmPHjuXo0aMA7Nu3j5iYGObMmcOqVatITU0FoHXr1kyePJnS0lKSkpLIy8vD39+fmTNnEhISQnZ2NlOnTsVqtdKtWzdGjx59mbpGRMR9edustAgJoEUVAcNRXsHBgpJfrUFyOmTsOJjHiZIyfjh6qNLj+HvZLmgMRpCPAobZqgwOK1aswOFw8MEHH5Cdnc2MGTOYN28eAGVlZUyfPp0FCxbg6+vLsGHD6NGjB1lZWedsM2fOHABOnDjBiBEjmDRpEna7nVmzZvH2228TEhLC3//+d44fP87HH39MVFQUY8aMYfHixbzyyiv8+c9/ZvLkyaSkpNC8eXMSExPJycmhTZs2l7eXRETkUOeFUQAACo1JREFUnLxsViLq+xNR3/+c2zMzM4mLi6OswsmhguJfr0dy5qDPgmLW5BZgGOc/n5+XlfBAvzOWbD/HiqrBfgQrYFw2VQaHzMxMunfvDkC7du3YtGmTa9uOHTuIiIggOPjUxClxcXFkZGSQnZ193jYAKSkpDB8+nNDQUNasWUNUVBQzZ85kz5493Hnnnfz/9u4/tom6jwP4+67XbvSuZRYmPsiWOLUJZAzoFhKTOvUPBc30D/wFmkkiJGPAgyKQjZlFCZNkKn8IxkT/ICZoIosaE000mqjMYtnz2GTjGYEs8uwZUAZs7Qi9bmu73vf5A1c23Lo+Prt2bO9XssDdfXv73ocf997d977ncrkQCASwefNmAEBlZSU++OAD6LqOeDyO4uJiAIDX64Xf72dwICKa4awWGUsKVCwpmDhgjBpJGriiD6feR3IjVAyhNzI45rHVIZzo7oORJmHkK5YJb4vcOsizYJ6NAeN/NGVw0HUdmnbzUpXFYsHIyAgURYGu63A4bg7EUVUVuq6n/UwoFILf78fevXsBAAMDA2hra8NXX30Fu92OF198EStXrhy3b1VVEYlE/rRfVVVx4cKFKQ/y1uBCNwUCgVx3YU5i3XODdc+Nv1J3GcDdAO62ASgEUGgDYANw4wfVEUNgYHgE/cMj6B+88WvfYAKh4RH0DY6uH8Z/wjqMNFcwbLKEhfOUMV/WccuF8xQsmKdgvs3CgPGHKYODpmmIRqOpZcMwoCjKhNui0SgcDkfaz3z33XeoqqqCxXJjtrOCggIsX74chYWFAICKigqcOXNm3D6i0SicTueE38/pTP8MNACUlpYiLy9vynZzzeglRMou1j03WPfcyHXdk4aBq/pw2veR9F4fwunwEJJpEobNIk86e+eN2yM3rm4sUPNyHjBisZipPzBPGRw8Hg9++uknPPHEE2hvb4fb7U5tu/fee9HT04Nr167Bbrfjt99+w6ZNmyBJ0qSf8fv9qK2tTS2Xlpaiq6sL4XAYTqcTHR0deO655+DxeHD8+HGUlZWhtbUV5eXl0DQNVqsV58+fR1FREXw+HwdHEhHRpCyy/MfJ3Q5PmnZJw0B/NJYaczHZ+0j+caF/yoBx1wS3Re4aM4vnYqcdC+x5kOXb8wrGlMHh0UcfxYkTJ7B+/XoIIXDgwAF8/fXXGBwcxPPPP4/6+nps2rQJQgg8/fTTWLRo0YSfGdXd3Y2ioqLUssvlwq5du1LjGdauXQu3242ioiLU1dVhw4YNsFqtOHjwIABg37592L17N5LJJLxeL1asWDHdNSEiojnGIstY5JiHRY55WJWmnWEI9EeH/zzI85aJtwIXw0gkjUn3o8jSuDkwJhuDsVDNn3EBQxIi3fjV29vo5RreqphYri8hzlWse26w7rkxV+tuGAKhwdi4R1Mne/nZVAFj9OmRWyfaGvuYaqGWB4ssAzD/3McJoIiIiKaZLEso1PJRqOWjbPEdk7YTQiAUjaXGXNw6XfjoRFsdlwbwzwuhSfdjkSUs0vKxeL4dSxfY8fdl6WcQ/X8wOBAREeWIJElYqOVjoZaP5X9LHzDCg3H0Xh/80/tHxl7N+FfvAILh6wwOREREc5kkSVig5mGBmofSKQLGNX0Q/+46a1pfZNP2TERERFklSZLpr0ZncCAiIqKMMTgQERFRxhgciIiIKGMMDkRERJQxBgciIiLKGIMDERERZYzBgYiIiDLG4EBEREQZY3AgIiKijDE4EBERUcZm9bsqRt8YHo/Hc9yTmSsWi+W6C3MS654brHtusO7ZNXrOGz0HTjdJmLXnGSASiaCrqyvX3SAiIso6t9sNh2P635I5q4ODYRiIRqOwWq2QJCnX3SEiIjKdEAKJRAKqqkKWp39EwqwODkRERDS9ODiSiIiIMsbgQERERBljcCAiIqKMMTgQERFRxmb1PA5zRSKRQENDA4LBIOLxOGpra3Hfffehvr4ekiTh/vvvxxtvvAFZltHS0oLPPvsMiqKgtrYWjzzyCIaHh7Fnzx6EQiGoqorm5ma4XC60t7fjrbfegsVigdfrxfbt23N9qDNSKBTCunXrcOTIESiKwrpnwYcffogff/wRiUQCGzZswOrVq1l3kyUSCdTX1yMYDEKWZezfv59/303W0dGBd999F0ePHkVPT49ptX7//ffx888/Q1EUNDQ0oKysLH3HBN32Pv/8c9HU1CSEECIcDouHHnpI1NTUiJMnTwohhGhsbBTff/+9uHr1qqiqqhKxWExcv3499fsjR46IQ4cOCSGE+Oabb8T+/fuFEEI89dRToqenRxiGITZv3iw6Oztzc4AzWDweF1u3bhWPPfaY+P3331n3LDh58qSoqakRyWRS6LouDh06xLpnwQ8//CB27NghhBDC5/OJ7du3s+4m+uijj0RVVZV49tlnhRDCtFp3dnaK6upqYRiGCAaDYt26dVP2jbcqZoG1a9filVdeSS1bLBacPn0aq1evBgBUVlbi119/xalTp7Bq1SrYbDY4HA4UFxfj7NmzCAQCePDBB1Nt/X4/dF1HPB5HcXExJEmC1+uF3+/PyfHNZM3NzVi/fj3uvPNOAGDds8Dn88HtdmPbtm3YsmULHn74YdY9C+655x4kk0kYhgFd16EoCutuouLiYhw+fDi1bFatA4EAvF4vJEnC4sWLkUwmEQ6H0/aNwWEWUFUVmqZB13Xs2LEDr776KoQQqUmvVFVFJBKBruvjZhFTVRW6ro9bP7atpmnj2kYikewe2Az35ZdfwuVypf6BAmDds2BgYACdnZ147733sG/fPuzevZt1zwK73Y5gMIjHH38cjY2NqK6uZt1NtGbNGijKzdEEZtX6r/wZcIzDLNHb24tt27bhhRdewJNPPol33nkntS0ajcLpdELTNESj0XHrHQ7HuPXp2jqdzuwd0G3giy++gCRJ8Pv9OHPmDOrq6sYlddbdHAUFBSgpKYHNZkNJSQny8vJw+fLl1HbW3Rwff/wxvF4vdu3ahd7eXmzcuBGJRCK1nXU319gZIKez1lardcJ9pO3LdB0U5U5/fz9efvll7NmzB8888wwAYNmyZWhrawMAtLa2oqKiAmVlZQgEAojFYohEIjh37hzcbjc8Hg+OHz+ealteXg5N02C1WnH+/HkIIeDz+VBRUZGzY5yJPv30U3zyySc4evQoli5diubmZlRWVrLuJisvL8cvv/wCIQSuXLmCoaEhPPDAA6y7yZxOZ+qEMn/+fIyMjPD/mSwyq9Yejwc+nw+GYeDSpUswDAMulyttXzjl9CzQ1NSEb7/9FiUlJal1r7/+OpqampBIJFBSUoKmpiZYLBa0tLTg2LFjEEKgpqYGa9aswdDQEOrq6tDX1wer1YqDBw+isLAQ7e3tOHDgAJLJJLxeL3bu3JnDo5zZqqur8eabb0KWZTQ2NrLuJnv77bfR1tYGIQR27tyJJUuWsO4mi0ajaGhoQF9fHxKJBF566SWUlpay7ia6ePEiXnvtNbS0tKC7u9u0Wh8+fBitra0wDAN79+6dMrwxOBAREVHGeKuCiIiIMsbgQERERBljcCAiIqKMMTgQERFRxhgciIiIKGMMDkRERJQxBgciIiLKGIMDERERZey/oD2abfHEDzYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "output_table.plot(kind='line',y='LSM',title='Price from LSM')\n",
    "plt.show()\n",
    "output_table.plot(kind='line',y='NN',title='Price from RLNN')\n",
    "plt.show()\n",
    "output_table.plot(kind='line',y='XGBoost',title='Price from XGBoost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c38e825648>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax=plt.gca()\n",
    "output_table.plot(kind='line',y='LSM',color='red',ax=ax)\n",
    "output_table.plot(kind='line',y='NN',color='blue',ax=ax)\n",
    "output_table.plot(kind='line',y='XGBoost',color='orange',ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN will always generate bigger values than LSM and XGBoost do, also it converges faster than XGBoost, in order to see the number of paths that XGBoost nees to converge, we built another 500,000 paths  sim_rates and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_rates_500k=smm(DFT, corr, 500000, len(para),para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prc_lsm_500k=Bermudan_swaption_lsm(lockout,maturity,sim_rates_500k,strike,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 18\n",
      "Epoch 1/10, train_loss: 0.01395, valid_loss: 0.00075\n",
      "Epoch 2/10, train_loss: 0.00988, valid_loss: 0.00075\n",
      "Epoch 3/10, train_loss: 0.00807, valid_loss: 0.00075\n",
      "Epoch 4/10, train_loss: 0.00700, valid_loss: 0.00075\n",
      "Epoch 5/10, train_loss: 0.00627, valid_loss: 0.00075\n",
      "Epoch 6/10, train_loss: 0.00573, valid_loss: 0.00075\n",
      "Epoch 7/10, train_loss: 0.00532, valid_loss: 0.00075\n",
      "Epoch 8/10, train_loss: 0.00498, valid_loss: 0.00074\n",
      "Epoch 9/10, train_loss: 0.00470, valid_loss: 0.00074\n",
      "Epoch 10/10, train_loss: 0.00447, valid_loss: 0.00074\n",
      "At step 17\n",
      "Epoch 1/10, train_loss: 0.01694, valid_loss: 0.00143\n",
      "Epoch 2/10, train_loss: 0.01202, valid_loss: 0.00143\n",
      "Epoch 3/10, train_loss: 0.00985, valid_loss: 0.00143\n",
      "Epoch 4/10, train_loss: 0.00856, valid_loss: 0.00143\n",
      "Epoch 5/10, train_loss: 0.00768, valid_loss: 0.00143\n",
      "Epoch 6/10, train_loss: 0.00704, valid_loss: 0.00143\n",
      "Epoch 7/10, train_loss: 0.00654, valid_loss: 0.00142\n",
      "Epoch 8/10, train_loss: 0.00613, valid_loss: 0.00142\n",
      "Epoch 9/10, train_loss: 0.00580, valid_loss: 0.00141\n",
      "Epoch 10/10, train_loss: 0.00552, valid_loss: 0.00141\n",
      "At step 16\n",
      "Epoch 1/10, train_loss: 0.00610, valid_loss: 0.00207\n",
      "Epoch 2/10, train_loss: 0.00455, valid_loss: 0.00206\n",
      "Epoch 3/10, train_loss: 0.00390, valid_loss: 0.00203\n",
      "Epoch 4/10, train_loss: 0.00351, valid_loss: 0.00200\n",
      "Epoch 5/10, train_loss: 0.00326, valid_loss: 0.00197\n",
      "Epoch 6/10, train_loss: 0.00307, valid_loss: 0.00196\n",
      "Epoch 7/10, train_loss: 0.00292, valid_loss: 0.00195\n",
      "Epoch 8/10, train_loss: 0.00280, valid_loss: 0.00192\n",
      "Epoch 9/10, train_loss: 0.00270, valid_loss: 0.00192\n",
      "Epoch 10/10, train_loss: 0.00261, valid_loss: 0.00196\n",
      "At step 15\n",
      "Epoch 1/10, train_loss: 0.00550, valid_loss: 0.00247\n",
      "Epoch 2/10, train_loss: 0.00426, valid_loss: 0.00244\n",
      "Epoch 3/10, train_loss: 0.00373, valid_loss: 0.00238\n",
      "Epoch 4/10, train_loss: 0.00342, valid_loss: 0.00230\n",
      "Epoch 5/10, train_loss: 0.00320, valid_loss: 0.00222\n",
      "Epoch 6/10, train_loss: 0.00304, valid_loss: 0.00218\n",
      "Epoch 7/10, train_loss: 0.00293, valid_loss: 0.00211\n",
      "Epoch 8/10, train_loss: 0.00285, valid_loss: 0.00210\n",
      "Epoch 9/10, train_loss: 0.00275, valid_loss: 0.00204\n",
      "Epoch 10/10, train_loss: 0.00267, valid_loss: 0.00252\n",
      "At step 14\n",
      "Epoch 1/10, train_loss: 0.00729, valid_loss: 0.00315\n",
      "Epoch 2/10, train_loss: 0.00560, valid_loss: 0.00306\n",
      "Epoch 3/10, train_loss: 0.00486, valid_loss: 0.00303\n",
      "Epoch 4/10, train_loss: 0.00441, valid_loss: 0.00290\n",
      "Epoch 5/10, train_loss: 0.00408, valid_loss: 0.00276\n",
      "Epoch 6/10, train_loss: 0.00383, valid_loss: 0.00264\n",
      "Epoch 7/10, train_loss: 0.00362, valid_loss: 0.00253\n",
      "Epoch 8/10, train_loss: 0.00346, valid_loss: 0.00249\n",
      "Epoch 9/10, train_loss: 0.00341, valid_loss: 0.00244\n",
      "Epoch 10/10, train_loss: 0.00329, valid_loss: 0.00239\n",
      "At step 13\n",
      "Epoch 1/10, train_loss: 0.00817, valid_loss: 0.00385\n",
      "Epoch 2/10, train_loss: 0.00637, valid_loss: 0.00378\n",
      "Epoch 3/10, train_loss: 0.00560, valid_loss: 0.00368\n",
      "Epoch 4/10, train_loss: 0.00514, valid_loss: 0.00355\n",
      "Epoch 5/10, train_loss: 0.00482, valid_loss: 0.00341\n",
      "Epoch 6/10, train_loss: 0.00454, valid_loss: 0.00335\n",
      "Epoch 7/10, train_loss: 0.00433, valid_loss: 0.00322\n",
      "Epoch 8/10, train_loss: 0.00417, valid_loss: 0.00311\n",
      "Epoch 9/10, train_loss: 0.00402, valid_loss: 0.00303\n",
      "Epoch 10/10, train_loss: 0.00390, valid_loss: 0.00296\n",
      "At step 12\n",
      "Epoch 1/10, train_loss: 0.00740, valid_loss: 0.00431\n",
      "Epoch 2/10, train_loss: 0.00601, valid_loss: 0.00421\n",
      "Epoch 3/10, train_loss: 0.00540, valid_loss: 0.00419\n",
      "Epoch 4/10, train_loss: 0.00499, valid_loss: 0.00405\n",
      "Epoch 5/10, train_loss: 0.00467, valid_loss: 0.00396\n",
      "Epoch 6/10, train_loss: 0.00442, valid_loss: 0.00378\n",
      "Epoch 7/10, train_loss: 0.00421, valid_loss: 0.00364\n",
      "Epoch 8/10, train_loss: 0.00404, valid_loss: 0.00352\n",
      "Epoch 9/10, train_loss: 0.00390, valid_loss: 0.00345\n",
      "Epoch 10/10, train_loss: 0.00379, valid_loss: 0.00335\n",
      "At step 11\n",
      "Epoch 1/10, train_loss: 0.00649, valid_loss: 0.00463\n",
      "Epoch 2/10, train_loss: 0.00556, valid_loss: 0.00442\n",
      "Epoch 3/10, train_loss: 0.00507, valid_loss: 0.00421\n",
      "Epoch 4/10, train_loss: 0.00469, valid_loss: 0.00393\n",
      "Epoch 5/10, train_loss: 0.00441, valid_loss: 0.00378\n",
      "Epoch 6/10, train_loss: 0.00419, valid_loss: 0.00375\n",
      "Epoch 7/10, train_loss: 0.00402, valid_loss: 0.00380\n",
      "Epoch 8/10, train_loss: 0.00389, valid_loss: 0.00372\n",
      "Epoch 9/10, train_loss: 0.00378, valid_loss: 0.00362\n",
      "Epoch 10/10, train_loss: 0.00369, valid_loss: 0.00354\n",
      "At step 10\n",
      "Epoch 1/10, train_loss: 0.00853, valid_loss: 0.00531\n",
      "Epoch 2/10, train_loss: 0.00705, valid_loss: 0.00519\n",
      "Epoch 3/10, train_loss: 0.00640, valid_loss: 0.00502\n",
      "Epoch 4/10, train_loss: 0.00597, valid_loss: 0.00482\n",
      "Epoch 5/10, train_loss: 0.00562, valid_loss: 0.00460\n",
      "Epoch 6/10, train_loss: 0.00534, valid_loss: 0.00443\n",
      "Epoch 7/10, train_loss: 0.00513, valid_loss: 0.00430\n",
      "Epoch 8/10, train_loss: 0.00496, valid_loss: 0.00420\n",
      "Epoch 9/10, train_loss: 0.00482, valid_loss: 0.00411\n",
      "Epoch 10/10, train_loss: 0.00471, valid_loss: 0.00404\n",
      "At step 9\n",
      "Epoch 1/10, train_loss: 0.01086, valid_loss: 0.00559\n",
      "Epoch 2/10, train_loss: 0.00859, valid_loss: 0.00542\n",
      "Epoch 3/10, train_loss: 0.00757, valid_loss: 0.00516\n",
      "Epoch 4/10, train_loss: 0.00686, valid_loss: 0.00484\n",
      "Epoch 5/10, train_loss: 0.00633, valid_loss: 0.00461\n",
      "Epoch 6/10, train_loss: 0.00595, valid_loss: 0.00440\n",
      "Epoch 7/10, train_loss: 0.00565, valid_loss: 0.00426\n",
      "Epoch 8/10, train_loss: 0.00541, valid_loss: 0.00415\n",
      "Epoch 9/10, train_loss: 0.00522, valid_loss: 0.00407\n",
      "Epoch 10/10, train_loss: 0.00506, valid_loss: 0.00402\n",
      "At step 8\n",
      "Epoch 1/10, train_loss: 0.00821, valid_loss: 0.00623\n",
      "Epoch 2/10, train_loss: 0.00713, valid_loss: 0.00576\n",
      "Epoch 3/10, train_loss: 0.00640, valid_loss: 0.00548\n",
      "Epoch 4/10, train_loss: 0.00586, valid_loss: 0.00520\n",
      "Epoch 5/10, train_loss: 0.00549, valid_loss: 0.00520\n",
      "Epoch 6/10, train_loss: 0.00523, valid_loss: 0.00513\n",
      "Epoch 7/10, train_loss: 0.00503, valid_loss: 0.00515\n",
      "Epoch 8/10, train_loss: 0.00487, valid_loss: 0.00505\n",
      "Epoch 9/10, train_loss: 0.00474, valid_loss: 0.00518\n",
      "Epoch 10/10, train_loss: 0.00464, valid_loss: 0.00514\n",
      "At step 7\n",
      "Epoch 1/10, train_loss: 0.00707, valid_loss: 0.00538\n",
      "Epoch 2/10, train_loss: 0.00600, valid_loss: 0.00465\n",
      "Epoch 3/10, train_loss: 0.00546, valid_loss: 0.00505\n",
      "Epoch 4/10, train_loss: 0.00514, valid_loss: 0.00493\n",
      "Epoch 5/10, train_loss: 0.00492, valid_loss: 0.00470\n",
      "Epoch 6/10, train_loss: 0.00475, valid_loss: 0.00468\n",
      "Epoch 7/10, train_loss: 0.00463, valid_loss: 0.00459\n",
      "Epoch 8/10, train_loss: 0.00454, valid_loss: 0.00452\n",
      "Epoch 9/10, train_loss: 0.00446, valid_loss: 0.00451\n",
      "Epoch 10/10, train_loss: 0.00439, valid_loss: 0.00446\n",
      "At step 6\n",
      "Epoch 1/10, train_loss: 0.01433, valid_loss: 0.00675\n",
      "Epoch 2/10, train_loss: 0.01117, valid_loss: 0.00663\n",
      "Epoch 3/10, train_loss: 0.00983, valid_loss: 0.00645\n",
      "Epoch 4/10, train_loss: 0.00896, valid_loss: 0.00612\n",
      "Epoch 5/10, train_loss: 0.00830, valid_loss: 0.00603\n",
      "Epoch 6/10, train_loss: 0.00781, valid_loss: 0.00598\n",
      "Epoch 7/10, train_loss: 0.00744, valid_loss: 0.00583\n",
      "Epoch 8/10, train_loss: 0.00714, valid_loss: 0.00572\n",
      "Epoch 9/10, train_loss: 0.00691, valid_loss: 0.00560\n",
      "Epoch 10/10, train_loss: 0.00671, valid_loss: 0.00550\n",
      "At step 5\n",
      "Epoch 1/10, train_loss: 0.00787, valid_loss: 0.00655\n",
      "Epoch 2/10, train_loss: 0.00674, valid_loss: 0.00571\n",
      "Epoch 3/10, train_loss: 0.00612, valid_loss: 0.00546\n",
      "Epoch 4/10, train_loss: 0.00577, valid_loss: 0.00533\n",
      "Epoch 5/10, train_loss: 0.00554, valid_loss: 0.00622\n",
      "Epoch 6/10, train_loss: 0.00540, valid_loss: 0.00598\n",
      "Epoch 7/10, train_loss: 0.00528, valid_loss: 0.00579\n",
      "Epoch 8/10, train_loss: 0.00518, valid_loss: 0.00567\n",
      "Epoch 9/10, train_loss: 0.00510, valid_loss: 0.00569\n",
      "Epoch 10/10, train_loss: 0.00503, valid_loss: 0.00562\n",
      "At step 4\n",
      "Epoch 1/10, train_loss: 0.01214, valid_loss: 0.00719\n",
      "Epoch 2/10, train_loss: 0.00984, valid_loss: 0.00676\n",
      "Epoch 3/10, train_loss: 0.00869, valid_loss: 0.00633\n",
      "Epoch 4/10, train_loss: 0.00791, valid_loss: 0.00615\n",
      "Epoch 5/10, train_loss: 0.00739, valid_loss: 0.00586\n",
      "Epoch 6/10, train_loss: 0.00702, valid_loss: 0.00567\n",
      "Epoch 7/10, train_loss: 0.00675, valid_loss: 0.00551\n",
      "Epoch 8/10, train_loss: 0.00654, valid_loss: 0.00540\n",
      "Epoch 9/10, train_loss: 0.00636, valid_loss: 0.00534\n",
      "Epoch 10/10, train_loss: 0.00621, valid_loss: 0.00526\n",
      "At step 3\n",
      "Epoch 1/10, train_loss: 0.01035, valid_loss: 0.00721\n",
      "Epoch 2/10, train_loss: 0.00870, valid_loss: 0.00668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, train_loss: 0.00776, valid_loss: 0.00614\n",
      "Epoch 4/10, train_loss: 0.00716, valid_loss: 0.00590\n",
      "Epoch 5/10, train_loss: 0.00678, valid_loss: 0.00571\n",
      "Epoch 6/10, train_loss: 0.00651, valid_loss: 0.00557\n",
      "Epoch 7/10, train_loss: 0.00631, valid_loss: 0.00546\n",
      "Epoch 8/10, train_loss: 0.00615, valid_loss: 0.00538\n",
      "Epoch 9/10, train_loss: 0.00602, valid_loss: 0.00533\n",
      "Epoch 10/10, train_loss: 0.00591, valid_loss: 0.00533\n",
      "At step 2\n",
      "Epoch 1/10, train_loss: 0.01197, valid_loss: 0.00689\n",
      "Epoch 2/10, train_loss: 0.00966, valid_loss: 0.00651\n",
      "Epoch 3/10, train_loss: 0.00855, valid_loss: 0.00612\n",
      "Epoch 4/10, train_loss: 0.00787, valid_loss: 0.00593\n",
      "Epoch 5/10, train_loss: 0.00743, valid_loss: 0.00580\n",
      "Epoch 6/10, train_loss: 0.00712, valid_loss: 0.00570\n",
      "Epoch 7/10, train_loss: 0.00688, valid_loss: 0.00562\n",
      "Epoch 8/10, train_loss: 0.00669, valid_loss: 0.00555\n",
      "Epoch 9/10, train_loss: 0.00654, valid_loss: 0.00554\n",
      "Epoch 10/10, train_loss: 0.00642, valid_loss: 0.00550\n",
      "Wall time: 10min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prc_nn_500k=Bermudan_swaption_nn(lockout,maturity,sim_rates_500k,strike,n_epochs,batch_size,learningrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prc_xgb_500k=Bermudan_swaption_xgboost_fixed(lockout,maturity,sim_rates_500k,strike,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European swaption pirce: 0.006943124318928889\n",
      "Bermudan swaption pirce: 0.0076011020883241225\n",
      "Excercise Probability Table\n",
      "    Time_step  ex_prob_Euro  ex_prob_xgb\n",
      "0           2      0.707186     0.599610\n",
      "1           3      0.000000     0.059324\n",
      "2           4      0.000000     0.025002\n",
      "3           5      0.000000     0.013884\n",
      "4           6      0.000000     0.008570\n",
      "5           7      0.000000     0.005944\n",
      "6           8      0.000000     0.004304\n",
      "7           9      0.000000     0.003380\n",
      "8          10      0.000000     0.002512\n",
      "9          11      0.000000     0.002576\n",
      "10         12      0.000000     0.002574\n",
      "11         13      0.000000     0.002982\n",
      "12         14      0.000000     0.003232\n",
      "13         15      0.000000     0.003594\n",
      "14         16      0.000000     0.003952\n",
      "15         17      0.000000     0.005030\n",
      "16         18      0.000000     0.006316\n",
      "17         19      0.000000     0.008356\n"
     ]
    }
   ],
   "source": [
    "print_result(prc_xgb_500k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=make_table(prc_lsm_500k,prc_nn_500k,prc_xgb_500k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame(np.concatenate([output_table.to_numpy(), df2.iloc[:,2].to_numpy().reshape((1,-1))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns=['LSM','Regress now','XGBoost']\n",
    "df2.index=['5000','10000','50000','100000','500000']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSM</th>\n",
       "      <th>Regress now</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>0.008798</td>\n",
       "      <td>0.007769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.007548</td>\n",
       "      <td>0.008774</td>\n",
       "      <td>0.007693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.008731</td>\n",
       "      <td>0.007611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.008706</td>\n",
       "      <td>0.007596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500000</td>\n",
       "      <td>0.007515</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.007601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LSM  Regress now   XGBoost\n",
       "5000    0.007563     0.008798  0.007769\n",
       "10000   0.007548     0.008774  0.007693\n",
       "50000   0.007513     0.008731  0.007611\n",
       "100000  0.007514     0.008706  0.007596\n",
       "500000  0.007515     0.008667  0.007601"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2.plot(kind='line',y='LSM',title='Price from LSM')\n",
    "plt.show()\n",
    "df2.plot(kind='line',y='Regress now',title='Price from Regress now')\n",
    "plt.show()\n",
    "df2.plot(kind='line',y='XGBoost',title='Price from XGBoost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c38e7d4d88>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax=plt.gca()\n",
    "df2.plot(kind='line',y='LSM',color='red',ax=ax)\n",
    "df2.plot(kind='line',y='Regress now',color='blue',ax=ax)\n",
    "df2.plot(kind='line',y='XGBoost',color='orange',ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  XGBoost model seems to converge after 100,000 paths, though it's still decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('output_008_1105.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_rates_1m=smm(DFT, corr, 1000000, len(para),para)\n",
    "prc_xgb_1m=Bermudan_swaption_xgboost_fixed(lockout,maturity,sim_rates_1m,strike,seed)\n",
    "path_series=np.append(path_series,1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_series=np.append(df2['XGBoost'].values,prc_xgb_1m[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   5000,   10000,   50000,  100000,  500000, 1000000], dtype=int64)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c38d982c08>]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(path_series,xgb_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Even we simulated 1 million paths this time, the results did not increase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's move to the Regress later approach\n",
    "\n",
    "#### for a 1 into 9 swaptions,1 year later, it's expected continuation value can be seen the 0.5 into 8.5 swaption, so I calculate the expected value at each time step, then do the regress later using NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bermudan_swaption_rlnn(lockout,maturity,sim_rates,strike,n_epochs,batch_size,learningrate):\n",
    "    expiry=int(2*lockout)\n",
    "    tenor=int(2*maturity)\n",
    "    \n",
    "    step=tenor-expiry  # 18\n",
    "    paths=sim_rates.shape[2] # 5000\n",
    "    di = np.diag_indices(expiry) # 1y 2 dis\n",
    "    \n",
    "# discount factor for calculate the final prc\n",
    "    cmmf = np.prod(sim_rates[di], axis = 0) # (5000,1)\n",
    "    \n",
    "    rates=sim_rates[expiry:tenor,expiry:tenor,:] #18*18*5000\n",
    "    \n",
    "    di=np.diag_indices(int(tenor-expiry-1))\n",
    "    di=(di[0]+expiry,di[1]+expiry)\n",
    "    \n",
    "# discount map for each related time step \n",
    "    discount_mat=np.hstack((np.ones((paths,1)),np.cumprod(sim_rates[di],axis=0).T)) #5000 * 18\n",
    "\n",
    "# initial matrix\n",
    "\n",
    "    value_rlnn,index_rlnn=np.zeros((paths,step)),np.zeros((paths,step))\n",
    "    \n",
    "# calculate the par rate at 18 possible excercise date\n",
    "    denominator=np.sum(sim_rates[expiry-1:tenor,expiry:tenor,:],axis=0)-1 # 18*5000 3D to 2D\n",
    "    \n",
    "    numerator=2*(1-sim_rates[int(tenor-1),expiry:tenor,:]) # 18*5000\n",
    "    par=numerator/denominator # 18*5000\n",
    "    payoff_mat = 0.5 * np.maximum(strike-par.T, 0) * denominator.T #5000 *100\n",
    "    \n",
    "# calculate the forward par rates\n",
    "    di_half = np.diag_indices(tenor-expiry) # 18\n",
    "    half_year_disc=rates[di_half] # 18*5000\n",
    "    denominator_forward_par=denominator-half_year_disc # last step will be 0\n",
    "    numerator_forward_par=2*(half_year_disc-sim_rates[int(tenor-1),expiry:tenor,:])\n",
    "    forward_par=numerator_forward_par/ denominator_forward_par\n",
    "    payoff_fp_mat= 0.5 * np.maximum(strike-forward_par.T, 0) * denominator_forward_par.T  #5000*18\n",
    "    \n",
    "    index_rlnn[:,-1]=np.where(payoff_mat[:,-1]>0,1,0)\n",
    "    value_rlnn[:,-1]=payoff_mat[:,-1]\n",
    "    \n",
    "# European swaption price and ex prob\n",
    "    Euro_prc=np.mean(payoff_mat[:,0]*cmmf)\n",
    "    ex_prob=np.sum(np.where(payoff_mat[:,0]>0,1,0))/paths    \n",
    "            \n",
    "    for i in range(step-2,-1,-1):\n",
    "        cv=payoff_fp_mat[:,i].reshape((paths,1)) # 5000*1\n",
    "        ev=payoff_mat[:,i].reshape((paths,1)) # 5000*1\n",
    "        bond_prc=rates[i:int(tenor-expiry),i,:].T # 5000*n\n",
    "        \n",
    "# construct the basis functions        \n",
    "#        swap_value = np.repeat(ev, 3, axis = 1) ** np.arange(1, 4) # 5000*3\n",
    "        swap_value = Laguerre_feature(ev.ravel(),3)\n",
    "        constant=np.ones((paths,1))\n",
    "#        basis=np.hstack((np.hstack((constant,bond_prc)),swap_value))\n",
    "        bond_prc_laguerre=np.apply_along_axis(Laguerre_feature,0,bond_prc,k=3).reshape((paths,-1))\n",
    "        basis=np.hstack((np.hstack((constant,bond_prc_laguerre)),swap_value))\n",
    "        \n",
    "\n",
    "        # Regress later NN\n",
    "        mask=ev.ravel()>0\n",
    "        ev=ev[mask]\n",
    "        cv=cv[mask] #(1327, 1)\n",
    "        basis=basis[mask] # (1327, 10)\n",
    "        \n",
    "        \n",
    "        print('At step {}'.format(i+2))\n",
    "        cv_rlnn=trainNN(basis,cv,n_epochs,batch_size,learningrate)\n",
    "        value_rlnn[mask,i]=np.where(ev>cv_rlnn,ev,cv).ravel() # cv instead of cv_rlnn\n",
    "        index_rlnn[mask,i]=np.where(ev>cv,1,0).ravel()\n",
    "        \n",
    "        for j in range(i+1,index_rlnn.shape[1]):            \n",
    "             index_rlnn[:,j][index_rlnn[:,int(i)]==1]=0\n",
    "             \n",
    "    prob=pd.DataFrame({'Time_step': np.arange(expiry,tenor),\n",
    "                       'ex_prob_Euro':np.append(ex_prob,np.repeat(0,step-1)),\n",
    "                       'ex_prob_RLNN':np.sum(index_rlnn,axis=0)/paths})\n",
    "\n",
    "    price_rlnn=np.mean(np.sum(np.multiply(discount_mat,np.multiply(index_rlnn,payoff_mat)),axis=1)*cmmf)\n",
    "    \n",
    "    return Euro_prc,price_rlnn,prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step 18\n",
      "Epoch 1/30, train_loss: 0.02517, valid_loss: 0.00728\n",
      "Epoch 2/30, train_loss: 0.01890, valid_loss: 0.00520\n",
      "Epoch 3/30, train_loss: 0.01558, valid_loss: 0.00435\n",
      "Epoch 4/30, train_loss: 0.01352, valid_loss: 0.00385\n",
      "Epoch 5/30, train_loss: 0.01210, valid_loss: 0.00346\n",
      "Epoch 6/30, train_loss: 0.01105, valid_loss: 0.00317\n",
      "Epoch 7/30, train_loss: 0.01023, valid_loss: 0.00295\n",
      "Epoch 8/30, train_loss: 0.00957, valid_loss: 0.00277\n",
      "Epoch 9/30, train_loss: 0.00903, valid_loss: 0.00262\n",
      "Epoch 10/30, train_loss: 0.00857, valid_loss: 0.00249\n",
      "Epoch 11/30, train_loss: 0.00817, valid_loss: 0.00238\n",
      "Epoch 12/30, train_loss: 0.00783, valid_loss: 0.00229\n",
      "Epoch 13/30, train_loss: 0.00752, valid_loss: 0.00221\n",
      "Epoch 14/30, train_loss: 0.00725, valid_loss: 0.00214\n",
      "Epoch 15/30, train_loss: 0.00701, valid_loss: 0.00207\n",
      "Epoch 16/30, train_loss: 0.00679, valid_loss: 0.00201\n",
      "Epoch 17/30, train_loss: 0.00658, valid_loss: 0.00196\n",
      "Epoch 18/30, train_loss: 0.00640, valid_loss: 0.00191\n",
      "Epoch 19/30, train_loss: 0.00623, valid_loss: 0.00187\n",
      "Epoch 20/30, train_loss: 0.00608, valid_loss: 0.00182\n",
      "Epoch 21/30, train_loss: 0.00593, valid_loss: 0.00179\n",
      "Epoch 22/30, train_loss: 0.00580, valid_loss: 0.00175\n",
      "Epoch 23/30, train_loss: 0.00567, valid_loss: 0.00172\n",
      "Epoch 24/30, train_loss: 0.00555, valid_loss: 0.00169\n",
      "Epoch 25/30, train_loss: 0.00544, valid_loss: 0.00166\n",
      "Epoch 26/30, train_loss: 0.00534, valid_loss: 0.00163\n",
      "Epoch 27/30, train_loss: 0.00524, valid_loss: 0.00161\n",
      "Epoch 28/30, train_loss: 0.00515, valid_loss: 0.00158\n",
      "Epoch 29/30, train_loss: 0.00506, valid_loss: 0.00156\n",
      "Epoch 30/30, train_loss: 0.00498, valid_loss: 0.00154\n",
      "At step 17\n",
      "Epoch 1/30, train_loss: 0.03536, valid_loss: 0.02397\n",
      "Epoch 2/30, train_loss: 0.02650, valid_loss: 0.01700\n",
      "Epoch 3/30, train_loss: 0.02182, valid_loss: 0.01408\n",
      "Epoch 4/30, train_loss: 0.01895, valid_loss: 0.01224\n",
      "Epoch 5/30, train_loss: 0.01696, valid_loss: 0.01097\n",
      "Epoch 6/30, train_loss: 0.01550, valid_loss: 0.01003\n",
      "Epoch 7/30, train_loss: 0.01436, valid_loss: 0.00930\n",
      "Epoch 8/30, train_loss: 0.01344, valid_loss: 0.00872\n",
      "Epoch 9/30, train_loss: 0.01268, valid_loss: 0.00823\n",
      "Epoch 10/30, train_loss: 0.01204, valid_loss: 0.00782\n",
      "Epoch 11/30, train_loss: 0.01149, valid_loss: 0.00747\n",
      "Epoch 12/30, train_loss: 0.01101, valid_loss: 0.00717\n",
      "Epoch 13/30, train_loss: 0.01059, valid_loss: 0.00690\n",
      "Epoch 14/30, train_loss: 0.01021, valid_loss: 0.00666\n",
      "Epoch 15/30, train_loss: 0.00987, valid_loss: 0.00644\n",
      "Epoch 16/30, train_loss: 0.00956, valid_loss: 0.00625\n",
      "Epoch 17/30, train_loss: 0.00929, valid_loss: 0.00607\n",
      "Epoch 18/30, train_loss: 0.00903, valid_loss: 0.00591\n",
      "Epoch 19/30, train_loss: 0.00880, valid_loss: 0.00576\n",
      "Epoch 20/30, train_loss: 0.00858, valid_loss: 0.00563\n",
      "Epoch 21/30, train_loss: 0.00838, valid_loss: 0.00550\n",
      "Epoch 22/30, train_loss: 0.00819, valid_loss: 0.00538\n",
      "Epoch 23/30, train_loss: 0.00802, valid_loss: 0.00527\n",
      "Epoch 24/30, train_loss: 0.00786, valid_loss: 0.00517\n",
      "Epoch 25/30, train_loss: 0.00770, valid_loss: 0.00507\n",
      "Epoch 26/30, train_loss: 0.00756, valid_loss: 0.00498\n",
      "Epoch 27/30, train_loss: 0.00742, valid_loss: 0.00490\n",
      "Epoch 28/30, train_loss: 0.00730, valid_loss: 0.00482\n",
      "Epoch 29/30, train_loss: 0.00717, valid_loss: 0.00474\n",
      "Epoch 30/30, train_loss: 0.00706, valid_loss: 0.00467\n",
      "At step 16\n",
      "Epoch 1/30, train_loss: 0.03751, valid_loss: 0.01927\n",
      "Epoch 2/30, train_loss: 0.02770, valid_loss: 0.01491\n",
      "Epoch 3/30, train_loss: 0.02279, valid_loss: 0.01224\n",
      "Epoch 4/30, train_loss: 0.01978, valid_loss: 0.01067\n",
      "Epoch 5/30, train_loss: 0.01772, valid_loss: 0.00960\n",
      "Epoch 6/30, train_loss: 0.01620, valid_loss: 0.00881\n",
      "Epoch 7/30, train_loss: 0.01502, valid_loss: 0.00820\n",
      "Epoch 8/30, train_loss: 0.01407, valid_loss: 0.00771\n",
      "Epoch 9/30, train_loss: 0.01329, valid_loss: 0.00731\n",
      "Epoch 10/30, train_loss: 0.01263, valid_loss: 0.00697\n",
      "Epoch 11/30, train_loss: 0.01206, valid_loss: 0.00668\n",
      "Epoch 12/30, train_loss: 0.01156, valid_loss: 0.00643\n",
      "Epoch 13/30, train_loss: 0.01112, valid_loss: 0.00620\n",
      "Epoch 14/30, train_loss: 0.01074, valid_loss: 0.00601\n",
      "Epoch 15/30, train_loss: 0.01039, valid_loss: 0.00583\n",
      "Epoch 16/30, train_loss: 0.01007, valid_loss: 0.00567\n",
      "Epoch 17/30, train_loss: 0.00979, valid_loss: 0.00553\n",
      "Epoch 18/30, train_loss: 0.00953, valid_loss: 0.00540\n",
      "Epoch 19/30, train_loss: 0.00929, valid_loss: 0.00528\n",
      "Epoch 20/30, train_loss: 0.00907, valid_loss: 0.00518\n",
      "Epoch 21/30, train_loss: 0.00886, valid_loss: 0.00508\n",
      "Epoch 22/30, train_loss: 0.00868, valid_loss: 0.00500\n",
      "Epoch 23/30, train_loss: 0.00850, valid_loss: 0.00491\n",
      "Epoch 24/30, train_loss: 0.00833, valid_loss: 0.00483\n",
      "Epoch 25/30, train_loss: 0.00818, valid_loss: 0.00475\n",
      "Epoch 26/30, train_loss: 0.00803, valid_loss: 0.00469\n",
      "Epoch 27/30, train_loss: 0.00790, valid_loss: 0.00463\n",
      "Epoch 28/30, train_loss: 0.00777, valid_loss: 0.00456\n",
      "Epoch 29/30, train_loss: 0.00764, valid_loss: 0.00450\n",
      "Epoch 30/30, train_loss: 0.00753, valid_loss: 0.00445\n",
      "At step 15\n",
      "Epoch 1/30, train_loss: 0.07105, valid_loss: 0.02735\n",
      "Epoch 2/30, train_loss: 0.05289, valid_loss: 0.02298\n",
      "Epoch 3/30, train_loss: 0.04353, valid_loss: 0.01884\n",
      "Epoch 4/30, train_loss: 0.03777, valid_loss: 0.01647\n",
      "Epoch 5/30, train_loss: 0.03381, valid_loss: 0.01480\n",
      "Epoch 6/30, train_loss: 0.03089, valid_loss: 0.01355\n",
      "Epoch 7/30, train_loss: 0.02862, valid_loss: 0.01259\n",
      "Epoch 8/30, train_loss: 0.02678, valid_loss: 0.01182\n",
      "Epoch 9/30, train_loss: 0.02527, valid_loss: 0.01118\n",
      "Epoch 10/30, train_loss: 0.02399, valid_loss: 0.01065\n",
      "Epoch 11/30, train_loss: 0.02288, valid_loss: 0.01019\n",
      "Epoch 12/30, train_loss: 0.02192, valid_loss: 0.00979\n",
      "Epoch 13/30, train_loss: 0.02108, valid_loss: 0.00944\n",
      "Epoch 14/30, train_loss: 0.02032, valid_loss: 0.00912\n",
      "Epoch 15/30, train_loss: 0.01965, valid_loss: 0.00884\n",
      "Epoch 16/30, train_loss: 0.01903, valid_loss: 0.00859\n",
      "Epoch 17/30, train_loss: 0.01848, valid_loss: 0.00836\n",
      "Epoch 18/30, train_loss: 0.01797, valid_loss: 0.00815\n",
      "Epoch 19/30, train_loss: 0.01750, valid_loss: 0.00796\n",
      "Epoch 20/30, train_loss: 0.01707, valid_loss: 0.00778\n",
      "Epoch 21/30, train_loss: 0.01666, valid_loss: 0.00762\n",
      "Epoch 22/30, train_loss: 0.01629, valid_loss: 0.00747\n",
      "Epoch 23/30, train_loss: 0.01594, valid_loss: 0.00733\n",
      "Epoch 24/30, train_loss: 0.01562, valid_loss: 0.00720\n",
      "Epoch 25/30, train_loss: 0.01531, valid_loss: 0.00707\n",
      "Epoch 26/30, train_loss: 0.01502, valid_loss: 0.00696\n",
      "Epoch 27/30, train_loss: 0.01475, valid_loss: 0.00685\n",
      "Epoch 28/30, train_loss: 0.01449, valid_loss: 0.00675\n",
      "Epoch 29/30, train_loss: 0.01425, valid_loss: 0.00665\n",
      "Epoch 30/30, train_loss: 0.01402, valid_loss: 0.00656\n",
      "At step 14\n",
      "Epoch 1/30, train_loss: 0.05361, valid_loss: 0.00761\n",
      "Epoch 2/30, train_loss: 0.03997, valid_loss: 0.00708\n",
      "Epoch 3/30, train_loss: 0.03297, valid_loss: 0.00692\n",
      "Epoch 4/30, train_loss: 0.02865, valid_loss: 0.00641\n",
      "Epoch 5/30, train_loss: 0.02568, valid_loss: 0.00588\n",
      "Epoch 6/30, train_loss: 0.02348, valid_loss: 0.00549\n",
      "Epoch 7/30, train_loss: 0.02177, valid_loss: 0.00521\n",
      "Epoch 8/30, train_loss: 0.02040, valid_loss: 0.00497\n",
      "Epoch 9/30, train_loss: 0.01926, valid_loss: 0.00478\n",
      "Epoch 10/30, train_loss: 0.01830, valid_loss: 0.00463\n",
      "Epoch 11/30, train_loss: 0.01747, valid_loss: 0.00449\n",
      "Epoch 12/30, train_loss: 0.01675, valid_loss: 0.00438\n",
      "Epoch 13/30, train_loss: 0.01612, valid_loss: 0.00428\n",
      "Epoch 14/30, train_loss: 0.01556, valid_loss: 0.00420\n",
      "Epoch 15/30, train_loss: 0.01505, valid_loss: 0.00413\n",
      "Epoch 16/30, train_loss: 0.01460, valid_loss: 0.00406\n",
      "Epoch 17/30, train_loss: 0.01418, valid_loss: 0.00400\n",
      "Epoch 18/30, train_loss: 0.01380, valid_loss: 0.00394\n",
      "Epoch 19/30, train_loss: 0.01345, valid_loss: 0.00389\n",
      "Epoch 20/30, train_loss: 0.01313, valid_loss: 0.00385\n",
      "Epoch 21/30, train_loss: 0.01283, valid_loss: 0.00380\n",
      "Epoch 22/30, train_loss: 0.01255, valid_loss: 0.00377\n",
      "Epoch 23/30, train_loss: 0.01230, valid_loss: 0.00373\n",
      "Epoch 24/30, train_loss: 0.01205, valid_loss: 0.00370\n",
      "Epoch 25/30, train_loss: 0.01183, valid_loss: 0.00366\n",
      "Epoch 26/30, train_loss: 0.01162, valid_loss: 0.00364\n",
      "Epoch 27/30, train_loss: 0.01141, valid_loss: 0.00364\n",
      "Epoch 28/30, train_loss: 0.01123, valid_loss: 0.00362\n",
      "Epoch 29/30, train_loss: 0.01105, valid_loss: 0.00360\n",
      "Epoch 30/30, train_loss: 0.01087, valid_loss: 0.00358\n",
      "At step 13\n",
      "Epoch 1/30, train_loss: 0.03387, valid_loss: 0.02366\n",
      "Epoch 2/30, train_loss: 0.02567, valid_loss: 0.01756\n",
      "Epoch 3/30, train_loss: 0.02123, valid_loss: 0.01454\n",
      "Epoch 4/30, train_loss: 0.01853, valid_loss: 0.01270\n",
      "Epoch 5/30, train_loss: 0.01666, valid_loss: 0.01146\n",
      "Epoch 6/30, train_loss: 0.01529, valid_loss: 0.01055\n",
      "Epoch 7/30, train_loss: 0.01423, valid_loss: 0.00989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, train_loss: 0.01338, valid_loss: 0.00932\n",
      "Epoch 9/30, train_loss: 0.01268, valid_loss: 0.00886\n",
      "Epoch 10/30, train_loss: 0.01209, valid_loss: 0.00848\n",
      "Epoch 11/30, train_loss: 0.01158, valid_loss: 0.00816\n",
      "Epoch 12/30, train_loss: 0.01114, valid_loss: 0.00787\n",
      "Epoch 13/30, train_loss: 0.01076, valid_loss: 0.00762\n",
      "Epoch 14/30, train_loss: 0.01041, valid_loss: 0.00741\n",
      "Epoch 15/30, train_loss: 0.01011, valid_loss: 0.00721\n",
      "Epoch 16/30, train_loss: 0.00983, valid_loss: 0.00705\n",
      "Epoch 17/30, train_loss: 0.00958, valid_loss: 0.00691\n",
      "Epoch 18/30, train_loss: 0.00936, valid_loss: 0.00677\n",
      "Epoch 19/30, train_loss: 0.00915, valid_loss: 0.00663\n",
      "Epoch 20/30, train_loss: 0.00896, valid_loss: 0.00651\n",
      "Epoch 21/30, train_loss: 0.00878, valid_loss: 0.00640\n",
      "Epoch 22/30, train_loss: 0.00862, valid_loss: 0.00630\n",
      "Epoch 23/30, train_loss: 0.00847, valid_loss: 0.00620\n",
      "Epoch 24/30, train_loss: 0.00833, valid_loss: 0.00610\n",
      "Epoch 25/30, train_loss: 0.00819, valid_loss: 0.00603\n",
      "Epoch 26/30, train_loss: 0.00807, valid_loss: 0.00595\n",
      "Epoch 27/30, train_loss: 0.00796, valid_loss: 0.00587\n",
      "Epoch 28/30, train_loss: 0.00784, valid_loss: 0.00580\n",
      "Epoch 29/30, train_loss: 0.00773, valid_loss: 0.00574\n",
      "Epoch 30/30, train_loss: 0.00763, valid_loss: 0.00568\n",
      "At step 12\n",
      "Epoch 1/30, train_loss: 0.05527, valid_loss: 0.01882\n",
      "Epoch 2/30, train_loss: 0.04133, valid_loss: 0.01578\n",
      "Epoch 3/30, train_loss: 0.03413, valid_loss: 0.01352\n",
      "Epoch 4/30, train_loss: 0.02965, valid_loss: 0.01188\n",
      "Epoch 5/30, train_loss: 0.02659, valid_loss: 0.01075\n",
      "Epoch 6/30, train_loss: 0.02432, valid_loss: 0.00994\n",
      "Epoch 7/30, train_loss: 0.02257, valid_loss: 0.00932\n",
      "Epoch 8/30, train_loss: 0.02116, valid_loss: 0.00881\n",
      "Epoch 9/30, train_loss: 0.01999, valid_loss: 0.00841\n",
      "Epoch 10/30, train_loss: 0.01901, valid_loss: 0.00806\n",
      "Epoch 11/30, train_loss: 0.01816, valid_loss: 0.00777\n",
      "Epoch 12/30, train_loss: 0.01742, valid_loss: 0.00753\n",
      "Epoch 13/30, train_loss: 0.01678, valid_loss: 0.00730\n",
      "Epoch 14/30, train_loss: 0.01620, valid_loss: 0.00711\n",
      "Epoch 15/30, train_loss: 0.01568, valid_loss: 0.00694\n",
      "Epoch 16/30, train_loss: 0.01522, valid_loss: 0.00679\n",
      "Epoch 17/30, train_loss: 0.01479, valid_loss: 0.00665\n",
      "Epoch 18/30, train_loss: 0.01441, valid_loss: 0.00653\n",
      "Epoch 19/30, train_loss: 0.01405, valid_loss: 0.00642\n",
      "Epoch 20/30, train_loss: 0.01372, valid_loss: 0.00632\n",
      "Epoch 21/30, train_loss: 0.01342, valid_loss: 0.00622\n",
      "Epoch 22/30, train_loss: 0.01314, valid_loss: 0.00612\n",
      "Epoch 23/30, train_loss: 0.01287, valid_loss: 0.00604\n",
      "Epoch 24/30, train_loss: 0.01263, valid_loss: 0.00596\n",
      "Epoch 25/30, train_loss: 0.01240, valid_loss: 0.00589\n",
      "Epoch 26/30, train_loss: 0.01218, valid_loss: 0.00581\n",
      "Epoch 27/30, train_loss: 0.01197, valid_loss: 0.00575\n",
      "Epoch 28/30, train_loss: 0.01178, valid_loss: 0.00569\n",
      "Epoch 29/30, train_loss: 0.01160, valid_loss: 0.00563\n",
      "Epoch 30/30, train_loss: 0.01142, valid_loss: 0.00557\n",
      "At step 11\n",
      "Epoch 1/30, train_loss: 0.01926, valid_loss: 0.00825\n",
      "Epoch 2/30, train_loss: 0.01483, valid_loss: 0.00715\n",
      "Epoch 3/30, train_loss: 0.01250, valid_loss: 0.00648\n",
      "Epoch 4/30, train_loss: 0.01110, valid_loss: 0.00610\n",
      "Epoch 5/30, train_loss: 0.01020, valid_loss: 0.00586\n",
      "Epoch 6/30, train_loss: 0.00957, valid_loss: 0.00566\n",
      "Epoch 7/30, train_loss: 0.00908, valid_loss: 0.00551\n",
      "Epoch 8/30, train_loss: 0.00866, valid_loss: 0.00540\n",
      "Epoch 9/30, train_loss: 0.00835, valid_loss: 0.00541\n",
      "Epoch 10/30, train_loss: 0.00806, valid_loss: 0.00533\n",
      "Epoch 11/30, train_loss: 0.00783, valid_loss: 0.00525\n",
      "Epoch 12/30, train_loss: 0.00762, valid_loss: 0.00518\n",
      "Epoch 13/30, train_loss: 0.00743, valid_loss: 0.00512\n",
      "Epoch 14/30, train_loss: 0.00727, valid_loss: 0.00517\n",
      "Epoch 15/30, train_loss: 0.00715, valid_loss: 0.00512\n",
      "Epoch 16/30, train_loss: 0.00702, valid_loss: 0.00517\n",
      "Epoch 17/30, train_loss: 0.00693, valid_loss: 0.00512\n",
      "Epoch 18/30, train_loss: 0.00682, valid_loss: 0.00507\n",
      "Epoch 19/30, train_loss: 0.00672, valid_loss: 0.00503\n",
      "Epoch 20/30, train_loss: 0.00663, valid_loss: 0.00499\n",
      "Epoch 21/30, train_loss: 0.00656, valid_loss: 0.00506\n",
      "Epoch 22/30, train_loss: 0.00651, valid_loss: 0.00502\n",
      "Epoch 23/30, train_loss: 0.00644, valid_loss: 0.00509\n",
      "Epoch 24/30, train_loss: 0.00641, valid_loss: 0.00506\n",
      "Epoch 25/30, train_loss: 0.00634, valid_loss: 0.00503\n",
      "Epoch 26/30, train_loss: 0.00627, valid_loss: 0.00499\n",
      "Epoch 27/30, train_loss: 0.00621, valid_loss: 0.00497\n",
      "Epoch 28/30, train_loss: 0.00616, valid_loss: 0.00504\n",
      "Epoch 29/30, train_loss: 0.00613, valid_loss: 0.00503\n",
      "Epoch 30/30, train_loss: 0.00609, valid_loss: 0.00499\n",
      "At step 10\n",
      "Epoch 1/30, train_loss: 0.04176, valid_loss: 0.01537\n",
      "Epoch 2/30, train_loss: 0.03061, valid_loss: 0.01285\n",
      "Epoch 3/30, train_loss: 0.02526, valid_loss: 0.01109\n",
      "Epoch 4/30, train_loss: 0.02202, valid_loss: 0.00995\n",
      "Epoch 5/30, train_loss: 0.01980, valid_loss: 0.00919\n",
      "Epoch 6/30, train_loss: 0.01818, valid_loss: 0.00865\n",
      "Epoch 7/30, train_loss: 0.01691, valid_loss: 0.00824\n",
      "Epoch 8/30, train_loss: 0.01590, valid_loss: 0.00792\n",
      "Epoch 9/30, train_loss: 0.01507, valid_loss: 0.00766\n",
      "Epoch 10/30, train_loss: 0.01437, valid_loss: 0.00744\n",
      "Epoch 11/30, train_loss: 0.01377, valid_loss: 0.00727\n",
      "Epoch 12/30, train_loss: 0.01325, valid_loss: 0.00711\n",
      "Epoch 13/30, train_loss: 0.01279, valid_loss: 0.00698\n",
      "Epoch 14/30, train_loss: 0.01239, valid_loss: 0.00687\n",
      "Epoch 15/30, train_loss: 0.01203, valid_loss: 0.00677\n",
      "Epoch 16/30, train_loss: 0.01170, valid_loss: 0.00667\n",
      "Epoch 17/30, train_loss: 0.01141, valid_loss: 0.00659\n",
      "Epoch 18/30, train_loss: 0.01114, valid_loss: 0.00652\n",
      "Epoch 19/30, train_loss: 0.01089, valid_loss: 0.00645\n",
      "Epoch 20/30, train_loss: 0.01066, valid_loss: 0.00639\n",
      "Epoch 21/30, train_loss: 0.01045, valid_loss: 0.00633\n",
      "Epoch 22/30, train_loss: 0.01025, valid_loss: 0.00627\n",
      "Epoch 23/30, train_loss: 0.01007, valid_loss: 0.00622\n",
      "Epoch 24/30, train_loss: 0.00990, valid_loss: 0.00618\n",
      "Epoch 25/30, train_loss: 0.00974, valid_loss: 0.00613\n",
      "Epoch 26/30, train_loss: 0.00959, valid_loss: 0.00610\n",
      "Epoch 27/30, train_loss: 0.00945, valid_loss: 0.00606\n",
      "Epoch 28/30, train_loss: 0.00932, valid_loss: 0.00602\n",
      "Epoch 29/30, train_loss: 0.00920, valid_loss: 0.00599\n",
      "Epoch 30/30, train_loss: 0.00908, valid_loss: 0.00595\n",
      "At step 9\n",
      "Epoch 1/30, train_loss: 0.01413, valid_loss: 0.01097\n",
      "Epoch 2/30, train_loss: 0.01111, valid_loss: 0.00883\n",
      "Epoch 3/30, train_loss: 0.00957, valid_loss: 0.00797\n",
      "Epoch 4/30, train_loss: 0.00869, valid_loss: 0.00740\n",
      "Epoch 5/30, train_loss: 0.00810, valid_loss: 0.00704\n",
      "Epoch 6/30, train_loss: 0.00769, valid_loss: 0.00686\n",
      "Epoch 7/30, train_loss: 0.00737, valid_loss: 0.00668\n",
      "Epoch 8/30, train_loss: 0.00711, valid_loss: 0.00652\n",
      "Epoch 9/30, train_loss: 0.00692, valid_loss: 0.00644\n",
      "Epoch 10/30, train_loss: 0.00676, valid_loss: 0.00634\n",
      "Epoch 11/30, train_loss: 0.00665, valid_loss: 0.00631\n",
      "Epoch 12/30, train_loss: 0.00656, valid_loss: 0.00622\n",
      "Epoch 13/30, train_loss: 0.00646, valid_loss: 0.00623\n",
      "Epoch 14/30, train_loss: 0.00637, valid_loss: 0.00628\n",
      "Epoch 15/30, train_loss: 0.00631, valid_loss: 0.00618\n",
      "Epoch 16/30, train_loss: 0.00622, valid_loss: 0.00624\n",
      "Epoch 17/30, train_loss: 0.00616, valid_loss: 0.00618\n",
      "Epoch 18/30, train_loss: 0.00607, valid_loss: 0.00610\n",
      "Epoch 19/30, train_loss: 0.00600, valid_loss: 0.00607\n",
      "Epoch 20/30, train_loss: 0.00595, valid_loss: 0.00607\n",
      "Epoch 21/30, train_loss: 0.00593, valid_loss: 0.00601\n",
      "Epoch 22/30, train_loss: 0.00587, valid_loss: 0.00598\n",
      "Epoch 23/30, train_loss: 0.00581, valid_loss: 0.00592\n",
      "Epoch 24/30, train_loss: 0.00576, valid_loss: 0.00588\n",
      "Epoch 25/30, train_loss: 0.00570, valid_loss: 0.00582\n",
      "Epoch 26/30, train_loss: 0.00564, valid_loss: 0.00576\n",
      "Epoch 27/30, train_loss: 0.00558, valid_loss: 0.00575\n",
      "Epoch 28/30, train_loss: 0.00554, valid_loss: 0.00569\n",
      "Epoch 29/30, train_loss: 0.00548, valid_loss: 0.00565\n",
      "Epoch 30/30, train_loss: 0.00542, valid_loss: 0.00564\n",
      "At step 8\n",
      "Epoch 1/30, train_loss: 0.02111, valid_loss: 0.01544\n",
      "Epoch 2/30, train_loss: 0.01618, valid_loss: 0.01155\n",
      "Epoch 3/30, train_loss: 0.01364, valid_loss: 0.00989\n",
      "Epoch 4/30, train_loss: 0.01215, valid_loss: 0.00891\n",
      "Epoch 5/30, train_loss: 0.01114, valid_loss: 0.00825\n",
      "Epoch 6/30, train_loss: 0.01041, valid_loss: 0.00781\n",
      "Epoch 7/30, train_loss: 0.00988, valid_loss: 0.00745\n",
      "Epoch 8/30, train_loss: 0.00944, valid_loss: 0.00715\n",
      "Epoch 9/30, train_loss: 0.00909, valid_loss: 0.00691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, train_loss: 0.00878, valid_loss: 0.00672\n",
      "Epoch 11/30, train_loss: 0.00852, valid_loss: 0.00655\n",
      "Epoch 12/30, train_loss: 0.00830, valid_loss: 0.00641\n",
      "Epoch 13/30, train_loss: 0.00811, valid_loss: 0.00630\n",
      "Epoch 14/30, train_loss: 0.00794, valid_loss: 0.00620\n",
      "Epoch 15/30, train_loss: 0.00780, valid_loss: 0.00616\n",
      "Epoch 16/30, train_loss: 0.00768, valid_loss: 0.00609\n",
      "Epoch 17/30, train_loss: 0.00755, valid_loss: 0.00601\n",
      "Epoch 18/30, train_loss: 0.00744, valid_loss: 0.00591\n",
      "Epoch 19/30, train_loss: 0.00733, valid_loss: 0.00583\n",
      "Epoch 20/30, train_loss: 0.00722, valid_loss: 0.00576\n",
      "Epoch 21/30, train_loss: 0.00712, valid_loss: 0.00568\n",
      "Epoch 22/30, train_loss: 0.00702, valid_loss: 0.00563\n",
      "Epoch 23/30, train_loss: 0.00693, valid_loss: 0.00556\n",
      "Epoch 24/30, train_loss: 0.00685, valid_loss: 0.00549\n",
      "Epoch 25/30, train_loss: 0.00677, valid_loss: 0.00543\n",
      "Epoch 26/30, train_loss: 0.00668, valid_loss: 0.00538\n",
      "Epoch 27/30, train_loss: 0.00661, valid_loss: 0.00532\n",
      "Epoch 28/30, train_loss: 0.00654, valid_loss: 0.00526\n",
      "Epoch 29/30, train_loss: 0.00646, valid_loss: 0.00524\n",
      "Epoch 30/30, train_loss: 0.00641, valid_loss: 0.00518\n",
      "At step 7\n",
      "Epoch 1/30, train_loss: 0.03503, valid_loss: 0.01407\n",
      "Epoch 2/30, train_loss: 0.02547, valid_loss: 0.01101\n",
      "Epoch 3/30, train_loss: 0.02112, valid_loss: 0.00959\n",
      "Epoch 4/30, train_loss: 0.01853, valid_loss: 0.00877\n",
      "Epoch 5/30, train_loss: 0.01679, valid_loss: 0.00827\n",
      "Epoch 6/30, train_loss: 0.01553, valid_loss: 0.00791\n",
      "Epoch 7/30, train_loss: 0.01456, valid_loss: 0.00762\n",
      "Epoch 8/30, train_loss: 0.01378, valid_loss: 0.00740\n",
      "Epoch 9/30, train_loss: 0.01314, valid_loss: 0.00722\n",
      "Epoch 10/30, train_loss: 0.01260, valid_loss: 0.00707\n",
      "Epoch 11/30, train_loss: 0.01215, valid_loss: 0.00697\n",
      "Epoch 12/30, train_loss: 0.01176, valid_loss: 0.00687\n",
      "Epoch 13/30, train_loss: 0.01142, valid_loss: 0.00678\n",
      "Epoch 14/30, train_loss: 0.01111, valid_loss: 0.00669\n",
      "Epoch 15/30, train_loss: 0.01084, valid_loss: 0.00661\n",
      "Epoch 16/30, train_loss: 0.01059, valid_loss: 0.00654\n",
      "Epoch 17/30, train_loss: 0.01037, valid_loss: 0.00647\n",
      "Epoch 18/30, train_loss: 0.01017, valid_loss: 0.00642\n",
      "Epoch 19/30, train_loss: 0.00999, valid_loss: 0.00636\n",
      "Epoch 20/30, train_loss: 0.00982, valid_loss: 0.00633\n",
      "Epoch 21/30, train_loss: 0.00967, valid_loss: 0.00628\n",
      "Epoch 22/30, train_loss: 0.00952, valid_loss: 0.00624\n",
      "Epoch 23/30, train_loss: 0.00938, valid_loss: 0.00621\n",
      "Epoch 24/30, train_loss: 0.00926, valid_loss: 0.00618\n",
      "Epoch 25/30, train_loss: 0.00914, valid_loss: 0.00616\n",
      "Epoch 26/30, train_loss: 0.00902, valid_loss: 0.00613\n",
      "Epoch 27/30, train_loss: 0.00892, valid_loss: 0.00612\n",
      "Epoch 28/30, train_loss: 0.00882, valid_loss: 0.00608\n",
      "Epoch 29/30, train_loss: 0.00872, valid_loss: 0.00604\n",
      "Epoch 30/30, train_loss: 0.00863, valid_loss: 0.00600\n",
      "At step 6\n",
      "Epoch 1/30, train_loss: 0.02415, valid_loss: 0.00991\n",
      "Epoch 2/30, train_loss: 0.01793, valid_loss: 0.00847\n",
      "Epoch 3/30, train_loss: 0.01510, valid_loss: 0.00790\n",
      "Epoch 4/30, train_loss: 0.01346, valid_loss: 0.00760\n",
      "Epoch 5/30, train_loss: 0.01237, valid_loss: 0.00740\n",
      "Epoch 6/30, train_loss: 0.01158, valid_loss: 0.00727\n",
      "Epoch 7/30, train_loss: 0.01098, valid_loss: 0.00718\n",
      "Epoch 8/30, train_loss: 0.01052, valid_loss: 0.00710\n",
      "Epoch 9/30, train_loss: 0.01013, valid_loss: 0.00703\n",
      "Epoch 10/30, train_loss: 0.00981, valid_loss: 0.00697\n",
      "Epoch 11/30, train_loss: 0.00954, valid_loss: 0.00692\n",
      "Epoch 12/30, train_loss: 0.00930, valid_loss: 0.00688\n",
      "Epoch 13/30, train_loss: 0.00910, valid_loss: 0.00685\n",
      "Epoch 14/30, train_loss: 0.00892, valid_loss: 0.00683\n",
      "Epoch 15/30, train_loss: 0.00876, valid_loss: 0.00679\n",
      "Epoch 16/30, train_loss: 0.00863, valid_loss: 0.00677\n",
      "Epoch 17/30, train_loss: 0.00850, valid_loss: 0.00673\n",
      "Epoch 18/30, train_loss: 0.00838, valid_loss: 0.00669\n",
      "Epoch 19/30, train_loss: 0.00826, valid_loss: 0.00667\n",
      "Epoch 20/30, train_loss: 0.00816, valid_loss: 0.00663\n",
      "Epoch 21/30, train_loss: 0.00807, valid_loss: 0.00660\n",
      "Epoch 22/30, train_loss: 0.00799, valid_loss: 0.00658\n",
      "Epoch 23/30, train_loss: 0.00790, valid_loss: 0.00654\n",
      "Epoch 24/30, train_loss: 0.00782, valid_loss: 0.00651\n",
      "Epoch 25/30, train_loss: 0.00774, valid_loss: 0.00647\n",
      "Epoch 26/30, train_loss: 0.00767, valid_loss: 0.00645\n",
      "Epoch 27/30, train_loss: 0.00759, valid_loss: 0.00641\n",
      "Epoch 28/30, train_loss: 0.00752, valid_loss: 0.00638\n",
      "Epoch 29/30, train_loss: 0.00745, valid_loss: 0.00635\n",
      "Epoch 30/30, train_loss: 0.00739, valid_loss: 0.00632\n",
      "At step 5\n",
      "Epoch 1/30, train_loss: 0.04237, valid_loss: 0.01168\n",
      "Epoch 2/30, train_loss: 0.03055, valid_loss: 0.00962\n",
      "Epoch 3/30, train_loss: 0.02519, valid_loss: 0.00868\n",
      "Epoch 4/30, train_loss: 0.02203, valid_loss: 0.00819\n",
      "Epoch 5/30, train_loss: 0.01988, valid_loss: 0.00793\n",
      "Epoch 6/30, train_loss: 0.01835, valid_loss: 0.00768\n",
      "Epoch 7/30, train_loss: 0.01717, valid_loss: 0.00751\n",
      "Epoch 8/30, train_loss: 0.01619, valid_loss: 0.00737\n",
      "Epoch 9/30, train_loss: 0.01539, valid_loss: 0.00729\n",
      "Epoch 10/30, train_loss: 0.01472, valid_loss: 0.00718\n",
      "Epoch 11/30, train_loss: 0.01414, valid_loss: 0.00713\n",
      "Epoch 12/30, train_loss: 0.01365, valid_loss: 0.00708\n",
      "Epoch 13/30, train_loss: 0.01322, valid_loss: 0.00701\n",
      "Epoch 14/30, train_loss: 0.01283, valid_loss: 0.00696\n",
      "Epoch 15/30, train_loss: 0.01249, valid_loss: 0.00697\n",
      "Epoch 16/30, train_loss: 0.01219, valid_loss: 0.00692\n",
      "Epoch 17/30, train_loss: 0.01192, valid_loss: 0.00690\n",
      "Epoch 18/30, train_loss: 0.01168, valid_loss: 0.00686\n",
      "Epoch 19/30, train_loss: 0.01144, valid_loss: 0.00681\n",
      "Epoch 20/30, train_loss: 0.01122, valid_loss: 0.00679\n",
      "Epoch 21/30, train_loss: 0.01103, valid_loss: 0.00678\n",
      "Epoch 22/30, train_loss: 0.01085, valid_loss: 0.00676\n",
      "Epoch 23/30, train_loss: 0.01070, valid_loss: 0.00687\n",
      "Epoch 24/30, train_loss: 0.01059, valid_loss: 0.00684\n",
      "Epoch 25/30, train_loss: 0.01044, valid_loss: 0.00690\n",
      "Epoch 26/30, train_loss: 0.01032, valid_loss: 0.00685\n",
      "Epoch 27/30, train_loss: 0.01018, valid_loss: 0.00681\n",
      "Epoch 28/30, train_loss: 0.01005, valid_loss: 0.00679\n",
      "Epoch 29/30, train_loss: 0.00993, valid_loss: 0.00676\n",
      "Epoch 30/30, train_loss: 0.00981, valid_loss: 0.00672\n",
      "At step 4\n",
      "Epoch 1/30, train_loss: 0.01298, valid_loss: 0.00619\n",
      "Epoch 2/30, train_loss: 0.01028, valid_loss: 0.00616\n",
      "Epoch 3/30, train_loss: 0.00915, valid_loss: 0.00639\n",
      "Epoch 4/30, train_loss: 0.00852, valid_loss: 0.00629\n",
      "Epoch 5/30, train_loss: 0.00810, valid_loss: 0.00621\n",
      "Epoch 6/30, train_loss: 0.00784, valid_loss: 0.00615\n",
      "Epoch 7/30, train_loss: 0.00762, valid_loss: 0.00621\n",
      "Epoch 8/30, train_loss: 0.00744, valid_loss: 0.00614\n",
      "Epoch 9/30, train_loss: 0.00727, valid_loss: 0.00606\n",
      "Epoch 10/30, train_loss: 0.00711, valid_loss: 0.00600\n",
      "Epoch 11/30, train_loss: 0.00700, valid_loss: 0.00607\n",
      "Epoch 12/30, train_loss: 0.00688, valid_loss: 0.00600\n",
      "Epoch 13/30, train_loss: 0.00675, valid_loss: 0.00591\n",
      "Epoch 14/30, train_loss: 0.00664, valid_loss: 0.00583\n",
      "Epoch 15/30, train_loss: 0.00652, valid_loss: 0.00575\n",
      "Epoch 16/30, train_loss: 0.00641, valid_loss: 0.00566\n",
      "Epoch 17/30, train_loss: 0.00631, valid_loss: 0.00557\n",
      "Epoch 18/30, train_loss: 0.00621, valid_loss: 0.00549\n",
      "Epoch 19/30, train_loss: 0.00611, valid_loss: 0.00546\n",
      "Epoch 20/30, train_loss: 0.00600, valid_loss: 0.00536\n",
      "Epoch 21/30, train_loss: 0.00589, valid_loss: 0.00527\n",
      "Epoch 22/30, train_loss: 0.00578, valid_loss: 0.00517\n",
      "Epoch 23/30, train_loss: 0.00568, valid_loss: 0.00508\n",
      "Epoch 24/30, train_loss: 0.00558, valid_loss: 0.00500\n",
      "Epoch 25/30, train_loss: 0.00548, valid_loss: 0.00491\n",
      "Epoch 26/30, train_loss: 0.00539, valid_loss: 0.00483\n",
      "Epoch 27/30, train_loss: 0.00530, valid_loss: 0.00476\n",
      "Epoch 28/30, train_loss: 0.00522, valid_loss: 0.00477\n",
      "Epoch 29/30, train_loss: 0.00515, valid_loss: 0.00470\n",
      "Epoch 30/30, train_loss: 0.00507, valid_loss: 0.00463\n",
      "At step 3\n",
      "Epoch 1/30, train_loss: 0.01383, valid_loss: 0.00718\n",
      "Epoch 2/30, train_loss: 0.01072, valid_loss: 0.00679\n",
      "Epoch 3/30, train_loss: 0.00945, valid_loss: 0.00665\n",
      "Epoch 4/30, train_loss: 0.00875, valid_loss: 0.00660\n",
      "Epoch 5/30, train_loss: 0.00827, valid_loss: 0.00654\n",
      "Epoch 6/30, train_loss: 0.00794, valid_loss: 0.00660\n",
      "Epoch 7/30, train_loss: 0.00767, valid_loss: 0.00652\n",
      "Epoch 8/30, train_loss: 0.00747, valid_loss: 0.00648\n",
      "Epoch 9/30, train_loss: 0.00732, valid_loss: 0.00641\n",
      "Epoch 10/30, train_loss: 0.00715, valid_loss: 0.00634\n",
      "Epoch 11/30, train_loss: 0.00700, valid_loss: 0.00634\n",
      "Epoch 12/30, train_loss: 0.00688, valid_loss: 0.00626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, train_loss: 0.00675, valid_loss: 0.00618\n",
      "Epoch 14/30, train_loss: 0.00665, valid_loss: 0.00609\n",
      "Epoch 15/30, train_loss: 0.00652, valid_loss: 0.00605\n",
      "Epoch 16/30, train_loss: 0.00642, valid_loss: 0.00600\n",
      "Epoch 17/30, train_loss: 0.00634, valid_loss: 0.00593\n",
      "Epoch 18/30, train_loss: 0.00624, valid_loss: 0.00583\n",
      "Epoch 19/30, train_loss: 0.00614, valid_loss: 0.00576\n",
      "Epoch 20/30, train_loss: 0.00604, valid_loss: 0.00566\n",
      "Epoch 21/30, train_loss: 0.00593, valid_loss: 0.00561\n",
      "Epoch 22/30, train_loss: 0.00584, valid_loss: 0.00554\n",
      "Epoch 23/30, train_loss: 0.00574, valid_loss: 0.00544\n",
      "Epoch 24/30, train_loss: 0.00564, valid_loss: 0.00534\n",
      "Epoch 25/30, train_loss: 0.00555, valid_loss: 0.00526\n",
      "Epoch 26/30, train_loss: 0.00546, valid_loss: 0.00517\n",
      "Epoch 27/30, train_loss: 0.00538, valid_loss: 0.00509\n",
      "Epoch 28/30, train_loss: 0.00530, valid_loss: 0.00502\n",
      "Epoch 29/30, train_loss: 0.00522, valid_loss: 0.00495\n",
      "Epoch 30/30, train_loss: 0.00515, valid_loss: 0.00488\n",
      "At step 2\n",
      "Epoch 1/30, train_loss: 0.01671, valid_loss: 0.00643\n",
      "Epoch 2/30, train_loss: 0.01265, valid_loss: 0.00655\n",
      "Epoch 3/30, train_loss: 0.01094, valid_loss: 0.00653\n",
      "Epoch 4/30, train_loss: 0.00997, valid_loss: 0.00647\n",
      "Epoch 5/30, train_loss: 0.00933, valid_loss: 0.00648\n",
      "Epoch 6/30, train_loss: 0.00888, valid_loss: 0.00640\n",
      "Epoch 7/30, train_loss: 0.00852, valid_loss: 0.00636\n",
      "Epoch 8/30, train_loss: 0.00825, valid_loss: 0.00628\n",
      "Epoch 9/30, train_loss: 0.00800, valid_loss: 0.00619\n",
      "Epoch 10/30, train_loss: 0.00781, valid_loss: 0.00613\n",
      "Epoch 11/30, train_loss: 0.00762, valid_loss: 0.00619\n",
      "Epoch 12/30, train_loss: 0.00745, valid_loss: 0.00612\n",
      "Epoch 13/30, train_loss: 0.00728, valid_loss: 0.00600\n",
      "Epoch 14/30, train_loss: 0.00711, valid_loss: 0.00590\n",
      "Epoch 15/30, train_loss: 0.00694, valid_loss: 0.00577\n",
      "Epoch 16/30, train_loss: 0.00677, valid_loss: 0.00571\n",
      "Epoch 17/30, train_loss: 0.00663, valid_loss: 0.00557\n",
      "Epoch 18/30, train_loss: 0.00648, valid_loss: 0.00549\n",
      "Epoch 19/30, train_loss: 0.00633, valid_loss: 0.00539\n",
      "Epoch 20/30, train_loss: 0.00620, valid_loss: 0.00527\n",
      "Epoch 21/30, train_loss: 0.00608, valid_loss: 0.00515\n",
      "Epoch 22/30, train_loss: 0.00595, valid_loss: 0.00504\n",
      "Epoch 23/30, train_loss: 0.00584, valid_loss: 0.00498\n",
      "Epoch 24/30, train_loss: 0.00573, valid_loss: 0.00489\n",
      "Epoch 25/30, train_loss: 0.00562, valid_loss: 0.00480\n",
      "Epoch 26/30, train_loss: 0.00553, valid_loss: 0.00472\n",
      "Epoch 27/30, train_loss: 0.00544, valid_loss: 0.00464\n",
      "Epoch 28/30, train_loss: 0.00535, valid_loss: 0.00456\n",
      "Epoch 29/30, train_loss: 0.00526, valid_loss: 0.00450\n",
      "Epoch 30/30, train_loss: 0.00519, valid_loss: 0.00443\n",
      "At step 18\n",
      "Epoch 1/30, train_loss: 0.01795, valid_loss: 0.00627\n",
      "Epoch 2/30, train_loss: 0.01282, valid_loss: 0.00450\n",
      "Epoch 3/30, train_loss: 0.01048, valid_loss: 0.00369\n",
      "Epoch 4/30, train_loss: 0.00908, valid_loss: 0.00322\n",
      "Epoch 5/30, train_loss: 0.00813, valid_loss: 0.00289\n",
      "Epoch 6/30, train_loss: 0.00743, valid_loss: 0.00266\n",
      "Epoch 7/30, train_loss: 0.00688, valid_loss: 0.00248\n",
      "Epoch 8/30, train_loss: 0.00644, valid_loss: 0.00233\n",
      "Epoch 9/30, train_loss: 0.00608, valid_loss: 0.00221\n",
      "Epoch 10/30, train_loss: 0.00577, valid_loss: 0.00211\n",
      "Epoch 11/30, train_loss: 0.00551, valid_loss: 0.00202\n",
      "Epoch 12/30, train_loss: 0.00528, valid_loss: 0.00194\n",
      "Epoch 13/30, train_loss: 0.00507, valid_loss: 0.00188\n",
      "Epoch 14/30, train_loss: 0.00489, valid_loss: 0.00182\n",
      "Epoch 15/30, train_loss: 0.00473, valid_loss: 0.00176\n",
      "Epoch 16/30, train_loss: 0.00458, valid_loss: 0.00172\n",
      "Epoch 17/30, train_loss: 0.00445, valid_loss: 0.00168\n",
      "Epoch 18/30, train_loss: 0.00433, valid_loss: 0.00164\n",
      "Epoch 19/30, train_loss: 0.00422, valid_loss: 0.00160\n",
      "Epoch 20/30, train_loss: 0.00411, valid_loss: 0.00157\n",
      "Epoch 21/30, train_loss: 0.00402, valid_loss: 0.00154\n",
      "Epoch 22/30, train_loss: 0.00393, valid_loss: 0.00151\n",
      "Epoch 23/30, train_loss: 0.00384, valid_loss: 0.00149\n",
      "Epoch 24/30, train_loss: 0.00377, valid_loss: 0.00147\n",
      "Epoch 25/30, train_loss: 0.00369, valid_loss: 0.00144\n",
      "Epoch 26/30, train_loss: 0.00362, valid_loss: 0.00142\n",
      "Epoch 27/30, train_loss: 0.00356, valid_loss: 0.00140\n",
      "Epoch 28/30, train_loss: 0.00350, valid_loss: 0.00138\n",
      "Epoch 29/30, train_loss: 0.00344, valid_loss: 0.00137\n",
      "Epoch 30/30, train_loss: 0.00338, valid_loss: 0.00135\n",
      "At step 17\n",
      "Epoch 1/30, train_loss: 0.01428, valid_loss: 0.00500\n",
      "Epoch 2/30, train_loss: 0.01025, valid_loss: 0.00370\n",
      "Epoch 3/30, train_loss: 0.00841, valid_loss: 0.00314\n",
      "Epoch 4/30, train_loss: 0.00731, valid_loss: 0.00282\n",
      "Epoch 5/30, train_loss: 0.00657, valid_loss: 0.00260\n",
      "Epoch 6/30, train_loss: 0.00603, valid_loss: 0.00246\n",
      "Epoch 7/30, train_loss: 0.00561, valid_loss: 0.00235\n",
      "Epoch 8/30, train_loss: 0.00527, valid_loss: 0.00226\n",
      "Epoch 9/30, train_loss: 0.00499, valid_loss: 0.00219\n",
      "Epoch 10/30, train_loss: 0.00475, valid_loss: 0.00213\n",
      "Epoch 11/30, train_loss: 0.00455, valid_loss: 0.00208\n",
      "Epoch 12/30, train_loss: 0.00438, valid_loss: 0.00204\n",
      "Epoch 13/30, train_loss: 0.00422, valid_loss: 0.00200\n",
      "Epoch 14/30, train_loss: 0.00409, valid_loss: 0.00197\n",
      "Epoch 15/30, train_loss: 0.00397, valid_loss: 0.00194\n",
      "Epoch 16/30, train_loss: 0.00386, valid_loss: 0.00192\n",
      "Epoch 17/30, train_loss: 0.00376, valid_loss: 0.00189\n",
      "Epoch 18/30, train_loss: 0.00367, valid_loss: 0.00187\n",
      "Epoch 19/30, train_loss: 0.00358, valid_loss: 0.00185\n",
      "Epoch 20/30, train_loss: 0.00351, valid_loss: 0.00183\n",
      "Epoch 21/30, train_loss: 0.00343, valid_loss: 0.00183\n",
      "Epoch 22/30, train_loss: 0.00337, valid_loss: 0.00181\n",
      "Epoch 23/30, train_loss: 0.00331, valid_loss: 0.00179\n",
      "Epoch 24/30, train_loss: 0.00325, valid_loss: 0.00178\n",
      "Epoch 25/30, train_loss: 0.00320, valid_loss: 0.00177\n",
      "Epoch 26/30, train_loss: 0.00315, valid_loss: 0.00176\n",
      "Epoch 27/30, train_loss: 0.00310, valid_loss: 0.00176\n",
      "Epoch 28/30, train_loss: 0.00306, valid_loss: 0.00179\n",
      "Epoch 29/30, train_loss: 0.00302, valid_loss: 0.00178\n",
      "Epoch 30/30, train_loss: 0.00298, valid_loss: 0.00177\n",
      "At step 16\n",
      "Epoch 1/30, train_loss: 0.02443, valid_loss: 0.00446\n",
      "Epoch 2/30, train_loss: 0.01749, valid_loss: 0.00354\n",
      "Epoch 3/30, train_loss: 0.01433, valid_loss: 0.00310\n",
      "Epoch 4/30, train_loss: 0.01244, valid_loss: 0.00286\n",
      "Epoch 5/30, train_loss: 0.01116, valid_loss: 0.00271\n",
      "Epoch 6/30, train_loss: 0.01022, valid_loss: 0.00260\n",
      "Epoch 7/30, train_loss: 0.00949, valid_loss: 0.00252\n",
      "Epoch 8/30, train_loss: 0.00890, valid_loss: 0.00246\n",
      "Epoch 9/30, train_loss: 0.00842, valid_loss: 0.00241\n",
      "Epoch 10/30, train_loss: 0.00801, valid_loss: 0.00237\n",
      "Epoch 11/30, train_loss: 0.00766, valid_loss: 0.00234\n",
      "Epoch 12/30, train_loss: 0.00735, valid_loss: 0.00232\n",
      "Epoch 13/30, train_loss: 0.00709, valid_loss: 0.00231\n",
      "Epoch 14/30, train_loss: 0.00685, valid_loss: 0.00229\n",
      "Epoch 15/30, train_loss: 0.00663, valid_loss: 0.00227\n",
      "Epoch 16/30, train_loss: 0.00644, valid_loss: 0.00224\n",
      "Epoch 17/30, train_loss: 0.00627, valid_loss: 0.00223\n",
      "Epoch 18/30, train_loss: 0.00611, valid_loss: 0.00222\n",
      "Epoch 19/30, train_loss: 0.00596, valid_loss: 0.00220\n",
      "Epoch 20/30, train_loss: 0.00582, valid_loss: 0.00219\n",
      "Epoch 21/30, train_loss: 0.00570, valid_loss: 0.00218\n",
      "Epoch 22/30, train_loss: 0.00558, valid_loss: 0.00217\n",
      "Epoch 23/30, train_loss: 0.00547, valid_loss: 0.00220\n",
      "Epoch 24/30, train_loss: 0.00537, valid_loss: 0.00218\n",
      "Epoch 25/30, train_loss: 0.00528, valid_loss: 0.00217\n",
      "Epoch 26/30, train_loss: 0.00519, valid_loss: 0.00216\n",
      "Epoch 27/30, train_loss: 0.00510, valid_loss: 0.00216\n",
      "Epoch 28/30, train_loss: 0.00503, valid_loss: 0.00215\n",
      "Epoch 29/30, train_loss: 0.00495, valid_loss: 0.00215\n",
      "Epoch 30/30, train_loss: 0.00488, valid_loss: 0.00214\n",
      "At step 15\n",
      "Epoch 1/30, train_loss: 0.05531, valid_loss: 0.02030\n",
      "Epoch 2/30, train_loss: 0.03962, valid_loss: 0.01460\n",
      "Epoch 3/30, train_loss: 0.03239, valid_loss: 0.01201\n",
      "Epoch 4/30, train_loss: 0.02808, valid_loss: 0.01048\n",
      "Epoch 5/30, train_loss: 0.02514, valid_loss: 0.00944\n",
      "Epoch 6/30, train_loss: 0.02297, valid_loss: 0.00868\n",
      "Epoch 7/30, train_loss: 0.02128, valid_loss: 0.00809\n",
      "Epoch 8/30, train_loss: 0.01993, valid_loss: 0.00762\n",
      "Epoch 9/30, train_loss: 0.01880, valid_loss: 0.00723\n",
      "Epoch 10/30, train_loss: 0.01786, valid_loss: 0.00691\n",
      "Epoch 11/30, train_loss: 0.01704, valid_loss: 0.00663\n",
      "Epoch 12/30, train_loss: 0.01633, valid_loss: 0.00639\n",
      "Epoch 13/30, train_loss: 0.01570, valid_loss: 0.00618\n",
      "Epoch 14/30, train_loss: 0.01514, valid_loss: 0.00599\n",
      "Epoch 15/30, train_loss: 0.01464, valid_loss: 0.00582\n",
      "Epoch 16/30, train_loss: 0.01419, valid_loss: 0.00567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, train_loss: 0.01378, valid_loss: 0.00554\n",
      "Epoch 18/30, train_loss: 0.01340, valid_loss: 0.00541\n",
      "Epoch 19/30, train_loss: 0.01306, valid_loss: 0.00530\n",
      "Epoch 20/30, train_loss: 0.01274, valid_loss: 0.00519\n",
      "Epoch 21/30, train_loss: 0.01244, valid_loss: 0.00509\n",
      "Epoch 22/30, train_loss: 0.01217, valid_loss: 0.00501\n",
      "Epoch 23/30, train_loss: 0.01191, valid_loss: 0.00492\n",
      "Epoch 24/30, train_loss: 0.01167, valid_loss: 0.00485\n",
      "Epoch 25/30, train_loss: 0.01144, valid_loss: 0.00477\n",
      "Epoch 26/30, train_loss: 0.01123, valid_loss: 0.00471\n",
      "Epoch 27/30, train_loss: 0.01103, valid_loss: 0.00465\n",
      "Epoch 28/30, train_loss: 0.01084, valid_loss: 0.00459\n",
      "Epoch 29/30, train_loss: 0.01066, valid_loss: 0.00453\n",
      "Epoch 30/30, train_loss: 0.01049, valid_loss: 0.00448\n",
      "At step 14\n",
      "Epoch 1/30, train_loss: 0.02370, valid_loss: 0.00297\n",
      "Epoch 2/30, train_loss: 0.01713, valid_loss: 0.00314\n",
      "Epoch 3/30, train_loss: 0.01409, valid_loss: 0.00302\n",
      "Epoch 4/30, train_loss: 0.01228, valid_loss: 0.00303\n",
      "Epoch 5/30, train_loss: 0.01106, valid_loss: 0.00299\n",
      "Epoch 6/30, train_loss: 0.01016, valid_loss: 0.00297\n",
      "Epoch 7/30, train_loss: 0.00946, valid_loss: 0.00295\n",
      "Epoch 8/30, train_loss: 0.00891, valid_loss: 0.00292\n",
      "Epoch 9/30, train_loss: 0.00845, valid_loss: 0.00297\n",
      "Epoch 10/30, train_loss: 0.00807, valid_loss: 0.00294\n",
      "Epoch 11/30, train_loss: 0.00774, valid_loss: 0.00292\n",
      "Epoch 12/30, train_loss: 0.00745, valid_loss: 0.00290\n",
      "Epoch 13/30, train_loss: 0.00720, valid_loss: 0.00289\n",
      "Epoch 14/30, train_loss: 0.00698, valid_loss: 0.00286\n",
      "Epoch 15/30, train_loss: 0.00678, valid_loss: 0.00285\n",
      "Epoch 16/30, train_loss: 0.00660, valid_loss: 0.00285\n",
      "Epoch 17/30, train_loss: 0.00643, valid_loss: 0.00284\n",
      "Epoch 18/30, train_loss: 0.00628, valid_loss: 0.00282\n",
      "Epoch 19/30, train_loss: 0.00614, valid_loss: 0.00281\n",
      "Epoch 20/30, train_loss: 0.00601, valid_loss: 0.00279\n",
      "Epoch 21/30, train_loss: 0.00589, valid_loss: 0.00278\n",
      "Epoch 22/30, train_loss: 0.00578, valid_loss: 0.00276\n",
      "Epoch 23/30, train_loss: 0.00567, valid_loss: 0.00275\n",
      "Epoch 24/30, train_loss: 0.00558, valid_loss: 0.00274\n",
      "Epoch 25/30, train_loss: 0.00549, valid_loss: 0.00273\n",
      "Epoch 26/30, train_loss: 0.00540, valid_loss: 0.00271\n",
      "Epoch 27/30, train_loss: 0.00532, valid_loss: 0.00270\n",
      "Epoch 28/30, train_loss: 0.00524, valid_loss: 0.00268\n",
      "Epoch 29/30, train_loss: 0.00518, valid_loss: 0.00271\n",
      "Epoch 30/30, train_loss: 0.00510, valid_loss: 0.00270\n",
      "At step 13\n",
      "Epoch 1/30, train_loss: 0.04429, valid_loss: 0.00558\n",
      "Epoch 2/30, train_loss: 0.03169, valid_loss: 0.00484\n",
      "Epoch 3/30, train_loss: 0.02598, valid_loss: 0.00454\n",
      "Epoch 4/30, train_loss: 0.02259, valid_loss: 0.00439\n",
      "Epoch 5/30, train_loss: 0.02029, valid_loss: 0.00429\n",
      "Epoch 6/30, train_loss: 0.01859, valid_loss: 0.00423\n",
      "Epoch 7/30, train_loss: 0.01728, valid_loss: 0.00417\n",
      "Epoch 8/30, train_loss: 0.01622, valid_loss: 0.00413\n",
      "Epoch 9/30, train_loss: 0.01535, valid_loss: 0.00409\n",
      "Epoch 10/30, train_loss: 0.01462, valid_loss: 0.00407\n",
      "Epoch 11/30, train_loss: 0.01399, valid_loss: 0.00404\n",
      "Epoch 12/30, train_loss: 0.01344, valid_loss: 0.00402\n",
      "Epoch 13/30, train_loss: 0.01297, valid_loss: 0.00401\n",
      "Epoch 14/30, train_loss: 0.01254, valid_loss: 0.00401\n",
      "Epoch 15/30, train_loss: 0.01216, valid_loss: 0.00405\n",
      "Epoch 16/30, train_loss: 0.01181, valid_loss: 0.00406\n",
      "Epoch 17/30, train_loss: 0.01150, valid_loss: 0.00406\n",
      "Epoch 18/30, train_loss: 0.01122, valid_loss: 0.00405\n",
      "Epoch 19/30, train_loss: 0.01095, valid_loss: 0.00404\n",
      "Epoch 20/30, train_loss: 0.01071, valid_loss: 0.00404\n",
      "Epoch 21/30, train_loss: 0.01049, valid_loss: 0.00404\n",
      "Epoch 22/30, train_loss: 0.01028, valid_loss: 0.00403\n",
      "Epoch 23/30, train_loss: 0.01008, valid_loss: 0.00403\n",
      "Epoch 24/30, train_loss: 0.00990, valid_loss: 0.00401\n",
      "Epoch 25/30, train_loss: 0.00974, valid_loss: 0.00400\n",
      "Epoch 26/30, train_loss: 0.00958, valid_loss: 0.00399\n",
      "Epoch 27/30, train_loss: 0.00942, valid_loss: 0.00398\n",
      "Epoch 28/30, train_loss: 0.00928, valid_loss: 0.00397\n",
      "Epoch 29/30, train_loss: 0.00915, valid_loss: 0.00395\n",
      "Epoch 30/30, train_loss: 0.00902, valid_loss: 0.00394\n",
      "At step 12\n",
      "Epoch 1/30, train_loss: 0.03119, valid_loss: 0.00493\n",
      "Epoch 2/30, train_loss: 0.02242, valid_loss: 0.00496\n",
      "Epoch 3/30, train_loss: 0.01848, valid_loss: 0.00474\n",
      "Epoch 4/30, train_loss: 0.01613, valid_loss: 0.00463\n",
      "Epoch 5/30, train_loss: 0.01455, valid_loss: 0.00458\n",
      "Epoch 6/30, train_loss: 0.01339, valid_loss: 0.00454\n",
      "Epoch 7/30, train_loss: 0.01249, valid_loss: 0.00452\n",
      "Epoch 8/30, train_loss: 0.01177, valid_loss: 0.00448\n",
      "Epoch 9/30, train_loss: 0.01118, valid_loss: 0.00446\n",
      "Epoch 10/30, train_loss: 0.01069, valid_loss: 0.00444\n",
      "Epoch 11/30, train_loss: 0.01026, valid_loss: 0.00442\n",
      "Epoch 12/30, train_loss: 0.00989, valid_loss: 0.00441\n",
      "Epoch 13/30, train_loss: 0.00957, valid_loss: 0.00439\n",
      "Epoch 14/30, train_loss: 0.00929, valid_loss: 0.00438\n",
      "Epoch 15/30, train_loss: 0.00903, valid_loss: 0.00437\n",
      "Epoch 16/30, train_loss: 0.00880, valid_loss: 0.00437\n",
      "Epoch 17/30, train_loss: 0.00859, valid_loss: 0.00437\n",
      "Epoch 18/30, train_loss: 0.00841, valid_loss: 0.00435\n",
      "Epoch 19/30, train_loss: 0.00823, valid_loss: 0.00436\n",
      "Epoch 20/30, train_loss: 0.00807, valid_loss: 0.00436\n",
      "Epoch 21/30, train_loss: 0.00792, valid_loss: 0.00437\n",
      "Epoch 22/30, train_loss: 0.00779, valid_loss: 0.00437\n",
      "Epoch 23/30, train_loss: 0.00766, valid_loss: 0.00437\n",
      "Epoch 24/30, train_loss: 0.00753, valid_loss: 0.00435\n",
      "Epoch 25/30, train_loss: 0.00742, valid_loss: 0.00434\n",
      "Epoch 26/30, train_loss: 0.00731, valid_loss: 0.00432\n",
      "Epoch 27/30, train_loss: 0.00721, valid_loss: 0.00430\n",
      "Epoch 28/30, train_loss: 0.00712, valid_loss: 0.00432\n",
      "Epoch 29/30, train_loss: 0.00703, valid_loss: 0.00430\n",
      "Epoch 30/30, train_loss: 0.00695, valid_loss: 0.00429\n",
      "At step 11\n",
      "Epoch 1/30, train_loss: 0.01422, valid_loss: 0.00705\n",
      "Epoch 2/30, train_loss: 0.01073, valid_loss: 0.00604\n",
      "Epoch 3/30, train_loss: 0.00920, valid_loss: 0.00568\n",
      "Epoch 4/30, train_loss: 0.00832, valid_loss: 0.00550\n",
      "Epoch 5/30, train_loss: 0.00774, valid_loss: 0.00536\n",
      "Epoch 6/30, train_loss: 0.00732, valid_loss: 0.00525\n",
      "Epoch 7/30, train_loss: 0.00701, valid_loss: 0.00516\n",
      "Epoch 8/30, train_loss: 0.00677, valid_loss: 0.00509\n",
      "Epoch 9/30, train_loss: 0.00657, valid_loss: 0.00506\n",
      "Epoch 10/30, train_loss: 0.00639, valid_loss: 0.00501\n",
      "Epoch 11/30, train_loss: 0.00624, valid_loss: 0.00496\n",
      "Epoch 12/30, train_loss: 0.00611, valid_loss: 0.00491\n",
      "Epoch 13/30, train_loss: 0.00599, valid_loss: 0.00486\n",
      "Epoch 14/30, train_loss: 0.00589, valid_loss: 0.00481\n",
      "Epoch 15/30, train_loss: 0.00579, valid_loss: 0.00476\n",
      "Epoch 16/30, train_loss: 0.00570, valid_loss: 0.00472\n",
      "Epoch 17/30, train_loss: 0.00562, valid_loss: 0.00468\n",
      "Epoch 18/30, train_loss: 0.00554, valid_loss: 0.00463\n",
      "Epoch 19/30, train_loss: 0.00546, valid_loss: 0.00461\n",
      "Epoch 20/30, train_loss: 0.00539, valid_loss: 0.00459\n",
      "Epoch 21/30, train_loss: 0.00532, valid_loss: 0.00454\n",
      "Epoch 22/30, train_loss: 0.00526, valid_loss: 0.00449\n",
      "Epoch 23/30, train_loss: 0.00519, valid_loss: 0.00444\n",
      "Epoch 24/30, train_loss: 0.00512, valid_loss: 0.00440\n",
      "Epoch 25/30, train_loss: 0.00505, valid_loss: 0.00438\n",
      "Epoch 26/30, train_loss: 0.00499, valid_loss: 0.00433\n",
      "Epoch 27/30, train_loss: 0.00493, valid_loss: 0.00428\n",
      "Epoch 28/30, train_loss: 0.00486, valid_loss: 0.00422\n",
      "Epoch 29/30, train_loss: 0.00480, valid_loss: 0.00419\n",
      "Epoch 30/30, train_loss: 0.00475, valid_loss: 0.00414\n",
      "At step 10\n",
      "Epoch 1/30, train_loss: 0.01068, valid_loss: 0.00548\n",
      "Epoch 2/30, train_loss: 0.00836, valid_loss: 0.00529\n",
      "Epoch 3/30, train_loss: 0.00740, valid_loss: 0.00521\n",
      "Epoch 4/30, train_loss: 0.00685, valid_loss: 0.00518\n",
      "Epoch 5/30, train_loss: 0.00650, valid_loss: 0.00517\n",
      "Epoch 6/30, train_loss: 0.00627, valid_loss: 0.00513\n",
      "Epoch 7/30, train_loss: 0.00607, valid_loss: 0.00510\n",
      "Epoch 8/30, train_loss: 0.00592, valid_loss: 0.00504\n",
      "Epoch 9/30, train_loss: 0.00579, valid_loss: 0.00500\n",
      "Epoch 10/30, train_loss: 0.00570, valid_loss: 0.00495\n",
      "Epoch 11/30, train_loss: 0.00561, valid_loss: 0.00490\n",
      "Epoch 12/30, train_loss: 0.00551, valid_loss: 0.00485\n",
      "Epoch 13/30, train_loss: 0.00542, valid_loss: 0.00481\n",
      "Epoch 14/30, train_loss: 0.00532, valid_loss: 0.00476\n",
      "Epoch 15/30, train_loss: 0.00523, valid_loss: 0.00470\n",
      "Epoch 16/30, train_loss: 0.00513, valid_loss: 0.00462\n",
      "Epoch 17/30, train_loss: 0.00503, valid_loss: 0.00461\n",
      "Epoch 18/30, train_loss: 0.00494, valid_loss: 0.00451\n",
      "Epoch 19/30, train_loss: 0.00485, valid_loss: 0.00443\n",
      "Epoch 20/30, train_loss: 0.00476, valid_loss: 0.00438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, train_loss: 0.00469, valid_loss: 0.00430\n",
      "Epoch 22/30, train_loss: 0.00459, valid_loss: 0.00422\n",
      "Epoch 23/30, train_loss: 0.00451, valid_loss: 0.00414\n",
      "Epoch 24/30, train_loss: 0.00442, valid_loss: 0.00408\n",
      "Epoch 25/30, train_loss: 0.00434, valid_loss: 0.00400\n",
      "Epoch 26/30, train_loss: 0.00426, valid_loss: 0.00393\n",
      "Epoch 27/30, train_loss: 0.00419, valid_loss: 0.00386\n",
      "Epoch 28/30, train_loss: 0.00413, valid_loss: 0.00380\n",
      "Epoch 29/30, train_loss: 0.00406, valid_loss: 0.00374\n",
      "Epoch 30/30, train_loss: 0.00400, valid_loss: 0.00368\n",
      "At step 9\n",
      "Epoch 1/30, train_loss: 0.03807, valid_loss: 0.00543\n",
      "Epoch 2/30, train_loss: 0.02729, valid_loss: 0.00517\n",
      "Epoch 3/30, train_loss: 0.02251, valid_loss: 0.00514\n",
      "Epoch 4/30, train_loss: 0.01969, valid_loss: 0.00512\n",
      "Epoch 5/30, train_loss: 0.01778, valid_loss: 0.00510\n",
      "Epoch 6/30, train_loss: 0.01638, valid_loss: 0.00512\n",
      "Epoch 7/30, train_loss: 0.01531, valid_loss: 0.00511\n",
      "Epoch 8/30, train_loss: 0.01445, valid_loss: 0.00508\n",
      "Epoch 9/30, train_loss: 0.01374, valid_loss: 0.00508\n",
      "Epoch 10/30, train_loss: 0.01315, valid_loss: 0.00506\n",
      "Epoch 11/30, train_loss: 0.01264, valid_loss: 0.00505\n",
      "Epoch 12/30, train_loss: 0.01220, valid_loss: 0.00501\n",
      "Epoch 13/30, train_loss: 0.01182, valid_loss: 0.00498\n",
      "Epoch 14/30, train_loss: 0.01148, valid_loss: 0.00498\n",
      "Epoch 15/30, train_loss: 0.01117, valid_loss: 0.00495\n",
      "Epoch 16/30, train_loss: 0.01090, valid_loss: 0.00496\n",
      "Epoch 17/30, train_loss: 0.01066, valid_loss: 0.00494\n",
      "Epoch 18/30, train_loss: 0.01043, valid_loss: 0.00493\n",
      "Epoch 19/30, train_loss: 0.01022, valid_loss: 0.00493\n",
      "Epoch 20/30, train_loss: 0.01003, valid_loss: 0.00493\n",
      "Epoch 21/30, train_loss: 0.00986, valid_loss: 0.00491\n",
      "Epoch 22/30, train_loss: 0.00970, valid_loss: 0.00492\n",
      "Epoch 23/30, train_loss: 0.00954, valid_loss: 0.00491\n",
      "Epoch 24/30, train_loss: 0.00940, valid_loss: 0.00489\n",
      "Epoch 25/30, train_loss: 0.00927, valid_loss: 0.00492\n",
      "Epoch 26/30, train_loss: 0.00914, valid_loss: 0.00492\n",
      "Epoch 27/30, train_loss: 0.00902, valid_loss: 0.00491\n",
      "Epoch 28/30, train_loss: 0.00890, valid_loss: 0.00490\n",
      "Epoch 29/30, train_loss: 0.00879, valid_loss: 0.00488\n",
      "Epoch 30/30, train_loss: 0.00869, valid_loss: 0.00486\n",
      "At step 8\n",
      "Epoch 1/30, train_loss: 0.02882, valid_loss: 0.00769\n",
      "Epoch 2/30, train_loss: 0.02080, valid_loss: 0.00674\n",
      "Epoch 3/30, train_loss: 0.01729, valid_loss: 0.00641\n",
      "Epoch 4/30, train_loss: 0.01523, valid_loss: 0.00624\n",
      "Epoch 5/30, train_loss: 0.01385, valid_loss: 0.00611\n",
      "Epoch 6/30, train_loss: 0.01285, valid_loss: 0.00606\n",
      "Epoch 7/30, train_loss: 0.01208, valid_loss: 0.00599\n",
      "Epoch 8/30, train_loss: 0.01146, valid_loss: 0.00594\n",
      "Epoch 9/30, train_loss: 0.01096, valid_loss: 0.00588\n",
      "Epoch 10/30, train_loss: 0.01054, valid_loss: 0.00583\n",
      "Epoch 11/30, train_loss: 0.01018, valid_loss: 0.00579\n",
      "Epoch 12/30, train_loss: 0.00987, valid_loss: 0.00576\n",
      "Epoch 13/30, train_loss: 0.00959, valid_loss: 0.00572\n",
      "Epoch 14/30, train_loss: 0.00935, valid_loss: 0.00568\n",
      "Epoch 15/30, train_loss: 0.00914, valid_loss: 0.00565\n",
      "Epoch 16/30, train_loss: 0.00895, valid_loss: 0.00563\n",
      "Epoch 17/30, train_loss: 0.00877, valid_loss: 0.00560\n",
      "Epoch 18/30, train_loss: 0.00861, valid_loss: 0.00555\n",
      "Epoch 19/30, train_loss: 0.00845, valid_loss: 0.00552\n",
      "Epoch 20/30, train_loss: 0.00831, valid_loss: 0.00549\n",
      "Epoch 21/30, train_loss: 0.00818, valid_loss: 0.00545\n",
      "Epoch 22/30, train_loss: 0.00805, valid_loss: 0.00542\n",
      "Epoch 23/30, train_loss: 0.00793, valid_loss: 0.00538\n",
      "Epoch 24/30, train_loss: 0.00781, valid_loss: 0.00533\n",
      "Epoch 25/30, train_loss: 0.00771, valid_loss: 0.00529\n",
      "Epoch 26/30, train_loss: 0.00760, valid_loss: 0.00525\n",
      "Epoch 27/30, train_loss: 0.00750, valid_loss: 0.00520\n",
      "Epoch 28/30, train_loss: 0.00740, valid_loss: 0.00517\n",
      "Epoch 29/30, train_loss: 0.00730, valid_loss: 0.00513\n",
      "Epoch 30/30, train_loss: 0.00721, valid_loss: 0.00508\n",
      "At step 7\n",
      "Epoch 1/30, train_loss: 0.01939, valid_loss: 0.00666\n",
      "Epoch 2/30, train_loss: 0.01439, valid_loss: 0.00628\n",
      "Epoch 3/30, train_loss: 0.01228, valid_loss: 0.00611\n",
      "Epoch 4/30, train_loss: 0.01106, valid_loss: 0.00629\n",
      "Epoch 5/30, train_loss: 0.01026, valid_loss: 0.00617\n",
      "Epoch 6/30, train_loss: 0.00971, valid_loss: 0.00621\n",
      "Epoch 7/30, train_loss: 0.00925, valid_loss: 0.00619\n",
      "Epoch 8/30, train_loss: 0.00889, valid_loss: 0.00612\n",
      "Epoch 9/30, train_loss: 0.00860, valid_loss: 0.00611\n",
      "Epoch 10/30, train_loss: 0.00835, valid_loss: 0.00603\n",
      "Epoch 11/30, train_loss: 0.00813, valid_loss: 0.00598\n",
      "Epoch 12/30, train_loss: 0.00794, valid_loss: 0.00591\n",
      "Epoch 13/30, train_loss: 0.00776, valid_loss: 0.00584\n",
      "Epoch 14/30, train_loss: 0.00760, valid_loss: 0.00575\n",
      "Epoch 15/30, train_loss: 0.00747, valid_loss: 0.00581\n",
      "Epoch 16/30, train_loss: 0.00734, valid_loss: 0.00574\n",
      "Epoch 17/30, train_loss: 0.00724, valid_loss: 0.00567\n",
      "Epoch 18/30, train_loss: 0.00711, valid_loss: 0.00559\n",
      "Epoch 19/30, train_loss: 0.00699, valid_loss: 0.00551\n",
      "Epoch 20/30, train_loss: 0.00687, valid_loss: 0.00542\n",
      "Epoch 21/30, train_loss: 0.00675, valid_loss: 0.00534\n",
      "Epoch 22/30, train_loss: 0.00664, valid_loss: 0.00525\n",
      "Epoch 23/30, train_loss: 0.00653, valid_loss: 0.00516\n",
      "Epoch 24/30, train_loss: 0.00642, valid_loss: 0.00508\n",
      "Epoch 25/30, train_loss: 0.00632, valid_loss: 0.00504\n",
      "Epoch 26/30, train_loss: 0.00622, valid_loss: 0.00497\n",
      "Epoch 27/30, train_loss: 0.00613, valid_loss: 0.00491\n",
      "Epoch 28/30, train_loss: 0.00603, valid_loss: 0.00483\n",
      "Epoch 29/30, train_loss: 0.00594, valid_loss: 0.00480\n",
      "Epoch 30/30, train_loss: 0.00585, valid_loss: 0.00475\n",
      "At step 6\n",
      "Epoch 1/30, train_loss: 0.02205, valid_loss: 0.00653\n",
      "Epoch 2/30, train_loss: 0.01616, valid_loss: 0.00624\n",
      "Epoch 3/30, train_loss: 0.01362, valid_loss: 0.00614\n",
      "Epoch 4/30, train_loss: 0.01215, valid_loss: 0.00607\n",
      "Epoch 5/30, train_loss: 0.01117, valid_loss: 0.00600\n",
      "Epoch 6/30, train_loss: 0.01046, valid_loss: 0.00595\n",
      "Epoch 7/30, train_loss: 0.00992, valid_loss: 0.00592\n",
      "Epoch 8/30, train_loss: 0.00949, valid_loss: 0.00588\n",
      "Epoch 9/30, train_loss: 0.00913, valid_loss: 0.00587\n",
      "Epoch 10/30, train_loss: 0.00883, valid_loss: 0.00582\n",
      "Epoch 11/30, train_loss: 0.00857, valid_loss: 0.00576\n",
      "Epoch 12/30, train_loss: 0.00834, valid_loss: 0.00571\n",
      "Epoch 13/30, train_loss: 0.00813, valid_loss: 0.00566\n",
      "Epoch 14/30, train_loss: 0.00794, valid_loss: 0.00560\n",
      "Epoch 15/30, train_loss: 0.00776, valid_loss: 0.00553\n",
      "Epoch 16/30, train_loss: 0.00759, valid_loss: 0.00546\n",
      "Epoch 17/30, train_loss: 0.00744, valid_loss: 0.00543\n",
      "Epoch 18/30, train_loss: 0.00730, valid_loss: 0.00535\n",
      "Epoch 19/30, train_loss: 0.00716, valid_loss: 0.00527\n",
      "Epoch 20/30, train_loss: 0.00702, valid_loss: 0.00518\n",
      "Epoch 21/30, train_loss: 0.00688, valid_loss: 0.00510\n",
      "Epoch 22/30, train_loss: 0.00675, valid_loss: 0.00501\n",
      "Epoch 23/30, train_loss: 0.00662, valid_loss: 0.00494\n",
      "Epoch 24/30, train_loss: 0.00650, valid_loss: 0.00486\n",
      "Epoch 25/30, train_loss: 0.00638, valid_loss: 0.00477\n",
      "Epoch 26/30, train_loss: 0.00627, valid_loss: 0.00469\n",
      "Epoch 27/30, train_loss: 0.00616, valid_loss: 0.00461\n",
      "Epoch 28/30, train_loss: 0.00606, valid_loss: 0.00453\n",
      "Epoch 29/30, train_loss: 0.00596, valid_loss: 0.00448\n",
      "Epoch 30/30, train_loss: 0.00587, valid_loss: 0.00442\n",
      "At step 5\n",
      "Epoch 1/30, train_loss: 0.01341, valid_loss: 0.00644\n",
      "Epoch 2/30, train_loss: 0.01043, valid_loss: 0.00631\n",
      "Epoch 3/30, train_loss: 0.00917, valid_loss: 0.00642\n",
      "Epoch 4/30, train_loss: 0.00850, valid_loss: 0.00627\n",
      "Epoch 5/30, train_loss: 0.00800, valid_loss: 0.00616\n",
      "Epoch 6/30, train_loss: 0.00762, valid_loss: 0.00600\n",
      "Epoch 7/30, train_loss: 0.00731, valid_loss: 0.00584\n",
      "Epoch 8/30, train_loss: 0.00705, valid_loss: 0.00590\n",
      "Epoch 9/30, train_loss: 0.00681, valid_loss: 0.00571\n",
      "Epoch 10/30, train_loss: 0.00656, valid_loss: 0.00553\n",
      "Epoch 11/30, train_loss: 0.00632, valid_loss: 0.00546\n",
      "Epoch 12/30, train_loss: 0.00611, valid_loss: 0.00532\n",
      "Epoch 13/30, train_loss: 0.00591, valid_loss: 0.00514\n",
      "Epoch 14/30, train_loss: 0.00572, valid_loss: 0.00496\n",
      "Epoch 15/30, train_loss: 0.00554, valid_loss: 0.00482\n",
      "Epoch 16/30, train_loss: 0.00538, valid_loss: 0.00470\n",
      "Epoch 17/30, train_loss: 0.00524, valid_loss: 0.00458\n",
      "Epoch 18/30, train_loss: 0.00511, valid_loss: 0.00448\n",
      "Epoch 19/30, train_loss: 0.00499, valid_loss: 0.00437\n",
      "Epoch 20/30, train_loss: 0.00488, valid_loss: 0.00427\n",
      "Epoch 21/30, train_loss: 0.00478, valid_loss: 0.00421\n",
      "Epoch 22/30, train_loss: 0.00469, valid_loss: 0.00416\n",
      "Epoch 23/30, train_loss: 0.00460, valid_loss: 0.00407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, train_loss: 0.00452, valid_loss: 0.00400\n",
      "Epoch 25/30, train_loss: 0.00443, valid_loss: 0.00395\n",
      "Epoch 26/30, train_loss: 0.00436, valid_loss: 0.00388\n",
      "Epoch 27/30, train_loss: 0.00429, valid_loss: 0.00382\n",
      "Epoch 28/30, train_loss: 0.00422, valid_loss: 0.00377\n",
      "Epoch 29/30, train_loss: 0.00416, valid_loss: 0.00371\n",
      "Epoch 30/30, train_loss: 0.00410, valid_loss: 0.00365\n",
      "At step 4\n",
      "Epoch 1/30, train_loss: 0.01156, valid_loss: 0.00645\n",
      "Epoch 2/30, train_loss: 0.00945, valid_loss: 0.00634\n",
      "Epoch 3/30, train_loss: 0.00858, valid_loss: 0.00621\n",
      "Epoch 4/30, train_loss: 0.00811, valid_loss: 0.00613\n",
      "Epoch 5/30, train_loss: 0.00774, valid_loss: 0.00597\n",
      "Epoch 6/30, train_loss: 0.00742, valid_loss: 0.00580\n",
      "Epoch 7/30, train_loss: 0.00713, valid_loss: 0.00568\n",
      "Epoch 8/30, train_loss: 0.00690, valid_loss: 0.00547\n",
      "Epoch 9/30, train_loss: 0.00664, valid_loss: 0.00529\n",
      "Epoch 10/30, train_loss: 0.00640, valid_loss: 0.00518\n",
      "Epoch 11/30, train_loss: 0.00616, valid_loss: 0.00500\n",
      "Epoch 12/30, train_loss: 0.00594, valid_loss: 0.00481\n",
      "Epoch 13/30, train_loss: 0.00574, valid_loss: 0.00464\n",
      "Epoch 14/30, train_loss: 0.00555, valid_loss: 0.00448\n",
      "Epoch 15/30, train_loss: 0.00539, valid_loss: 0.00435\n",
      "Epoch 16/30, train_loss: 0.00524, valid_loss: 0.00422\n",
      "Epoch 17/30, train_loss: 0.00509, valid_loss: 0.00412\n",
      "Epoch 18/30, train_loss: 0.00497, valid_loss: 0.00401\n",
      "Epoch 19/30, train_loss: 0.00485, valid_loss: 0.00393\n",
      "Epoch 20/30, train_loss: 0.00474, valid_loss: 0.00385\n",
      "Epoch 21/30, train_loss: 0.00464, valid_loss: 0.00377\n",
      "Epoch 22/30, train_loss: 0.00455, valid_loss: 0.00371\n",
      "Epoch 23/30, train_loss: 0.00446, valid_loss: 0.00365\n",
      "Epoch 24/30, train_loss: 0.00437, valid_loss: 0.00360\n",
      "Epoch 25/30, train_loss: 0.00430, valid_loss: 0.00353\n",
      "Epoch 26/30, train_loss: 0.00422, valid_loss: 0.00347\n",
      "Epoch 27/30, train_loss: 0.00416, valid_loss: 0.00341\n",
      "Epoch 28/30, train_loss: 0.00410, valid_loss: 0.00336\n",
      "Epoch 29/30, train_loss: 0.00404, valid_loss: 0.00330\n",
      "Epoch 30/30, train_loss: 0.00398, valid_loss: 0.00325\n",
      "At step 3\n",
      "Epoch 1/30, train_loss: 0.01028, valid_loss: 0.00655\n",
      "Epoch 2/30, train_loss: 0.00845, valid_loss: 0.00627\n",
      "Epoch 3/30, train_loss: 0.00769, valid_loss: 0.00599\n",
      "Epoch 4/30, train_loss: 0.00722, valid_loss: 0.00584\n",
      "Epoch 5/30, train_loss: 0.00677, valid_loss: 0.00570\n",
      "Epoch 6/30, train_loss: 0.00643, valid_loss: 0.00571\n",
      "Epoch 7/30, train_loss: 0.00610, valid_loss: 0.00561\n",
      "Epoch 8/30, train_loss: 0.00579, valid_loss: 0.00530\n",
      "Epoch 9/30, train_loss: 0.00551, valid_loss: 0.00516\n",
      "Epoch 10/30, train_loss: 0.00526, valid_loss: 0.00495\n",
      "Epoch 11/30, train_loss: 0.00505, valid_loss: 0.00484\n",
      "Epoch 12/30, train_loss: 0.00488, valid_loss: 0.00465\n",
      "Epoch 13/30, train_loss: 0.00471, valid_loss: 0.00455\n",
      "Epoch 14/30, train_loss: 0.00457, valid_loss: 0.00444\n",
      "Epoch 15/30, train_loss: 0.00444, valid_loss: 0.00432\n",
      "Epoch 16/30, train_loss: 0.00433, valid_loss: 0.00428\n",
      "Epoch 17/30, train_loss: 0.00422, valid_loss: 0.00416\n",
      "Epoch 18/30, train_loss: 0.00412, valid_loss: 0.00406\n",
      "Epoch 19/30, train_loss: 0.00404, valid_loss: 0.00400\n",
      "Epoch 20/30, train_loss: 0.00396, valid_loss: 0.00391\n",
      "Epoch 21/30, train_loss: 0.00389, valid_loss: 0.00383\n",
      "Epoch 22/30, train_loss: 0.00383, valid_loss: 0.00376\n",
      "Epoch 23/30, train_loss: 0.00377, valid_loss: 0.00369\n",
      "Epoch 24/30, train_loss: 0.00370, valid_loss: 0.00362\n",
      "Epoch 25/30, train_loss: 0.00364, valid_loss: 0.00362\n",
      "Epoch 26/30, train_loss: 0.00359, valid_loss: 0.00355\n",
      "Epoch 27/30, train_loss: 0.00354, valid_loss: 0.00349\n",
      "Epoch 28/30, train_loss: 0.00348, valid_loss: 0.00343\n",
      "Epoch 29/30, train_loss: 0.00344, valid_loss: 0.00342\n",
      "Epoch 30/30, train_loss: 0.00339, valid_loss: 0.00337\n",
      "At step 2\n",
      "Epoch 1/30, train_loss: 0.01977, valid_loss: 0.00634\n",
      "Epoch 2/30, train_loss: 0.01470, valid_loss: 0.00637\n",
      "Epoch 3/30, train_loss: 0.01255, valid_loss: 0.00628\n",
      "Epoch 4/30, train_loss: 0.01131, valid_loss: 0.00624\n",
      "Epoch 5/30, train_loss: 0.01049, valid_loss: 0.00618\n",
      "Epoch 6/30, train_loss: 0.00989, valid_loss: 0.00625\n",
      "Epoch 7/30, train_loss: 0.00942, valid_loss: 0.00617\n",
      "Epoch 8/30, train_loss: 0.00904, valid_loss: 0.00610\n",
      "Epoch 9/30, train_loss: 0.00872, valid_loss: 0.00601\n",
      "Epoch 10/30, train_loss: 0.00844, valid_loss: 0.00596\n",
      "Epoch 11/30, train_loss: 0.00819, valid_loss: 0.00589\n",
      "Epoch 12/30, train_loss: 0.00796, valid_loss: 0.00576\n",
      "Epoch 13/30, train_loss: 0.00774, valid_loss: 0.00564\n",
      "Epoch 14/30, train_loss: 0.00752, valid_loss: 0.00550\n",
      "Epoch 15/30, train_loss: 0.00731, valid_loss: 0.00536\n",
      "Epoch 16/30, train_loss: 0.00712, valid_loss: 0.00522\n",
      "Epoch 17/30, train_loss: 0.00692, valid_loss: 0.00508\n",
      "Epoch 18/30, train_loss: 0.00675, valid_loss: 0.00495\n",
      "Epoch 19/30, train_loss: 0.00658, valid_loss: 0.00483\n",
      "Epoch 20/30, train_loss: 0.00643, valid_loss: 0.00471\n",
      "Epoch 21/30, train_loss: 0.00628, valid_loss: 0.00465\n",
      "Epoch 22/30, train_loss: 0.00616, valid_loss: 0.00455\n",
      "Epoch 23/30, train_loss: 0.00603, valid_loss: 0.00446\n",
      "Epoch 24/30, train_loss: 0.00591, valid_loss: 0.00437\n",
      "Epoch 25/30, train_loss: 0.00581, valid_loss: 0.00429\n",
      "Epoch 26/30, train_loss: 0.00570, valid_loss: 0.00422\n",
      "Epoch 27/30, train_loss: 0.00560, valid_loss: 0.00415\n",
      "Epoch 28/30, train_loss: 0.00551, valid_loss: 0.00408\n",
      "Epoch 29/30, train_loss: 0.00543, valid_loss: 0.00404\n",
      "Epoch 30/30, train_loss: 0.00535, valid_loss: 0.00398\n",
      "At step 18\n",
      "Epoch 1/30, train_loss: 0.01175, valid_loss: 0.00072\n",
      "Epoch 2/30, train_loss: 0.00832, valid_loss: 0.00074\n",
      "Epoch 3/30, train_loss: 0.00681, valid_loss: 0.00075\n",
      "Epoch 4/30, train_loss: 0.00591, valid_loss: 0.00076\n",
      "Epoch 5/30, train_loss: 0.00529, valid_loss: 0.00075\n",
      "Epoch 6/30, train_loss: 0.00484, valid_loss: 0.00074\n",
      "Epoch 7/30, train_loss: 0.00449, valid_loss: 0.00083\n",
      "Epoch 8/30, train_loss: 0.00421, valid_loss: 0.00083\n",
      "Epoch 9/30, train_loss: 0.00398, valid_loss: 0.00084\n",
      "Epoch 10/30, train_loss: 0.00378, valid_loss: 0.00083\n",
      "Epoch 11/30, train_loss: 0.00361, valid_loss: 0.00082\n",
      "Epoch 12/30, train_loss: 0.00346, valid_loss: 0.00081\n",
      "Epoch 13/30, train_loss: 0.00334, valid_loss: 0.00080\n",
      "Epoch 14/30, train_loss: 0.00322, valid_loss: 0.00080\n",
      "Epoch 15/30, train_loss: 0.00312, valid_loss: 0.00081\n",
      "Epoch 16/30, train_loss: 0.00303, valid_loss: 0.00081\n",
      "Epoch 17/30, train_loss: 0.00294, valid_loss: 0.00084\n",
      "Epoch 18/30, train_loss: 0.00287, valid_loss: 0.00083\n",
      "Epoch 19/30, train_loss: 0.00280, valid_loss: 0.00084\n",
      "Epoch 20/30, train_loss: 0.00274, valid_loss: 0.00085\n",
      "Epoch 21/30, train_loss: 0.00268, valid_loss: 0.00095\n",
      "Epoch 22/30, train_loss: 0.00263, valid_loss: 0.00096\n",
      "Epoch 23/30, train_loss: 0.00258, valid_loss: 0.00099\n",
      "Epoch 24/30, train_loss: 0.00254, valid_loss: 0.00098\n",
      "Epoch 25/30, train_loss: 0.00249, valid_loss: 0.00097\n",
      "Epoch 26/30, train_loss: 0.00245, valid_loss: 0.00103\n",
      "Epoch 27/30, train_loss: 0.00241, valid_loss: 0.00110\n",
      "Epoch 28/30, train_loss: 0.00238, valid_loss: 0.00109\n",
      "Epoch 29/30, train_loss: 0.00234, valid_loss: 0.00108\n",
      "Epoch 30/30, train_loss: 0.00231, valid_loss: 0.00107\n",
      "At step 17\n",
      "Epoch 1/30, train_loss: 0.00645, valid_loss: 0.00144\n",
      "Epoch 2/30, train_loss: 0.00467, valid_loss: 0.00143\n",
      "Epoch 3/30, train_loss: 0.00390, valid_loss: 0.00264\n",
      "Epoch 4/30, train_loss: 0.00348, valid_loss: 0.00253\n",
      "Epoch 5/30, train_loss: 0.00319, valid_loss: 0.00237\n",
      "Epoch 6/30, train_loss: 0.00296, valid_loss: 0.00226\n",
      "Epoch 7/30, train_loss: 0.00280, valid_loss: 0.00214\n",
      "Epoch 8/30, train_loss: 0.00266, valid_loss: 0.00260\n",
      "Epoch 9/30, train_loss: 0.00255, valid_loss: 0.00287\n",
      "Epoch 10/30, train_loss: 0.00246, valid_loss: 0.00274\n",
      "Epoch 11/30, train_loss: 0.00238, valid_loss: 0.00271\n",
      "Epoch 12/30, train_loss: 0.00231, valid_loss: 0.00263\n",
      "Epoch 13/30, train_loss: 0.00224, valid_loss: 0.00254\n",
      "Epoch 14/30, train_loss: 0.00218, valid_loss: 0.00246\n",
      "Epoch 15/30, train_loss: 0.00213, valid_loss: 0.00242\n",
      "Epoch 16/30, train_loss: 0.00208, valid_loss: 0.00238\n",
      "Epoch 17/30, train_loss: 0.00204, valid_loss: 0.00236\n",
      "Epoch 18/30, train_loss: 0.00199, valid_loss: 0.00230\n",
      "Epoch 19/30, train_loss: 0.00195, valid_loss: 0.00225\n",
      "Epoch 20/30, train_loss: 0.00191, valid_loss: 0.00219\n",
      "Epoch 21/30, train_loss: 0.00187, valid_loss: 0.00217\n",
      "Epoch 22/30, train_loss: 0.00184, valid_loss: 0.00215\n",
      "Epoch 23/30, train_loss: 0.00181, valid_loss: 0.00211\n",
      "Epoch 24/30, train_loss: 0.00178, valid_loss: 0.00211\n",
      "Epoch 25/30, train_loss: 0.00175, valid_loss: 0.00207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, train_loss: 0.00172, valid_loss: 0.00203\n",
      "Epoch 27/30, train_loss: 0.00170, valid_loss: 0.00200\n",
      "Epoch 28/30, train_loss: 0.00168, valid_loss: 0.00198\n",
      "Epoch 29/30, train_loss: 0.00165, valid_loss: 0.00195\n",
      "Epoch 30/30, train_loss: 0.00163, valid_loss: 0.00191\n",
      "At step 16\n",
      "Epoch 1/30, train_loss: 0.02588, valid_loss: 0.00206\n",
      "Epoch 2/30, train_loss: 0.01836, valid_loss: 0.00206\n",
      "Epoch 3/30, train_loss: 0.01504, valid_loss: 0.00207\n",
      "Epoch 4/30, train_loss: 0.01306, valid_loss: 0.00207\n",
      "Epoch 5/30, train_loss: 0.01172, valid_loss: 0.00206\n",
      "Epoch 6/30, train_loss: 0.01073, valid_loss: 0.00205\n",
      "Epoch 7/30, train_loss: 0.00997, valid_loss: 0.00208\n",
      "Epoch 8/30, train_loss: 0.00935, valid_loss: 0.00213\n",
      "Epoch 9/30, train_loss: 0.00884, valid_loss: 0.00211\n",
      "Epoch 10/30, train_loss: 0.00841, valid_loss: 0.00209\n",
      "Epoch 11/30, train_loss: 0.00804, valid_loss: 0.00208\n",
      "Epoch 12/30, train_loss: 0.00772, valid_loss: 0.00206\n",
      "Epoch 13/30, train_loss: 0.00744, valid_loss: 0.00208\n",
      "Epoch 14/30, train_loss: 0.00719, valid_loss: 0.00237\n",
      "Epoch 15/30, train_loss: 0.00696, valid_loss: 0.00234\n",
      "Epoch 16/30, train_loss: 0.00676, valid_loss: 0.00231\n",
      "Epoch 17/30, train_loss: 0.00657, valid_loss: 0.00229\n",
      "Epoch 18/30, train_loss: 0.00640, valid_loss: 0.00231\n",
      "Epoch 19/30, train_loss: 0.00625, valid_loss: 0.00228\n",
      "Epoch 20/30, train_loss: 0.00610, valid_loss: 0.00225\n",
      "Epoch 21/30, train_loss: 0.00596, valid_loss: 0.00231\n",
      "Epoch 22/30, train_loss: 0.00583, valid_loss: 0.00240\n",
      "Epoch 23/30, train_loss: 0.00572, valid_loss: 0.00246\n",
      "Epoch 24/30, train_loss: 0.00561, valid_loss: 0.00248\n",
      "Epoch 25/30, train_loss: 0.00550, valid_loss: 0.00245\n",
      "Epoch 26/30, train_loss: 0.00540, valid_loss: 0.00247\n",
      "Epoch 27/30, train_loss: 0.00531, valid_loss: 0.00253\n",
      "Epoch 28/30, train_loss: 0.00522, valid_loss: 0.00251\n",
      "Epoch 29/30, train_loss: 0.00514, valid_loss: 0.00252\n",
      "Epoch 30/30, train_loss: 0.00506, valid_loss: 0.00259\n",
      "At step 15\n",
      "Epoch 1/30, train_loss: 0.00591, valid_loss: 0.00259\n",
      "Epoch 2/30, train_loss: 0.00457, valid_loss: 0.00257\n",
      "Epoch 3/30, train_loss: 0.00403, valid_loss: 0.00271\n",
      "Epoch 4/30, train_loss: 0.00372, valid_loss: 0.00265\n",
      "Epoch 5/30, train_loss: 0.00350, valid_loss: 0.00265\n",
      "Epoch 6/30, train_loss: 0.00335, valid_loss: 0.00261\n",
      "Epoch 7/30, train_loss: 0.00321, valid_loss: 0.00252\n",
      "Epoch 8/30, train_loss: 0.00310, valid_loss: 0.00245\n",
      "Epoch 9/30, train_loss: 0.00299, valid_loss: 0.00240\n",
      "Epoch 10/30, train_loss: 0.00288, valid_loss: 0.00231\n",
      "Epoch 11/30, train_loss: 0.00278, valid_loss: 0.00224\n",
      "Epoch 12/30, train_loss: 0.00269, valid_loss: 0.00219\n",
      "Epoch 13/30, train_loss: 0.00261, valid_loss: 0.00214\n",
      "Epoch 14/30, train_loss: 0.00254, valid_loss: 0.00220\n",
      "Epoch 15/30, train_loss: 0.00247, valid_loss: 0.00214\n",
      "Epoch 16/30, train_loss: 0.00240, valid_loss: 0.00214\n",
      "Epoch 17/30, train_loss: 0.00248, valid_loss: 0.00212\n",
      "Epoch 18/30, train_loss: 0.00245, valid_loss: 0.00210\n",
      "Epoch 19/30, train_loss: 0.00241, valid_loss: 0.00207\n",
      "Epoch 20/30, train_loss: 0.00237, valid_loss: 0.00203\n",
      "Epoch 21/30, train_loss: 0.00233, valid_loss: 0.00200\n",
      "Epoch 22/30, train_loss: 0.00228, valid_loss: 0.00196\n",
      "Epoch 23/30, train_loss: 0.00224, valid_loss: 0.00192\n",
      "Epoch 24/30, train_loss: 0.00220, valid_loss: 0.00189\n",
      "Epoch 25/30, train_loss: 0.00216, valid_loss: 0.00186\n",
      "Epoch 26/30, train_loss: 0.00212, valid_loss: 0.00183\n",
      "Epoch 27/30, train_loss: 0.00209, valid_loss: 0.00180\n",
      "Epoch 28/30, train_loss: 0.00206, valid_loss: 0.00177\n",
      "Epoch 29/30, train_loss: 0.00203, valid_loss: 0.00175\n",
      "Epoch 30/30, train_loss: 0.00200, valid_loss: 0.00172\n",
      "At step 14\n",
      "Epoch 1/30, train_loss: 0.01103, valid_loss: 0.00283\n",
      "Epoch 2/30, train_loss: 0.00806, valid_loss: 0.00293\n",
      "Epoch 3/30, train_loss: 0.00677, valid_loss: 0.00310\n",
      "Epoch 4/30, train_loss: 0.00602, valid_loss: 0.00299\n",
      "Epoch 5/30, train_loss: 0.00552, valid_loss: 0.00291\n",
      "Epoch 6/30, train_loss: 0.00514, valid_loss: 0.00283\n",
      "Epoch 7/30, train_loss: 0.00485, valid_loss: 0.00276\n",
      "Epoch 8/30, train_loss: 0.00461, valid_loss: 0.00267\n",
      "Epoch 9/30, train_loss: 0.00441, valid_loss: 0.00264\n",
      "Epoch 10/30, train_loss: 0.00423, valid_loss: 0.00256\n",
      "Epoch 11/30, train_loss: 0.00407, valid_loss: 0.00248\n",
      "Epoch 12/30, train_loss: 0.00392, valid_loss: 0.00240\n",
      "Epoch 13/30, train_loss: 0.00379, valid_loss: 0.00233\n",
      "Epoch 14/30, train_loss: 0.00366, valid_loss: 0.00226\n",
      "Epoch 15/30, train_loss: 0.00356, valid_loss: 0.00221\n",
      "Epoch 16/30, train_loss: 0.00346, valid_loss: 0.00216\n",
      "Epoch 17/30, train_loss: 0.00337, valid_loss: 0.00210\n",
      "Epoch 18/30, train_loss: 0.00330, valid_loss: 0.00205\n",
      "Epoch 19/30, train_loss: 0.00322, valid_loss: 0.00206\n",
      "Epoch 20/30, train_loss: 0.00315, valid_loss: 0.00205\n",
      "Epoch 21/30, train_loss: 0.00309, valid_loss: 0.00208\n",
      "Epoch 22/30, train_loss: 0.00302, valid_loss: 0.00205\n",
      "Epoch 23/30, train_loss: 0.00297, valid_loss: 0.00214\n",
      "Epoch 24/30, train_loss: 0.00292, valid_loss: 0.00210\n",
      "Epoch 25/30, train_loss: 0.00287, valid_loss: 0.00208\n",
      "Epoch 26/30, train_loss: 0.00282, valid_loss: 0.00207\n",
      "Epoch 27/30, train_loss: 0.00278, valid_loss: 0.00205\n",
      "Epoch 28/30, train_loss: 0.00274, valid_loss: 0.00206\n",
      "Epoch 29/30, train_loss: 0.00270, valid_loss: 0.00207\n",
      "Epoch 30/30, train_loss: 0.00266, valid_loss: 0.00204\n",
      "At step 13\n",
      "Epoch 1/30, train_loss: 0.01547, valid_loss: 0.00412\n",
      "Epoch 2/30, train_loss: 0.01132, valid_loss: 0.00412\n",
      "Epoch 3/30, train_loss: 0.00954, valid_loss: 0.00406\n",
      "Epoch 4/30, train_loss: 0.00849, valid_loss: 0.00400\n",
      "Epoch 5/30, train_loss: 0.00778, valid_loss: 0.00394\n",
      "Epoch 6/30, train_loss: 0.00726, valid_loss: 0.00396\n",
      "Epoch 7/30, train_loss: 0.00685, valid_loss: 0.00387\n",
      "Epoch 8/30, train_loss: 0.00651, valid_loss: 0.00376\n",
      "Epoch 9/30, train_loss: 0.00621, valid_loss: 0.00366\n",
      "Epoch 10/30, train_loss: 0.00595, valid_loss: 0.00354\n",
      "Epoch 11/30, train_loss: 0.00570, valid_loss: 0.00345\n",
      "Epoch 12/30, train_loss: 0.00549, valid_loss: 0.00334\n",
      "Epoch 13/30, train_loss: 0.00529, valid_loss: 0.00323\n",
      "Epoch 14/30, train_loss: 0.00511, valid_loss: 0.00313\n",
      "Epoch 15/30, train_loss: 0.00495, valid_loss: 0.00304\n",
      "Epoch 16/30, train_loss: 0.00480, valid_loss: 0.00295\n",
      "Epoch 17/30, train_loss: 0.00467, valid_loss: 0.00288\n",
      "Epoch 18/30, train_loss: 0.00455, valid_loss: 0.00284\n",
      "Epoch 19/30, train_loss: 0.00444, valid_loss: 0.00279\n",
      "Epoch 20/30, train_loss: 0.00434, valid_loss: 0.00272\n",
      "Epoch 21/30, train_loss: 0.00424, valid_loss: 0.00266\n",
      "Epoch 22/30, train_loss: 0.00416, valid_loss: 0.00267\n",
      "Epoch 23/30, train_loss: 0.00408, valid_loss: 0.00262\n",
      "Epoch 24/30, train_loss: 0.00400, valid_loss: 0.00261\n",
      "Epoch 25/30, train_loss: 0.00393, valid_loss: 0.00256\n",
      "Epoch 26/30, train_loss: 0.00386, valid_loss: 0.00254\n",
      "Epoch 27/30, train_loss: 0.00380, valid_loss: 0.00252\n",
      "Epoch 28/30, train_loss: 0.00374, valid_loss: 0.00249\n",
      "Epoch 29/30, train_loss: 0.00368, valid_loss: 0.00245\n",
      "Epoch 30/30, train_loss: 0.00363, valid_loss: 0.00242\n",
      "At step 12\n",
      "Epoch 1/30, train_loss: 0.01510, valid_loss: 0.00387\n",
      "Epoch 2/30, train_loss: 0.01100, valid_loss: 0.00385\n",
      "Epoch 3/30, train_loss: 0.00923, valid_loss: 0.00381\n",
      "Epoch 4/30, train_loss: 0.00820, valid_loss: 0.00377\n",
      "Epoch 5/30, train_loss: 0.00751, valid_loss: 0.00374\n",
      "Epoch 6/30, train_loss: 0.00699, valid_loss: 0.00368\n",
      "Epoch 7/30, train_loss: 0.00659, valid_loss: 0.00361\n",
      "Epoch 8/30, train_loss: 0.00626, valid_loss: 0.00354\n",
      "Epoch 9/30, train_loss: 0.00598, valid_loss: 0.00345\n",
      "Epoch 10/30, train_loss: 0.00573, valid_loss: 0.00343\n",
      "Epoch 11/30, train_loss: 0.00551, valid_loss: 0.00333\n",
      "Epoch 12/30, train_loss: 0.00531, valid_loss: 0.00323\n",
      "Epoch 13/30, train_loss: 0.00511, valid_loss: 0.00314\n",
      "Epoch 14/30, train_loss: 0.00494, valid_loss: 0.00305\n",
      "Epoch 15/30, train_loss: 0.00479, valid_loss: 0.00299\n",
      "Epoch 16/30, train_loss: 0.00464, valid_loss: 0.00291\n",
      "Epoch 17/30, train_loss: 0.00452, valid_loss: 0.00284\n",
      "Epoch 18/30, train_loss: 0.00440, valid_loss: 0.00279\n",
      "Epoch 19/30, train_loss: 0.00429, valid_loss: 0.00272\n",
      "Epoch 20/30, train_loss: 0.00419, valid_loss: 0.00266\n",
      "Epoch 21/30, train_loss: 0.00409, valid_loss: 0.00263\n",
      "Epoch 22/30, train_loss: 0.00401, valid_loss: 0.00260\n",
      "Epoch 23/30, train_loss: 0.00393, valid_loss: 0.00255\n",
      "Epoch 24/30, train_loss: 0.00386, valid_loss: 0.00250\n",
      "Epoch 25/30, train_loss: 0.00379, valid_loss: 0.00246\n",
      "Epoch 26/30, train_loss: 0.00372, valid_loss: 0.00242\n",
      "Epoch 27/30, train_loss: 0.00366, valid_loss: 0.00239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, train_loss: 0.00360, valid_loss: 0.00236\n",
      "Epoch 29/30, train_loss: 0.00354, valid_loss: 0.00232\n",
      "Epoch 30/30, train_loss: 0.00349, valid_loss: 0.00230\n",
      "At step 11\n",
      "Epoch 1/30, train_loss: 0.01311, valid_loss: 0.00452\n",
      "Epoch 2/30, train_loss: 0.00977, valid_loss: 0.00449\n",
      "Epoch 3/30, train_loss: 0.00835, valid_loss: 0.00449\n",
      "Epoch 4/30, train_loss: 0.00752, valid_loss: 0.00440\n",
      "Epoch 5/30, train_loss: 0.00696, valid_loss: 0.00433\n",
      "Epoch 6/30, train_loss: 0.00655, valid_loss: 0.00422\n",
      "Epoch 7/30, train_loss: 0.00621, valid_loss: 0.00415\n",
      "Epoch 8/30, train_loss: 0.00592, valid_loss: 0.00413\n",
      "Epoch 9/30, train_loss: 0.00566, valid_loss: 0.00399\n",
      "Epoch 10/30, train_loss: 0.00542, valid_loss: 0.00384\n",
      "Epoch 11/30, train_loss: 0.00520, valid_loss: 0.00370\n",
      "Epoch 12/30, train_loss: 0.00499, valid_loss: 0.00360\n",
      "Epoch 13/30, train_loss: 0.00481, valid_loss: 0.00348\n",
      "Epoch 14/30, train_loss: 0.00465, valid_loss: 0.00338\n",
      "Epoch 15/30, train_loss: 0.00450, valid_loss: 0.00327\n",
      "Epoch 16/30, train_loss: 0.00437, valid_loss: 0.00320\n",
      "Epoch 17/30, train_loss: 0.00425, valid_loss: 0.00312\n",
      "Epoch 18/30, train_loss: 0.00414, valid_loss: 0.00304\n",
      "Epoch 19/30, train_loss: 0.00404, valid_loss: 0.00299\n",
      "Epoch 20/30, train_loss: 0.00395, valid_loss: 0.00293\n",
      "Epoch 21/30, train_loss: 0.00386, valid_loss: 0.00286\n",
      "Epoch 22/30, train_loss: 0.00378, valid_loss: 0.00280\n",
      "Epoch 23/30, train_loss: 0.00370, valid_loss: 0.00274\n",
      "Epoch 24/30, train_loss: 0.00363, valid_loss: 0.00269\n",
      "Epoch 25/30, train_loss: 0.00357, valid_loss: 0.00264\n",
      "Epoch 26/30, train_loss: 0.00351, valid_loss: 0.00265\n",
      "Epoch 27/30, train_loss: 0.00345, valid_loss: 0.00260\n",
      "Epoch 28/30, train_loss: 0.00339, valid_loss: 0.00257\n",
      "Epoch 29/30, train_loss: 0.00334, valid_loss: 0.00255\n",
      "Epoch 30/30, train_loss: 0.00329, valid_loss: 0.00252\n",
      "At step 10\n",
      "Epoch 1/30, train_loss: 0.02298, valid_loss: 0.00458\n",
      "Epoch 2/30, train_loss: 0.01658, valid_loss: 0.00472\n",
      "Epoch 3/30, train_loss: 0.01379, valid_loss: 0.00472\n",
      "Epoch 4/30, train_loss: 0.01215, valid_loss: 0.00466\n",
      "Epoch 5/30, train_loss: 0.01104, valid_loss: 0.00457\n",
      "Epoch 6/30, train_loss: 0.01022, valid_loss: 0.00449\n",
      "Epoch 7/30, train_loss: 0.00959, valid_loss: 0.00441\n",
      "Epoch 8/30, train_loss: 0.00907, valid_loss: 0.00435\n",
      "Epoch 9/30, train_loss: 0.00864, valid_loss: 0.00433\n",
      "Epoch 10/30, train_loss: 0.00827, valid_loss: 0.00422\n",
      "Epoch 11/30, train_loss: 0.00794, valid_loss: 0.00421\n",
      "Epoch 12/30, train_loss: 0.00764, valid_loss: 0.00408\n",
      "Epoch 13/30, train_loss: 0.00737, valid_loss: 0.00396\n",
      "Epoch 14/30, train_loss: 0.00712, valid_loss: 0.00398\n",
      "Epoch 15/30, train_loss: 0.00689, valid_loss: 0.00386\n",
      "Epoch 16/30, train_loss: 0.00668, valid_loss: 0.00375\n",
      "Epoch 17/30, train_loss: 0.00649, valid_loss: 0.00380\n",
      "Epoch 18/30, train_loss: 0.00631, valid_loss: 0.00371\n",
      "Epoch 19/30, train_loss: 0.00615, valid_loss: 0.00362\n",
      "Epoch 20/30, train_loss: 0.00601, valid_loss: 0.00362\n",
      "Epoch 21/30, train_loss: 0.00587, valid_loss: 0.00354\n",
      "Epoch 22/30, train_loss: 0.00574, valid_loss: 0.00349\n",
      "Epoch 23/30, train_loss: 0.00562, valid_loss: 0.00344\n",
      "Epoch 24/30, train_loss: 0.00551, valid_loss: 0.00338\n",
      "Epoch 25/30, train_loss: 0.00541, valid_loss: 0.00332\n",
      "Epoch 26/30, train_loss: 0.00531, valid_loss: 0.00326\n",
      "Epoch 27/30, train_loss: 0.00522, valid_loss: 0.00322\n",
      "Epoch 28/30, train_loss: 0.00513, valid_loss: 0.00319\n",
      "Epoch 29/30, train_loss: 0.00505, valid_loss: 0.00317\n",
      "Epoch 30/30, train_loss: 0.00497, valid_loss: 0.00312\n",
      "At step 9\n",
      "Epoch 1/30, train_loss: 0.01949, valid_loss: 0.00552\n",
      "Epoch 2/30, train_loss: 0.01432, valid_loss: 0.00546\n",
      "Epoch 3/30, train_loss: 0.01210, valid_loss: 0.00566\n",
      "Epoch 4/30, train_loss: 0.01081, valid_loss: 0.00568\n",
      "Epoch 5/30, train_loss: 0.00993, valid_loss: 0.00554\n",
      "Epoch 6/30, train_loss: 0.00929, valid_loss: 0.00541\n",
      "Epoch 7/30, train_loss: 0.00877, valid_loss: 0.00527\n",
      "Epoch 8/30, train_loss: 0.00834, valid_loss: 0.00513\n",
      "Epoch 9/30, train_loss: 0.00796, valid_loss: 0.00496\n",
      "Epoch 10/30, train_loss: 0.00761, valid_loss: 0.00481\n",
      "Epoch 11/30, train_loss: 0.00730, valid_loss: 0.00464\n",
      "Epoch 12/30, train_loss: 0.00702, valid_loss: 0.00447\n",
      "Epoch 13/30, train_loss: 0.00676, valid_loss: 0.00431\n",
      "Epoch 14/30, train_loss: 0.00654, valid_loss: 0.00418\n",
      "Epoch 15/30, train_loss: 0.00633, valid_loss: 0.00405\n",
      "Epoch 16/30, train_loss: 0.00614, valid_loss: 0.00395\n",
      "Epoch 17/30, train_loss: 0.00597, valid_loss: 0.00390\n",
      "Epoch 18/30, train_loss: 0.00582, valid_loss: 0.00380\n",
      "Epoch 19/30, train_loss: 0.00567, valid_loss: 0.00371\n",
      "Epoch 20/30, train_loss: 0.00554, valid_loss: 0.00364\n",
      "Epoch 21/30, train_loss: 0.00542, valid_loss: 0.00362\n",
      "Epoch 22/30, train_loss: 0.00531, valid_loss: 0.00355\n",
      "Epoch 23/30, train_loss: 0.00520, valid_loss: 0.00348\n",
      "Epoch 24/30, train_loss: 0.00510, valid_loss: 0.00341\n",
      "Epoch 25/30, train_loss: 0.00500, valid_loss: 0.00336\n",
      "Epoch 26/30, train_loss: 0.00492, valid_loss: 0.00330\n",
      "Epoch 27/30, train_loss: 0.00483, valid_loss: 0.00326\n",
      "Epoch 28/30, train_loss: 0.00476, valid_loss: 0.00323\n",
      "Epoch 29/30, train_loss: 0.00468, valid_loss: 0.00318\n",
      "Epoch 30/30, train_loss: 0.00461, valid_loss: 0.00313\n",
      "At step 8\n",
      "Epoch 1/30, train_loss: 0.00757, valid_loss: 0.00578\n",
      "Epoch 2/30, train_loss: 0.00652, valid_loss: 0.00524\n",
      "Epoch 3/30, train_loss: 0.00592, valid_loss: 0.00495\n",
      "Epoch 4/30, train_loss: 0.00534, valid_loss: 0.00438\n",
      "Epoch 5/30, train_loss: 0.00486, valid_loss: 0.00396\n",
      "Epoch 6/30, train_loss: 0.00452, valid_loss: 0.00367\n",
      "Epoch 7/30, train_loss: 0.00422, valid_loss: 0.00343\n",
      "Epoch 8/30, train_loss: 0.00401, valid_loss: 0.00324\n",
      "Epoch 9/30, train_loss: 0.00382, valid_loss: 0.00307\n",
      "Epoch 10/30, train_loss: 0.00365, valid_loss: 0.00296\n",
      "Epoch 11/30, train_loss: 0.00351, valid_loss: 0.00285\n",
      "Epoch 12/30, train_loss: 0.00338, valid_loss: 0.00275\n",
      "Epoch 13/30, train_loss: 0.00330, valid_loss: 0.00269\n",
      "Epoch 14/30, train_loss: 0.00321, valid_loss: 0.00261\n",
      "Epoch 15/30, train_loss: 0.00312, valid_loss: 0.00256\n",
      "Epoch 16/30, train_loss: 0.00304, valid_loss: 0.00248\n",
      "Epoch 17/30, train_loss: 0.00296, valid_loss: 0.00242\n",
      "Epoch 18/30, train_loss: 0.00289, valid_loss: 0.00236\n",
      "Epoch 19/30, train_loss: 0.00283, valid_loss: 0.00236\n",
      "Epoch 20/30, train_loss: 0.00277, valid_loss: 0.00231\n",
      "Epoch 21/30, train_loss: 0.00271, valid_loss: 0.00226\n",
      "Epoch 22/30, train_loss: 0.00266, valid_loss: 0.00223\n",
      "Epoch 23/30, train_loss: 0.00262, valid_loss: 0.00221\n",
      "Epoch 24/30, train_loss: 0.00257, valid_loss: 0.00217\n",
      "Epoch 25/30, train_loss: 0.00253, valid_loss: 0.00213\n",
      "Epoch 26/30, train_loss: 0.00248, valid_loss: 0.00210\n",
      "Epoch 27/30, train_loss: 0.00244, valid_loss: 0.00207\n",
      "Epoch 28/30, train_loss: 0.00241, valid_loss: 0.00203\n",
      "Epoch 29/30, train_loss: 0.00237, valid_loss: 0.00200\n",
      "Epoch 30/30, train_loss: 0.00234, valid_loss: 0.00197\n",
      "At step 7\n",
      "Epoch 1/30, train_loss: 0.01202, valid_loss: 0.00539\n",
      "Epoch 2/30, train_loss: 0.00922, valid_loss: 0.00521\n",
      "Epoch 3/30, train_loss: 0.00802, valid_loss: 0.00508\n",
      "Epoch 4/30, train_loss: 0.00724, valid_loss: 0.00476\n",
      "Epoch 5/30, train_loss: 0.00664, valid_loss: 0.00441\n",
      "Epoch 6/30, train_loss: 0.00613, valid_loss: 0.00410\n",
      "Epoch 7/30, train_loss: 0.00571, valid_loss: 0.00385\n",
      "Epoch 8/30, train_loss: 0.00537, valid_loss: 0.00365\n",
      "Epoch 9/30, train_loss: 0.00509, valid_loss: 0.00353\n",
      "Epoch 10/30, train_loss: 0.00486, valid_loss: 0.00337\n",
      "Epoch 11/30, train_loss: 0.00466, valid_loss: 0.00327\n",
      "Epoch 12/30, train_loss: 0.00448, valid_loss: 0.00322\n",
      "Epoch 13/30, train_loss: 0.00432, valid_loss: 0.00312\n",
      "Epoch 14/30, train_loss: 0.00419, valid_loss: 0.00301\n",
      "Epoch 15/30, train_loss: 0.00409, valid_loss: 0.00294\n",
      "Epoch 16/30, train_loss: 0.00397, valid_loss: 0.00286\n",
      "Epoch 17/30, train_loss: 0.00386, valid_loss: 0.00281\n",
      "Epoch 18/30, train_loss: 0.00377, valid_loss: 0.00274\n",
      "Epoch 19/30, train_loss: 0.00368, valid_loss: 0.00267\n",
      "Epoch 20/30, train_loss: 0.00359, valid_loss: 0.00261\n",
      "Epoch 21/30, train_loss: 0.00352, valid_loss: 0.00256\n",
      "Epoch 22/30, train_loss: 0.00344, valid_loss: 0.00252\n",
      "Epoch 23/30, train_loss: 0.00338, valid_loss: 0.00247\n",
      "Epoch 24/30, train_loss: 0.00332, valid_loss: 0.00244\n",
      "Epoch 25/30, train_loss: 0.00326, valid_loss: 0.00239\n",
      "Epoch 26/30, train_loss: 0.00320, valid_loss: 0.00235\n",
      "Epoch 27/30, train_loss: 0.00315, valid_loss: 0.00231\n",
      "Epoch 28/30, train_loss: 0.00310, valid_loss: 0.00227\n",
      "Epoch 29/30, train_loss: 0.00306, valid_loss: 0.00225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, train_loss: 0.00301, valid_loss: 0.00221\n",
      "At step 6\n",
      "Epoch 1/30, train_loss: 0.01401, valid_loss: 0.00615\n",
      "Epoch 2/30, train_loss: 0.01081, valid_loss: 0.00601\n",
      "Epoch 3/30, train_loss: 0.00942, valid_loss: 0.00577\n",
      "Epoch 4/30, train_loss: 0.00854, valid_loss: 0.00545\n",
      "Epoch 5/30, train_loss: 0.00785, valid_loss: 0.00509\n",
      "Epoch 6/30, train_loss: 0.00726, valid_loss: 0.00474\n",
      "Epoch 7/30, train_loss: 0.00677, valid_loss: 0.00443\n",
      "Epoch 8/30, train_loss: 0.00636, valid_loss: 0.00417\n",
      "Epoch 9/30, train_loss: 0.00602, valid_loss: 0.00395\n",
      "Epoch 10/30, train_loss: 0.00574, valid_loss: 0.00377\n",
      "Epoch 11/30, train_loss: 0.00549, valid_loss: 0.00366\n",
      "Epoch 12/30, train_loss: 0.00528, valid_loss: 0.00353\n",
      "Epoch 13/30, train_loss: 0.00509, valid_loss: 0.00341\n",
      "Epoch 14/30, train_loss: 0.00492, valid_loss: 0.00330\n",
      "Epoch 15/30, train_loss: 0.00477, valid_loss: 0.00320\n",
      "Epoch 16/30, train_loss: 0.00463, valid_loss: 0.00311\n",
      "Epoch 17/30, train_loss: 0.00450, valid_loss: 0.00302\n",
      "Epoch 18/30, train_loss: 0.00439, valid_loss: 0.00295\n",
      "Epoch 19/30, train_loss: 0.00428, valid_loss: 0.00287\n",
      "Epoch 20/30, train_loss: 0.00418, valid_loss: 0.00281\n",
      "Epoch 21/30, train_loss: 0.00409, valid_loss: 0.00274\n",
      "Epoch 22/30, train_loss: 0.00401, valid_loss: 0.00269\n",
      "Epoch 23/30, train_loss: 0.00393, valid_loss: 0.00264\n",
      "Epoch 24/30, train_loss: 0.00387, valid_loss: 0.00259\n",
      "Epoch 25/30, train_loss: 0.00380, valid_loss: 0.00255\n",
      "Epoch 26/30, train_loss: 0.00373, valid_loss: 0.00250\n",
      "Epoch 27/30, train_loss: 0.00367, valid_loss: 0.00247\n",
      "Epoch 28/30, train_loss: 0.00361, valid_loss: 0.00242\n",
      "Epoch 29/30, train_loss: 0.00356, valid_loss: 0.00239\n",
      "Epoch 30/30, train_loss: 0.00350, valid_loss: 0.00236\n",
      "At step 5\n",
      "Epoch 1/30, train_loss: 0.01515, valid_loss: 0.00609\n",
      "Epoch 2/30, train_loss: 0.01155, valid_loss: 0.00600\n",
      "Epoch 3/30, train_loss: 0.01001, valid_loss: 0.00575\n",
      "Epoch 4/30, train_loss: 0.00906, valid_loss: 0.00548\n",
      "Epoch 5/30, train_loss: 0.00832, valid_loss: 0.00511\n",
      "Epoch 6/30, train_loss: 0.00768, valid_loss: 0.00473\n",
      "Epoch 7/30, train_loss: 0.00713, valid_loss: 0.00442\n",
      "Epoch 8/30, train_loss: 0.00669, valid_loss: 0.00416\n",
      "Epoch 9/30, train_loss: 0.00633, valid_loss: 0.00394\n",
      "Epoch 10/30, train_loss: 0.00603, valid_loss: 0.00376\n",
      "Epoch 11/30, train_loss: 0.00577, valid_loss: 0.00361\n",
      "Epoch 12/30, train_loss: 0.00554, valid_loss: 0.00351\n",
      "Epoch 13/30, train_loss: 0.00533, valid_loss: 0.00339\n",
      "Epoch 14/30, train_loss: 0.00516, valid_loss: 0.00328\n",
      "Epoch 15/30, train_loss: 0.00499, valid_loss: 0.00318\n",
      "Epoch 16/30, train_loss: 0.00485, valid_loss: 0.00308\n",
      "Epoch 17/30, train_loss: 0.00472, valid_loss: 0.00300\n",
      "Epoch 18/30, train_loss: 0.00460, valid_loss: 0.00292\n",
      "Epoch 19/30, train_loss: 0.00449, valid_loss: 0.00285\n",
      "Epoch 20/30, train_loss: 0.00438, valid_loss: 0.00280\n",
      "Epoch 21/30, train_loss: 0.00428, valid_loss: 0.00275\n",
      "Epoch 22/30, train_loss: 0.00419, valid_loss: 0.00269\n",
      "Epoch 23/30, train_loss: 0.00411, valid_loss: 0.00264\n",
      "Epoch 24/30, train_loss: 0.00403, valid_loss: 0.00259\n",
      "Epoch 25/30, train_loss: 0.00396, valid_loss: 0.00254\n",
      "Epoch 26/30, train_loss: 0.00389, valid_loss: 0.00251\n",
      "Epoch 27/30, train_loss: 0.00382, valid_loss: 0.00247\n",
      "Epoch 28/30, train_loss: 0.00376, valid_loss: 0.00243\n",
      "Epoch 29/30, train_loss: 0.00370, valid_loss: 0.00239\n",
      "Epoch 30/30, train_loss: 0.00364, valid_loss: 0.00235\n",
      "At step 4\n",
      "Epoch 1/30, train_loss: 0.00933, valid_loss: 0.00592\n",
      "Epoch 2/30, train_loss: 0.00766, valid_loss: 0.00542\n",
      "Epoch 3/30, train_loss: 0.00660, valid_loss: 0.00458\n",
      "Epoch 4/30, train_loss: 0.00579, valid_loss: 0.00401\n",
      "Epoch 5/30, train_loss: 0.00524, valid_loss: 0.00364\n",
      "Epoch 6/30, train_loss: 0.00482, valid_loss: 0.00340\n",
      "Epoch 7/30, train_loss: 0.00450, valid_loss: 0.00320\n",
      "Epoch 8/30, train_loss: 0.00424, valid_loss: 0.00302\n",
      "Epoch 9/30, train_loss: 0.00403, valid_loss: 0.00307\n",
      "Epoch 10/30, train_loss: 0.00385, valid_loss: 0.00293\n",
      "Epoch 11/30, train_loss: 0.00369, valid_loss: 0.00280\n",
      "Epoch 12/30, train_loss: 0.00356, valid_loss: 0.00272\n",
      "Epoch 13/30, train_loss: 0.00343, valid_loss: 0.00262\n",
      "Epoch 14/30, train_loss: 0.00332, valid_loss: 0.00253\n",
      "Epoch 15/30, train_loss: 0.00322, valid_loss: 0.00247\n",
      "Epoch 16/30, train_loss: 0.00313, valid_loss: 0.00243\n",
      "Epoch 17/30, train_loss: 0.00305, valid_loss: 0.00238\n",
      "Epoch 18/30, train_loss: 0.00297, valid_loss: 0.00231\n",
      "Epoch 19/30, train_loss: 0.00290, valid_loss: 0.00227\n",
      "Epoch 20/30, train_loss: 0.00284, valid_loss: 0.00221\n",
      "Epoch 21/30, train_loss: 0.00278, valid_loss: 0.00217\n",
      "Epoch 22/30, train_loss: 0.00272, valid_loss: 0.00212\n",
      "Epoch 23/30, train_loss: 0.00267, valid_loss: 0.00209\n",
      "Epoch 24/30, train_loss: 0.00262, valid_loss: 0.00207\n",
      "Epoch 25/30, train_loss: 0.00257, valid_loss: 0.00203\n",
      "Epoch 26/30, train_loss: 0.00253, valid_loss: 0.00199\n",
      "Epoch 27/30, train_loss: 0.00249, valid_loss: 0.00196\n",
      "Epoch 28/30, train_loss: 0.00245, valid_loss: 0.00193\n",
      "Epoch 29/30, train_loss: 0.00241, valid_loss: 0.00191\n",
      "Epoch 30/30, train_loss: 0.00237, valid_loss: 0.00188\n",
      "At step 3\n",
      "Epoch 1/30, train_loss: 0.00770, valid_loss: 0.00592\n",
      "Epoch 2/30, train_loss: 0.00635, valid_loss: 0.00451\n",
      "Epoch 3/30, train_loss: 0.00534, valid_loss: 0.00376\n",
      "Epoch 4/30, train_loss: 0.00470, valid_loss: 0.00330\n",
      "Epoch 5/30, train_loss: 0.00427, valid_loss: 0.00300\n",
      "Epoch 6/30, train_loss: 0.00395, valid_loss: 0.00278\n",
      "Epoch 7/30, train_loss: 0.00370, valid_loss: 0.00259\n",
      "Epoch 8/30, train_loss: 0.00350, valid_loss: 0.00257\n",
      "Epoch 9/30, train_loss: 0.00332, valid_loss: 0.00244\n",
      "Epoch 10/30, train_loss: 0.00318, valid_loss: 0.00234\n",
      "Epoch 11/30, train_loss: 0.00305, valid_loss: 0.00229\n",
      "Epoch 12/30, train_loss: 0.00295, valid_loss: 0.00226\n",
      "Epoch 13/30, train_loss: 0.00285, valid_loss: 0.00218\n",
      "Epoch 14/30, train_loss: 0.00277, valid_loss: 0.00210\n",
      "Epoch 15/30, train_loss: 0.00269, valid_loss: 0.00204\n",
      "Epoch 16/30, train_loss: 0.00261, valid_loss: 0.00199\n",
      "Epoch 17/30, train_loss: 0.00254, valid_loss: 0.00193\n",
      "Epoch 18/30, train_loss: 0.00248, valid_loss: 0.00188\n",
      "Epoch 19/30, train_loss: 0.00243, valid_loss: 0.00184\n",
      "Epoch 20/30, train_loss: 0.00238, valid_loss: 0.00180\n",
      "Epoch 21/30, train_loss: 0.00233, valid_loss: 0.00176\n",
      "Epoch 22/30, train_loss: 0.00228, valid_loss: 0.00172\n",
      "Epoch 23/30, train_loss: 0.00224, valid_loss: 0.00169\n",
      "Epoch 24/30, train_loss: 0.00220, valid_loss: 0.00166\n",
      "Epoch 25/30, train_loss: 0.00216, valid_loss: 0.00163\n",
      "Epoch 26/30, train_loss: 0.00212, valid_loss: 0.00161\n",
      "Epoch 27/30, train_loss: 0.00209, valid_loss: 0.00158\n",
      "Epoch 28/30, train_loss: 0.00205, valid_loss: 0.00156\n",
      "Epoch 29/30, train_loss: 0.00202, valid_loss: 0.00154\n",
      "Epoch 30/30, train_loss: 0.00199, valid_loss: 0.00153\n",
      "At step 2\n",
      "Epoch 1/30, train_loss: 0.00806, valid_loss: 0.00540\n",
      "Epoch 2/30, train_loss: 0.00654, valid_loss: 0.00471\n",
      "Epoch 3/30, train_loss: 0.00549, valid_loss: 0.00393\n",
      "Epoch 4/30, train_loss: 0.00484, valid_loss: 0.00347\n",
      "Epoch 5/30, train_loss: 0.00439, valid_loss: 0.00315\n",
      "Epoch 6/30, train_loss: 0.00406, valid_loss: 0.00299\n",
      "Epoch 7/30, train_loss: 0.00381, valid_loss: 0.00280\n",
      "Epoch 8/30, train_loss: 0.00360, valid_loss: 0.00267\n",
      "Epoch 9/30, train_loss: 0.00342, valid_loss: 0.00255\n",
      "Epoch 10/30, train_loss: 0.00328, valid_loss: 0.00251\n",
      "Epoch 11/30, train_loss: 0.00315, valid_loss: 0.00240\n",
      "Epoch 12/30, train_loss: 0.00304, valid_loss: 0.00238\n",
      "Epoch 13/30, train_loss: 0.00294, valid_loss: 0.00230\n",
      "Epoch 14/30, train_loss: 0.00286, valid_loss: 0.00223\n",
      "Epoch 15/30, train_loss: 0.00277, valid_loss: 0.00218\n",
      "Epoch 16/30, train_loss: 0.00270, valid_loss: 0.00211\n",
      "Epoch 17/30, train_loss: 0.00263, valid_loss: 0.00205\n",
      "Epoch 18/30, train_loss: 0.00257, valid_loss: 0.00200\n",
      "Epoch 19/30, train_loss: 0.00251, valid_loss: 0.00195\n",
      "Epoch 20/30, train_loss: 0.00245, valid_loss: 0.00192\n",
      "Epoch 21/30, train_loss: 0.00240, valid_loss: 0.00188\n",
      "Epoch 22/30, train_loss: 0.00236, valid_loss: 0.00184\n",
      "Epoch 23/30, train_loss: 0.00231, valid_loss: 0.00181\n",
      "Epoch 24/30, train_loss: 0.00227, valid_loss: 0.00177\n",
      "Epoch 25/30, train_loss: 0.00223, valid_loss: 0.00174\n",
      "Epoch 26/30, train_loss: 0.00219, valid_loss: 0.00171\n",
      "Epoch 27/30, train_loss: 0.00216, valid_loss: 0.00168\n",
      "Epoch 28/30, train_loss: 0.00213, valid_loss: 0.00167\n",
      "Epoch 29/30, train_loss: 0.00209, valid_loss: 0.00164\n",
      "Epoch 30/30, train_loss: 0.00206, valid_loss: 0.00162\n",
      "At step 18\n",
      "Epoch 1/30, train_loss: 0.00677, valid_loss: 0.00073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, train_loss: 0.00481, valid_loss: 0.00069\n",
      "Epoch 3/30, train_loss: 0.00395, valid_loss: 0.00069\n",
      "Epoch 4/30, train_loss: 0.00344, valid_loss: 0.00068\n",
      "Epoch 5/30, train_loss: 0.00309, valid_loss: 0.00070\n",
      "Epoch 6/30, train_loss: 0.00284, valid_loss: 0.00072\n",
      "Epoch 7/30, train_loss: 0.00268, valid_loss: 0.00070\n",
      "Epoch 8/30, train_loss: 0.00252, valid_loss: 0.00076\n",
      "Epoch 9/30, train_loss: 0.00239, valid_loss: 0.00083\n",
      "Epoch 10/30, train_loss: 0.00228, valid_loss: 0.00081\n",
      "Epoch 11/30, train_loss: 0.00219, valid_loss: 0.00081\n",
      "Epoch 12/30, train_loss: 0.00211, valid_loss: 0.00079\n",
      "Epoch 13/30, train_loss: 0.00205, valid_loss: 0.00087\n",
      "Epoch 14/30, train_loss: 0.00199, valid_loss: 0.00085\n",
      "Epoch 15/30, train_loss: 0.00193, valid_loss: 0.00087\n",
      "Epoch 16/30, train_loss: 0.00194, valid_loss: 0.00085\n",
      "Epoch 17/30, train_loss: 0.00189, valid_loss: 0.00083\n",
      "Epoch 18/30, train_loss: 0.00184, valid_loss: 0.00082\n",
      "Epoch 19/30, train_loss: 0.00179, valid_loss: 0.00081\n",
      "Epoch 20/30, train_loss: 0.00175, valid_loss: 0.00080\n",
      "Epoch 21/30, train_loss: 0.00171, valid_loss: 0.00078\n",
      "Epoch 22/30, train_loss: 0.00168, valid_loss: 0.00078\n",
      "Epoch 23/30, train_loss: 0.00165, valid_loss: 0.00076\n",
      "Epoch 24/30, train_loss: 0.00162, valid_loss: 0.00075\n",
      "Epoch 25/30, train_loss: 0.00159, valid_loss: 0.00074\n",
      "Epoch 26/30, train_loss: 0.00156, valid_loss: 0.00074\n",
      "Epoch 27/30, train_loss: 0.00153, valid_loss: 0.00073\n",
      "Epoch 28/30, train_loss: 0.00151, valid_loss: 0.00072\n",
      "Epoch 29/30, train_loss: 0.00149, valid_loss: 0.00071\n",
      "Epoch 30/30, train_loss: 0.00147, valid_loss: 0.00070\n",
      "At step 17\n",
      "Epoch 1/30, train_loss: 0.00467, valid_loss: 0.00133\n",
      "Epoch 2/30, train_loss: 0.00345, valid_loss: 0.00137\n",
      "Epoch 3/30, train_loss: 0.00292, valid_loss: 0.00133\n",
      "Epoch 4/30, train_loss: 0.00263, valid_loss: 0.00134\n",
      "Epoch 5/30, train_loss: 0.00245, valid_loss: 0.00130\n",
      "Epoch 6/30, train_loss: 0.00231, valid_loss: 0.00126\n",
      "Epoch 7/30, train_loss: 0.00220, valid_loss: 0.00127\n",
      "Epoch 8/30, train_loss: 0.00211, valid_loss: 0.00139\n",
      "Epoch 9/30, train_loss: 0.00204, valid_loss: 0.00140\n",
      "Epoch 10/30, train_loss: 0.00197, valid_loss: 0.00138\n",
      "Epoch 11/30, train_loss: 0.00196, valid_loss: 0.00134\n",
      "Epoch 12/30, train_loss: 0.00189, valid_loss: 0.00132\n",
      "Epoch 13/30, train_loss: 0.00184, valid_loss: 0.00129\n",
      "Epoch 14/30, train_loss: 0.00178, valid_loss: 0.00131\n",
      "Epoch 15/30, train_loss: 0.00173, valid_loss: 0.00128\n",
      "Epoch 16/30, train_loss: 0.00169, valid_loss: 0.00125\n",
      "Epoch 17/30, train_loss: 0.00165, valid_loss: 0.00122\n",
      "Epoch 18/30, train_loss: 0.00162, valid_loss: 0.00119\n",
      "Epoch 19/30, train_loss: 0.00158, valid_loss: 0.00116\n",
      "Epoch 20/30, train_loss: 0.00155, valid_loss: 0.00115\n",
      "Epoch 21/30, train_loss: 0.00152, valid_loss: 0.00113\n",
      "Epoch 22/30, train_loss: 0.00149, valid_loss: 0.00113\n",
      "Epoch 23/30, train_loss: 0.00147, valid_loss: 0.00111\n",
      "Epoch 24/30, train_loss: 0.00144, valid_loss: 0.00110\n",
      "Epoch 25/30, train_loss: 0.00142, valid_loss: 0.00108\n",
      "Epoch 26/30, train_loss: 0.00140, valid_loss: 0.00108\n",
      "Epoch 27/30, train_loss: 0.00138, valid_loss: 0.00107\n",
      "Epoch 28/30, train_loss: 0.00136, valid_loss: 0.00106\n",
      "Epoch 29/30, train_loss: 0.00134, valid_loss: 0.00105\n",
      "Epoch 30/30, train_loss: 0.00132, valid_loss: 0.00103\n",
      "At step 16\n",
      "Epoch 1/30, train_loss: 0.00762, valid_loss: 0.00190\n",
      "Epoch 2/30, train_loss: 0.00556, valid_loss: 0.00189\n",
      "Epoch 3/30, train_loss: 0.00466, valid_loss: 0.00187\n",
      "Epoch 4/30, train_loss: 0.00414, valid_loss: 0.00194\n",
      "Epoch 5/30, train_loss: 0.00379, valid_loss: 0.00198\n",
      "Epoch 6/30, train_loss: 0.00352, valid_loss: 0.00202\n",
      "Epoch 7/30, train_loss: 0.00332, valid_loss: 0.00192\n",
      "Epoch 8/30, train_loss: 0.00314, valid_loss: 0.00183\n",
      "Epoch 9/30, train_loss: 0.00300, valid_loss: 0.00185\n",
      "Epoch 10/30, train_loss: 0.00288, valid_loss: 0.00177\n",
      "Epoch 11/30, train_loss: 0.00277, valid_loss: 0.00189\n",
      "Epoch 12/30, train_loss: 0.00267, valid_loss: 0.00182\n",
      "Epoch 13/30, train_loss: 0.00259, valid_loss: 0.00175\n",
      "Epoch 14/30, train_loss: 0.00251, valid_loss: 0.00173\n",
      "Epoch 15/30, train_loss: 0.00244, valid_loss: 0.00168\n",
      "Epoch 16/30, train_loss: 0.00238, valid_loss: 0.00169\n",
      "Epoch 17/30, train_loss: 0.00232, valid_loss: 0.00166\n",
      "Epoch 18/30, train_loss: 0.00226, valid_loss: 0.00162\n",
      "Epoch 19/30, train_loss: 0.00221, valid_loss: 0.00159\n",
      "Epoch 20/30, train_loss: 0.00217, valid_loss: 0.00155\n",
      "Epoch 21/30, train_loss: 0.00212, valid_loss: 0.00153\n",
      "Epoch 22/30, train_loss: 0.00210, valid_loss: 0.00151\n",
      "Epoch 23/30, train_loss: 0.00206, valid_loss: 0.00148\n",
      "Epoch 24/30, train_loss: 0.00202, valid_loss: 0.00146\n",
      "Epoch 25/30, train_loss: 0.00199, valid_loss: 0.00143\n",
      "Epoch 26/30, train_loss: 0.00195, valid_loss: 0.00141\n",
      "Epoch 27/30, train_loss: 0.00192, valid_loss: 0.00139\n",
      "Epoch 28/30, train_loss: 0.00189, valid_loss: 0.00136\n",
      "Epoch 29/30, train_loss: 0.00187, valid_loss: 0.00134\n",
      "Epoch 30/30, train_loss: 0.00184, valid_loss: 0.00132\n",
      "At step 15\n",
      "Epoch 1/30, train_loss: 0.01035, valid_loss: 0.00294\n",
      "Epoch 2/30, train_loss: 0.00758, valid_loss: 0.00285\n",
      "Epoch 3/30, train_loss: 0.00638, valid_loss: 0.00282\n",
      "Epoch 4/30, train_loss: 0.00567, valid_loss: 0.00275\n",
      "Epoch 5/30, train_loss: 0.00519, valid_loss: 0.00267\n",
      "Epoch 6/30, train_loss: 0.00482, valid_loss: 0.00260\n",
      "Epoch 7/30, train_loss: 0.00452, valid_loss: 0.00251\n",
      "Epoch 8/30, train_loss: 0.00427, valid_loss: 0.00241\n",
      "Epoch 9/30, train_loss: 0.00405, valid_loss: 0.00230\n",
      "Epoch 10/30, train_loss: 0.00385, valid_loss: 0.00219\n",
      "Epoch 11/30, train_loss: 0.00367, valid_loss: 0.00212\n",
      "Epoch 12/30, train_loss: 0.00353, valid_loss: 0.00205\n",
      "Epoch 13/30, train_loss: 0.00340, valid_loss: 0.00197\n",
      "Epoch 14/30, train_loss: 0.00328, valid_loss: 0.00191\n",
      "Epoch 15/30, train_loss: 0.00318, valid_loss: 0.00186\n",
      "Epoch 16/30, train_loss: 0.00308, valid_loss: 0.00181\n",
      "Epoch 17/30, train_loss: 0.00300, valid_loss: 0.00176\n",
      "Epoch 18/30, train_loss: 0.00292, valid_loss: 0.00173\n",
      "Epoch 19/30, train_loss: 0.00285, valid_loss: 0.00169\n",
      "Epoch 20/30, train_loss: 0.00278, valid_loss: 0.00165\n",
      "Epoch 21/30, train_loss: 0.00272, valid_loss: 0.00162\n",
      "Epoch 22/30, train_loss: 0.00266, valid_loss: 0.00160\n",
      "Epoch 23/30, train_loss: 0.00261, valid_loss: 0.00156\n",
      "Epoch 24/30, train_loss: 0.00256, valid_loss: 0.00155\n",
      "Epoch 25/30, train_loss: 0.00251, valid_loss: 0.00152\n",
      "Epoch 26/30, train_loss: 0.00246, valid_loss: 0.00149\n",
      "Epoch 27/30, train_loss: 0.00242, valid_loss: 0.00146\n",
      "Epoch 28/30, train_loss: 0.00238, valid_loss: 0.00144\n",
      "Epoch 29/30, train_loss: 0.00234, valid_loss: 0.00142\n",
      "Epoch 30/30, train_loss: 0.00230, valid_loss: 0.00140\n",
      "At step 14\n",
      "Epoch 1/30, train_loss: 0.01568, valid_loss: 0.00308\n",
      "Epoch 2/30, train_loss: 0.01130, valid_loss: 0.00304\n",
      "Epoch 3/30, train_loss: 0.00939, valid_loss: 0.00306\n",
      "Epoch 4/30, train_loss: 0.00826, valid_loss: 0.00303\n",
      "Epoch 5/30, train_loss: 0.00749, valid_loss: 0.00294\n",
      "Epoch 6/30, train_loss: 0.00691, valid_loss: 0.00285\n",
      "Epoch 7/30, train_loss: 0.00646, valid_loss: 0.00275\n",
      "Epoch 8/30, train_loss: 0.00609, valid_loss: 0.00263\n",
      "Epoch 9/30, train_loss: 0.00577, valid_loss: 0.00255\n",
      "Epoch 10/30, train_loss: 0.00549, valid_loss: 0.00245\n",
      "Epoch 11/30, train_loss: 0.00524, valid_loss: 0.00239\n",
      "Epoch 12/30, train_loss: 0.00502, valid_loss: 0.00232\n",
      "Epoch 13/30, train_loss: 0.00483, valid_loss: 0.00223\n",
      "Epoch 14/30, train_loss: 0.00467, valid_loss: 0.00217\n",
      "Epoch 15/30, train_loss: 0.00452, valid_loss: 0.00210\n",
      "Epoch 16/30, train_loss: 0.00438, valid_loss: 0.00205\n",
      "Epoch 17/30, train_loss: 0.00426, valid_loss: 0.00203\n",
      "Epoch 18/30, train_loss: 0.00414, valid_loss: 0.00198\n",
      "Epoch 19/30, train_loss: 0.00404, valid_loss: 0.00196\n",
      "Epoch 20/30, train_loss: 0.00394, valid_loss: 0.00192\n",
      "Epoch 21/30, train_loss: 0.00385, valid_loss: 0.00188\n",
      "Epoch 22/30, train_loss: 0.00377, valid_loss: 0.00185\n",
      "Epoch 23/30, train_loss: 0.00369, valid_loss: 0.00183\n",
      "Epoch 24/30, train_loss: 0.00362, valid_loss: 0.00180\n",
      "Epoch 25/30, train_loss: 0.00355, valid_loss: 0.00177\n",
      "Epoch 26/30, train_loss: 0.00349, valid_loss: 0.00174\n",
      "Epoch 27/30, train_loss: 0.00342, valid_loss: 0.00171\n",
      "Epoch 28/30, train_loss: 0.00337, valid_loss: 0.00169\n",
      "Epoch 29/30, train_loss: 0.00331, valid_loss: 0.00167\n",
      "Epoch 30/30, train_loss: 0.00326, valid_loss: 0.00164\n",
      "At step 13\n",
      "Epoch 1/30, train_loss: 0.00488, valid_loss: 0.00388\n",
      "Epoch 2/30, train_loss: 0.00414, valid_loss: 0.00337\n",
      "Epoch 3/30, train_loss: 0.00365, valid_loss: 0.00304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, train_loss: 0.00328, valid_loss: 0.00274\n",
      "Epoch 5/30, train_loss: 0.00300, valid_loss: 0.00255\n",
      "Epoch 6/30, train_loss: 0.00279, valid_loss: 0.00235\n",
      "Epoch 7/30, train_loss: 0.00262, valid_loss: 0.00219\n",
      "Epoch 8/30, train_loss: 0.00249, valid_loss: 0.00210\n",
      "Epoch 9/30, train_loss: 0.00238, valid_loss: 0.00199\n",
      "Epoch 10/30, train_loss: 0.00228, valid_loss: 0.00190\n",
      "Epoch 11/30, train_loss: 0.00220, valid_loss: 0.00184\n",
      "Epoch 12/30, train_loss: 0.00213, valid_loss: 0.00178\n",
      "Epoch 13/30, train_loss: 0.00206, valid_loss: 0.00175\n",
      "Epoch 14/30, train_loss: 0.00201, valid_loss: 0.00169\n",
      "Epoch 15/30, train_loss: 0.00196, valid_loss: 0.00164\n",
      "Epoch 16/30, train_loss: 0.00191, valid_loss: 0.00159\n",
      "Epoch 17/30, train_loss: 0.00186, valid_loss: 0.00155\n",
      "Epoch 18/30, train_loss: 0.00183, valid_loss: 0.00154\n",
      "Epoch 19/30, train_loss: 0.00179, valid_loss: 0.00151\n",
      "Epoch 20/30, train_loss: 0.00175, valid_loss: 0.00148\n",
      "Epoch 21/30, train_loss: 0.00172, valid_loss: 0.00145\n",
      "Epoch 22/30, train_loss: 0.00169, valid_loss: 0.00142\n",
      "Epoch 23/30, train_loss: 0.00166, valid_loss: 0.00142\n",
      "Epoch 24/30, train_loss: 0.00163, valid_loss: 0.00139\n",
      "Epoch 25/30, train_loss: 0.00161, valid_loss: 0.00137\n",
      "Epoch 26/30, train_loss: 0.00158, valid_loss: 0.00135\n",
      "Epoch 27/30, train_loss: 0.00156, valid_loss: 0.00133\n",
      "Epoch 28/30, train_loss: 0.00153, valid_loss: 0.00132\n",
      "Epoch 29/30, train_loss: 0.00151, valid_loss: 0.00130\n",
      "Epoch 30/30, train_loss: 0.00149, valid_loss: 0.00128\n",
      "At step 12\n",
      "Epoch 1/30, train_loss: 0.00822, valid_loss: 0.00406\n",
      "Epoch 2/30, train_loss: 0.00636, valid_loss: 0.00370\n",
      "Epoch 3/30, train_loss: 0.00550, valid_loss: 0.00338\n",
      "Epoch 4/30, train_loss: 0.00489, valid_loss: 0.00357\n",
      "Epoch 5/30, train_loss: 0.00443, valid_loss: 0.00325\n",
      "Epoch 6/30, train_loss: 0.00410, valid_loss: 0.00301\n",
      "Epoch 7/30, train_loss: 0.00383, valid_loss: 0.00297\n",
      "Epoch 8/30, train_loss: 0.00362, valid_loss: 0.00279\n",
      "Epoch 9/30, train_loss: 0.00345, valid_loss: 0.00265\n",
      "Epoch 10/30, train_loss: 0.00330, valid_loss: 0.00252\n",
      "Epoch 11/30, train_loss: 0.00317, valid_loss: 0.00244\n",
      "Epoch 12/30, train_loss: 0.00306, valid_loss: 0.00235\n",
      "Epoch 13/30, train_loss: 0.00296, valid_loss: 0.00227\n",
      "Epoch 14/30, train_loss: 0.00287, valid_loss: 0.00219\n",
      "Epoch 15/30, train_loss: 0.00279, valid_loss: 0.00213\n",
      "Epoch 16/30, train_loss: 0.00272, valid_loss: 0.00207\n",
      "Epoch 17/30, train_loss: 0.00265, valid_loss: 0.00201\n",
      "Epoch 18/30, train_loss: 0.00261, valid_loss: 0.00196\n",
      "Epoch 19/30, train_loss: 0.00256, valid_loss: 0.00195\n",
      "Epoch 20/30, train_loss: 0.00250, valid_loss: 0.00190\n",
      "Epoch 21/30, train_loss: 0.00245, valid_loss: 0.00187\n",
      "Epoch 22/30, train_loss: 0.00241, valid_loss: 0.00183\n",
      "Epoch 23/30, train_loss: 0.00236, valid_loss: 0.00179\n",
      "Epoch 24/30, train_loss: 0.00232, valid_loss: 0.00175\n",
      "Epoch 25/30, train_loss: 0.00228, valid_loss: 0.00172\n",
      "Epoch 26/30, train_loss: 0.00224, valid_loss: 0.00169\n",
      "Epoch 27/30, train_loss: 0.00220, valid_loss: 0.00166\n",
      "Epoch 28/30, train_loss: 0.00217, valid_loss: 0.00164\n",
      "Epoch 29/30, train_loss: 0.00214, valid_loss: 0.00162\n",
      "Epoch 30/30, train_loss: 0.00211, valid_loss: 0.00159\n",
      "At step 11\n",
      "Epoch 1/30, train_loss: 0.01218, valid_loss: 0.00452\n",
      "Epoch 2/30, train_loss: 0.00917, valid_loss: 0.00435\n",
      "Epoch 3/30, train_loss: 0.00785, valid_loss: 0.00413\n",
      "Epoch 4/30, train_loss: 0.00701, valid_loss: 0.00387\n",
      "Epoch 5/30, train_loss: 0.00637, valid_loss: 0.00356\n",
      "Epoch 6/30, train_loss: 0.00585, valid_loss: 0.00328\n",
      "Epoch 7/30, train_loss: 0.00544, valid_loss: 0.00310\n",
      "Epoch 8/30, train_loss: 0.00511, valid_loss: 0.00294\n",
      "Epoch 9/30, train_loss: 0.00484, valid_loss: 0.00279\n",
      "Epoch 10/30, train_loss: 0.00460, valid_loss: 0.00266\n",
      "Epoch 11/30, train_loss: 0.00441, valid_loss: 0.00255\n",
      "Epoch 12/30, train_loss: 0.00424, valid_loss: 0.00248\n",
      "Epoch 13/30, train_loss: 0.00409, valid_loss: 0.00240\n",
      "Epoch 14/30, train_loss: 0.00395, valid_loss: 0.00234\n",
      "Epoch 15/30, train_loss: 0.00383, valid_loss: 0.00230\n",
      "Epoch 16/30, train_loss: 0.00373, valid_loss: 0.00227\n",
      "Epoch 17/30, train_loss: 0.00362, valid_loss: 0.00221\n",
      "Epoch 18/30, train_loss: 0.00353, valid_loss: 0.00215\n",
      "Epoch 19/30, train_loss: 0.00344, valid_loss: 0.00211\n",
      "Epoch 20/30, train_loss: 0.00336, valid_loss: 0.00206\n",
      "Epoch 21/30, train_loss: 0.00329, valid_loss: 0.00201\n",
      "Epoch 22/30, train_loss: 0.00322, valid_loss: 0.00197\n",
      "Epoch 23/30, train_loss: 0.00316, valid_loss: 0.00193\n",
      "Epoch 24/30, train_loss: 0.00309, valid_loss: 0.00190\n",
      "Epoch 25/30, train_loss: 0.00304, valid_loss: 0.00186\n",
      "Epoch 26/30, train_loss: 0.00298, valid_loss: 0.00186\n",
      "Epoch 27/30, train_loss: 0.00293, valid_loss: 0.00186\n",
      "Epoch 28/30, train_loss: 0.00288, valid_loss: 0.00183\n",
      "Epoch 29/30, train_loss: 0.00284, valid_loss: 0.00180\n",
      "Epoch 30/30, train_loss: 0.00279, valid_loss: 0.00177\n",
      "At step 10\n",
      "Epoch 1/30, train_loss: 0.00645, valid_loss: 0.00450\n",
      "Epoch 2/30, train_loss: 0.00535, valid_loss: 0.00391\n",
      "Epoch 3/30, train_loss: 0.00460, valid_loss: 0.00330\n",
      "Epoch 4/30, train_loss: 0.00408, valid_loss: 0.00311\n",
      "Epoch 5/30, train_loss: 0.00373, valid_loss: 0.00282\n",
      "Epoch 6/30, train_loss: 0.00345, valid_loss: 0.00262\n",
      "Epoch 7/30, train_loss: 0.00324, valid_loss: 0.00257\n",
      "Epoch 8/30, train_loss: 0.00308, valid_loss: 0.00243\n",
      "Epoch 9/30, train_loss: 0.00293, valid_loss: 0.00230\n",
      "Epoch 10/30, train_loss: 0.00281, valid_loss: 0.00220\n",
      "Epoch 11/30, train_loss: 0.00270, valid_loss: 0.00211\n",
      "Epoch 12/30, train_loss: 0.00261, valid_loss: 0.00205\n",
      "Epoch 13/30, train_loss: 0.00253, valid_loss: 0.00198\n",
      "Epoch 14/30, train_loss: 0.00245, valid_loss: 0.00192\n",
      "Epoch 15/30, train_loss: 0.00238, valid_loss: 0.00186\n",
      "Epoch 16/30, train_loss: 0.00232, valid_loss: 0.00182\n",
      "Epoch 17/30, train_loss: 0.00227, valid_loss: 0.00180\n",
      "Epoch 18/30, train_loss: 0.00222, valid_loss: 0.00176\n",
      "Epoch 19/30, train_loss: 0.00217, valid_loss: 0.00171\n",
      "Epoch 20/30, train_loss: 0.00212, valid_loss: 0.00169\n",
      "Epoch 21/30, train_loss: 0.00208, valid_loss: 0.00166\n",
      "Epoch 22/30, train_loss: 0.00204, valid_loss: 0.00163\n",
      "Epoch 23/30, train_loss: 0.00200, valid_loss: 0.00161\n",
      "Epoch 24/30, train_loss: 0.00197, valid_loss: 0.00159\n",
      "Epoch 25/30, train_loss: 0.00193, valid_loss: 0.00159\n",
      "Epoch 26/30, train_loss: 0.00190, valid_loss: 0.00156\n",
      "Epoch 27/30, train_loss: 0.00187, valid_loss: 0.00153\n",
      "Epoch 28/30, train_loss: 0.00184, valid_loss: 0.00153\n",
      "Epoch 29/30, train_loss: 0.00182, valid_loss: 0.00150\n",
      "Epoch 30/30, train_loss: 0.00179, valid_loss: 0.00148\n",
      "At step 9\n",
      "Epoch 1/30, train_loss: 0.00616, valid_loss: 0.00550\n",
      "Epoch 2/30, train_loss: 0.00506, valid_loss: 0.00418\n",
      "Epoch 3/30, train_loss: 0.00430, valid_loss: 0.00388\n",
      "Epoch 4/30, train_loss: 0.00381, valid_loss: 0.00339\n",
      "Epoch 5/30, train_loss: 0.00347, valid_loss: 0.00307\n",
      "Epoch 6/30, train_loss: 0.00323, valid_loss: 0.00296\n",
      "Epoch 7/30, train_loss: 0.00303, valid_loss: 0.00276\n",
      "Epoch 8/30, train_loss: 0.00287, valid_loss: 0.00259\n",
      "Epoch 9/30, train_loss: 0.00274, valid_loss: 0.00248\n",
      "Epoch 10/30, train_loss: 0.00262, valid_loss: 0.00236\n",
      "Epoch 11/30, train_loss: 0.00252, valid_loss: 0.00226\n",
      "Epoch 12/30, train_loss: 0.00243, valid_loss: 0.00218\n",
      "Epoch 13/30, train_loss: 0.00236, valid_loss: 0.00210\n",
      "Epoch 14/30, train_loss: 0.00228, valid_loss: 0.00202\n",
      "Epoch 15/30, train_loss: 0.00222, valid_loss: 0.00197\n",
      "Epoch 16/30, train_loss: 0.00216, valid_loss: 0.00192\n",
      "Epoch 17/30, train_loss: 0.00211, valid_loss: 0.00189\n",
      "Epoch 18/30, train_loss: 0.00206, valid_loss: 0.00184\n",
      "Epoch 19/30, train_loss: 0.00202, valid_loss: 0.00180\n",
      "Epoch 20/30, train_loss: 0.00198, valid_loss: 0.00176\n",
      "Epoch 21/30, train_loss: 0.00193, valid_loss: 0.00172\n",
      "Epoch 22/30, train_loss: 0.00190, valid_loss: 0.00168\n",
      "Epoch 23/30, train_loss: 0.00186, valid_loss: 0.00165\n",
      "Epoch 24/30, train_loss: 0.00183, valid_loss: 0.00161\n",
      "Epoch 25/30, train_loss: 0.00180, valid_loss: 0.00158\n",
      "Epoch 26/30, train_loss: 0.00177, valid_loss: 0.00155\n",
      "Epoch 27/30, train_loss: 0.00174, valid_loss: 0.00153\n",
      "Epoch 28/30, train_loss: 0.00172, valid_loss: 0.00153\n",
      "Epoch 29/30, train_loss: 0.00169, valid_loss: 0.00150\n",
      "Epoch 30/30, train_loss: 0.00167, valid_loss: 0.00150\n",
      "At step 8\n",
      "Epoch 1/30, train_loss: 0.01184, valid_loss: 0.00488\n",
      "Epoch 2/30, train_loss: 0.00904, valid_loss: 0.00470\n",
      "Epoch 3/30, train_loss: 0.00778, valid_loss: 0.00432\n",
      "Epoch 4/30, train_loss: 0.00689, valid_loss: 0.00389\n",
      "Epoch 5/30, train_loss: 0.00622, valid_loss: 0.00352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, train_loss: 0.00572, valid_loss: 0.00325\n",
      "Epoch 7/30, train_loss: 0.00532, valid_loss: 0.00308\n",
      "Epoch 8/30, train_loss: 0.00499, valid_loss: 0.00290\n",
      "Epoch 9/30, train_loss: 0.00473, valid_loss: 0.00276\n",
      "Epoch 10/30, train_loss: 0.00451, valid_loss: 0.00263\n",
      "Epoch 11/30, train_loss: 0.00431, valid_loss: 0.00254\n",
      "Epoch 12/30, train_loss: 0.00414, valid_loss: 0.00244\n",
      "Epoch 13/30, train_loss: 0.00399, valid_loss: 0.00235\n",
      "Epoch 14/30, train_loss: 0.00386, valid_loss: 0.00227\n",
      "Epoch 15/30, train_loss: 0.00374, valid_loss: 0.00221\n",
      "Epoch 16/30, train_loss: 0.00363, valid_loss: 0.00217\n",
      "Epoch 17/30, train_loss: 0.00353, valid_loss: 0.00214\n",
      "Epoch 18/30, train_loss: 0.00344, valid_loss: 0.00209\n",
      "Epoch 19/30, train_loss: 0.00335, valid_loss: 0.00204\n",
      "Epoch 20/30, train_loss: 0.00327, valid_loss: 0.00199\n",
      "Epoch 21/30, train_loss: 0.00320, valid_loss: 0.00198\n",
      "Epoch 22/30, train_loss: 0.00313, valid_loss: 0.00193\n",
      "Epoch 23/30, train_loss: 0.00307, valid_loss: 0.00189\n",
      "Epoch 24/30, train_loss: 0.00301, valid_loss: 0.00187\n",
      "Epoch 25/30, train_loss: 0.00295, valid_loss: 0.00184\n",
      "Epoch 26/30, train_loss: 0.00290, valid_loss: 0.00180\n",
      "Epoch 27/30, train_loss: 0.00285, valid_loss: 0.00177\n",
      "Epoch 28/30, train_loss: 0.00280, valid_loss: 0.00174\n",
      "Epoch 29/30, train_loss: 0.00275, valid_loss: 0.00171\n",
      "Epoch 30/30, train_loss: 0.00271, valid_loss: 0.00169\n",
      "At step 7\n",
      "Epoch 1/30, train_loss: 0.00674, valid_loss: 0.00561\n",
      "Epoch 2/30, train_loss: 0.00538, valid_loss: 0.00501\n",
      "Epoch 3/30, train_loss: 0.00452, valid_loss: 0.00453\n",
      "Epoch 4/30, train_loss: 0.00400, valid_loss: 0.00395\n",
      "Epoch 5/30, train_loss: 0.00364, valid_loss: 0.00378\n",
      "Epoch 6/30, train_loss: 0.00338, valid_loss: 0.00348\n",
      "Epoch 7/30, train_loss: 0.00316, valid_loss: 0.00324\n",
      "Epoch 8/30, train_loss: 0.00306, valid_loss: 0.00305\n",
      "Epoch 9/30, train_loss: 0.00292, valid_loss: 0.00289\n",
      "Epoch 10/30, train_loss: 0.00279, valid_loss: 0.00280\n",
      "Epoch 11/30, train_loss: 0.00268, valid_loss: 0.00268\n",
      "Epoch 12/30, train_loss: 0.00259, valid_loss: 0.00262\n",
      "Epoch 13/30, train_loss: 0.00250, valid_loss: 0.00252\n",
      "Epoch 14/30, train_loss: 0.00243, valid_loss: 0.00244\n",
      "Epoch 15/30, train_loss: 0.00236, valid_loss: 0.00238\n",
      "Epoch 16/30, train_loss: 0.00230, valid_loss: 0.00231\n",
      "Epoch 17/30, train_loss: 0.00224, valid_loss: 0.00227\n",
      "Epoch 18/30, train_loss: 0.00218, valid_loss: 0.00221\n",
      "Epoch 19/30, train_loss: 0.00213, valid_loss: 0.00216\n",
      "Epoch 20/30, train_loss: 0.00209, valid_loss: 0.00211\n",
      "Epoch 21/30, train_loss: 0.00205, valid_loss: 0.00206\n",
      "Epoch 22/30, train_loss: 0.00201, valid_loss: 0.00202\n",
      "Epoch 23/30, train_loss: 0.00197, valid_loss: 0.00200\n",
      "Epoch 24/30, train_loss: 0.00193, valid_loss: 0.00197\n",
      "Epoch 25/30, train_loss: 0.00190, valid_loss: 0.00193\n",
      "Epoch 26/30, train_loss: 0.00187, valid_loss: 0.00192\n",
      "Epoch 27/30, train_loss: 0.00184, valid_loss: 0.00188\n",
      "Epoch 28/30, train_loss: 0.00181, valid_loss: 0.00185\n",
      "Epoch 29/30, train_loss: 0.00179, valid_loss: 0.00182\n",
      "Epoch 30/30, train_loss: 0.00176, valid_loss: 0.00181\n",
      "At step 6\n",
      "Epoch 1/30, train_loss: 0.00828, valid_loss: 0.00581\n",
      "Epoch 2/30, train_loss: 0.00696, valid_loss: 0.00502\n",
      "Epoch 3/30, train_loss: 0.00596, valid_loss: 0.00421\n",
      "Epoch 4/30, train_loss: 0.00522, valid_loss: 0.00370\n",
      "Epoch 5/30, train_loss: 0.00472, valid_loss: 0.00334\n",
      "Epoch 6/30, train_loss: 0.00434, valid_loss: 0.00314\n",
      "Epoch 7/30, train_loss: 0.00405, valid_loss: 0.00293\n",
      "Epoch 8/30, train_loss: 0.00381, valid_loss: 0.00276\n",
      "Epoch 9/30, train_loss: 0.00362, valid_loss: 0.00262\n",
      "Epoch 10/30, train_loss: 0.00345, valid_loss: 0.00250\n",
      "Epoch 11/30, train_loss: 0.00330, valid_loss: 0.00241\n",
      "Epoch 12/30, train_loss: 0.00318, valid_loss: 0.00241\n",
      "Epoch 13/30, train_loss: 0.00306, valid_loss: 0.00235\n",
      "Epoch 14/30, train_loss: 0.00296, valid_loss: 0.00227\n",
      "Epoch 15/30, train_loss: 0.00287, valid_loss: 0.00220\n",
      "Epoch 16/30, train_loss: 0.00279, valid_loss: 0.00214\n",
      "Epoch 17/30, train_loss: 0.00271, valid_loss: 0.00209\n",
      "Epoch 18/30, train_loss: 0.00264, valid_loss: 0.00205\n",
      "Epoch 19/30, train_loss: 0.00258, valid_loss: 0.00200\n",
      "Epoch 20/30, train_loss: 0.00251, valid_loss: 0.00195\n",
      "Epoch 21/30, train_loss: 0.00246, valid_loss: 0.00191\n",
      "Epoch 22/30, train_loss: 0.00241, valid_loss: 0.00187\n",
      "Epoch 23/30, train_loss: 0.00236, valid_loss: 0.00183\n",
      "Epoch 24/30, train_loss: 0.00232, valid_loss: 0.00179\n",
      "Epoch 25/30, train_loss: 0.00228, valid_loss: 0.00176\n",
      "Epoch 26/30, train_loss: 0.00223, valid_loss: 0.00173\n",
      "Epoch 27/30, train_loss: 0.00220, valid_loss: 0.00170\n",
      "Epoch 28/30, train_loss: 0.00216, valid_loss: 0.00167\n",
      "Epoch 29/30, train_loss: 0.00213, valid_loss: 0.00164\n",
      "Epoch 30/30, train_loss: 0.00210, valid_loss: 0.00161\n",
      "At step 5\n",
      "Epoch 1/30, train_loss: 0.01021, valid_loss: 0.00597\n",
      "Epoch 2/30, train_loss: 0.00810, valid_loss: 0.00523\n",
      "Epoch 3/30, train_loss: 0.00680, valid_loss: 0.00435\n",
      "Epoch 4/30, train_loss: 0.00594, valid_loss: 0.00390\n",
      "Epoch 5/30, train_loss: 0.00535, valid_loss: 0.00354\n",
      "Epoch 6/30, train_loss: 0.00491, valid_loss: 0.00325\n",
      "Epoch 7/30, train_loss: 0.00458, valid_loss: 0.00306\n",
      "Epoch 8/30, train_loss: 0.00430, valid_loss: 0.00289\n",
      "Epoch 9/30, train_loss: 0.00407, valid_loss: 0.00273\n",
      "Epoch 10/30, train_loss: 0.00388, valid_loss: 0.00261\n",
      "Epoch 11/30, train_loss: 0.00371, valid_loss: 0.00252\n",
      "Epoch 12/30, train_loss: 0.00356, valid_loss: 0.00243\n",
      "Epoch 13/30, train_loss: 0.00344, valid_loss: 0.00234\n",
      "Epoch 14/30, train_loss: 0.00332, valid_loss: 0.00226\n",
      "Epoch 15/30, train_loss: 0.00321, valid_loss: 0.00219\n",
      "Epoch 16/30, train_loss: 0.00312, valid_loss: 0.00212\n",
      "Epoch 17/30, train_loss: 0.00303, valid_loss: 0.00206\n",
      "Epoch 18/30, train_loss: 0.00295, valid_loss: 0.00201\n",
      "Epoch 19/30, train_loss: 0.00288, valid_loss: 0.00196\n",
      "Epoch 20/30, train_loss: 0.00281, valid_loss: 0.00192\n",
      "Epoch 21/30, train_loss: 0.00275, valid_loss: 0.00188\n",
      "Epoch 22/30, train_loss: 0.00269, valid_loss: 0.00184\n",
      "Epoch 23/30, train_loss: 0.00263, valid_loss: 0.00180\n",
      "Epoch 24/30, train_loss: 0.00258, valid_loss: 0.00177\n",
      "Epoch 25/30, train_loss: 0.00254, valid_loss: 0.00174\n",
      "Epoch 26/30, train_loss: 0.00249, valid_loss: 0.00171\n",
      "Epoch 27/30, train_loss: 0.00245, valid_loss: 0.00168\n",
      "Epoch 28/30, train_loss: 0.00241, valid_loss: 0.00166\n",
      "Epoch 29/30, train_loss: 0.00237, valid_loss: 0.00163\n",
      "Epoch 30/30, train_loss: 0.00233, valid_loss: 0.00161\n",
      "At step 4\n",
      "Epoch 1/30, train_loss: 0.00983, valid_loss: 0.00527\n",
      "Epoch 2/30, train_loss: 0.00758, valid_loss: 0.00424\n",
      "Epoch 3/30, train_loss: 0.00629, valid_loss: 0.00354\n",
      "Epoch 4/30, train_loss: 0.00552, valid_loss: 0.00355\n",
      "Epoch 5/30, train_loss: 0.00499, valid_loss: 0.00327\n",
      "Epoch 6/30, train_loss: 0.00460, valid_loss: 0.00304\n",
      "Epoch 7/30, train_loss: 0.00429, valid_loss: 0.00291\n",
      "Epoch 8/30, train_loss: 0.00405, valid_loss: 0.00278\n",
      "Epoch 9/30, train_loss: 0.00384, valid_loss: 0.00263\n",
      "Epoch 10/30, train_loss: 0.00366, valid_loss: 0.00252\n",
      "Epoch 11/30, train_loss: 0.00350, valid_loss: 0.00242\n",
      "Epoch 12/30, train_loss: 0.00336, valid_loss: 0.00233\n",
      "Epoch 13/30, train_loss: 0.00324, valid_loss: 0.00225\n",
      "Epoch 14/30, train_loss: 0.00313, valid_loss: 0.00218\n",
      "Epoch 15/30, train_loss: 0.00303, valid_loss: 0.00211\n",
      "Epoch 16/30, train_loss: 0.00294, valid_loss: 0.00215\n",
      "Epoch 17/30, train_loss: 0.00286, valid_loss: 0.00210\n",
      "Epoch 18/30, train_loss: 0.00279, valid_loss: 0.00208\n",
      "Epoch 19/30, train_loss: 0.00272, valid_loss: 0.00212\n",
      "Epoch 20/30, train_loss: 0.00266, valid_loss: 0.00207\n",
      "Epoch 21/30, train_loss: 0.00260, valid_loss: 0.00203\n",
      "Epoch 22/30, train_loss: 0.00254, valid_loss: 0.00200\n",
      "Epoch 23/30, train_loss: 0.00249, valid_loss: 0.00196\n",
      "Epoch 24/30, train_loss: 0.00244, valid_loss: 0.00193\n",
      "Epoch 25/30, train_loss: 0.00239, valid_loss: 0.00190\n",
      "Epoch 26/30, train_loss: 0.00235, valid_loss: 0.00187\n",
      "Epoch 27/30, train_loss: 0.00231, valid_loss: 0.00185\n",
      "Epoch 28/30, train_loss: 0.00227, valid_loss: 0.00182\n",
      "Epoch 29/30, train_loss: 0.00224, valid_loss: 0.00179\n",
      "Epoch 30/30, train_loss: 0.00220, valid_loss: 0.00176\n",
      "At step 3\n",
      "Epoch 1/30, train_loss: 0.00738, valid_loss: 0.00538\n",
      "Epoch 2/30, train_loss: 0.00555, valid_loss: 0.00389\n",
      "Epoch 3/30, train_loss: 0.00464, valid_loss: 0.00342\n",
      "Epoch 4/30, train_loss: 0.00409, valid_loss: 0.00306\n",
      "Epoch 5/30, train_loss: 0.00371, valid_loss: 0.00276\n",
      "Epoch 6/30, train_loss: 0.00343, valid_loss: 0.00254\n",
      "Epoch 7/30, train_loss: 0.00320, valid_loss: 0.00236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, train_loss: 0.00302, valid_loss: 0.00226\n",
      "Epoch 9/30, train_loss: 0.00286, valid_loss: 0.00215\n",
      "Epoch 10/30, train_loss: 0.00273, valid_loss: 0.00205\n",
      "Epoch 11/30, train_loss: 0.00263, valid_loss: 0.00196\n",
      "Epoch 12/30, train_loss: 0.00252, valid_loss: 0.00195\n",
      "Epoch 13/30, train_loss: 0.00243, valid_loss: 0.00187\n",
      "Epoch 14/30, train_loss: 0.00235, valid_loss: 0.00181\n",
      "Epoch 15/30, train_loss: 0.00228, valid_loss: 0.00177\n",
      "Epoch 16/30, train_loss: 0.00221, valid_loss: 0.00173\n",
      "Epoch 17/30, train_loss: 0.00215, valid_loss: 0.00169\n",
      "Epoch 18/30, train_loss: 0.00210, valid_loss: 0.00165\n",
      "Epoch 19/30, train_loss: 0.00205, valid_loss: 0.00160\n",
      "Epoch 20/30, train_loss: 0.00200, valid_loss: 0.00157\n",
      "Epoch 21/30, train_loss: 0.00196, valid_loss: 0.00153\n",
      "Epoch 22/30, train_loss: 0.00192, valid_loss: 0.00150\n",
      "Epoch 23/30, train_loss: 0.00188, valid_loss: 0.00147\n",
      "Epoch 24/30, train_loss: 0.00184, valid_loss: 0.00144\n",
      "Epoch 25/30, train_loss: 0.00181, valid_loss: 0.00142\n",
      "Epoch 26/30, train_loss: 0.00178, valid_loss: 0.00139\n",
      "Epoch 27/30, train_loss: 0.00175, valid_loss: 0.00137\n",
      "Epoch 28/30, train_loss: 0.00172, valid_loss: 0.00134\n",
      "Epoch 29/30, train_loss: 0.00169, valid_loss: 0.00132\n",
      "Epoch 30/30, train_loss: 0.00166, valid_loss: 0.00130\n",
      "At step 2\n",
      "Epoch 1/30, train_loss: 0.00469, valid_loss: 0.00123\n",
      "Epoch 2/30, train_loss: 0.00352, valid_loss: 0.00281\n",
      "Epoch 3/30, train_loss: 0.00300, valid_loss: 0.00246\n",
      "Epoch 4/30, train_loss: 0.00269, valid_loss: 0.00230\n",
      "Epoch 5/30, train_loss: 0.00248, valid_loss: 0.00208\n",
      "Epoch 6/30, train_loss: 0.00232, valid_loss: 0.00191\n",
      "Epoch 7/30, train_loss: 0.00219, valid_loss: 0.00187\n",
      "Epoch 8/30, train_loss: 0.00209, valid_loss: 0.00180\n",
      "Epoch 9/30, train_loss: 0.00200, valid_loss: 0.00171\n",
      "Epoch 10/30, train_loss: 0.00192, valid_loss: 0.00163\n",
      "Epoch 11/30, train_loss: 0.00185, valid_loss: 0.00161\n",
      "Epoch 12/30, train_loss: 0.00179, valid_loss: 0.00167\n",
      "Epoch 13/30, train_loss: 0.00174, valid_loss: 0.00162\n",
      "Epoch 14/30, train_loss: 0.00169, valid_loss: 0.00175\n",
      "Epoch 15/30, train_loss: 0.00165, valid_loss: 0.00169\n",
      "Epoch 16/30, train_loss: 0.00161, valid_loss: 0.00164\n",
      "Epoch 17/30, train_loss: 0.00157, valid_loss: 0.00160\n",
      "Epoch 18/30, train_loss: 0.00153, valid_loss: 0.00157\n",
      "Epoch 19/30, train_loss: 0.00150, valid_loss: 0.00154\n",
      "Epoch 20/30, train_loss: 0.00147, valid_loss: 0.00152\n",
      "Epoch 21/30, train_loss: 0.00144, valid_loss: 0.00149\n",
      "Epoch 22/30, train_loss: 0.00142, valid_loss: 0.00146\n",
      "Epoch 23/30, train_loss: 0.00140, valid_loss: 0.00143\n",
      "Epoch 24/30, train_loss: 0.00137, valid_loss: 0.00140\n",
      "Epoch 25/30, train_loss: 0.00135, valid_loss: 0.00139\n",
      "Epoch 26/30, train_loss: 0.00133, valid_loss: 0.00137\n",
      "Epoch 27/30, train_loss: 0.00131, valid_loss: 0.00135\n",
      "Epoch 28/30, train_loss: 0.00129, valid_loss: 0.00133\n",
      "Epoch 29/30, train_loss: 0.00128, valid_loss: 0.00131\n",
      "Epoch 30/30, train_loss: 0.00126, valid_loss: 0.00129\n"
     ]
    }
   ],
   "source": [
    "# 5000 paths\n",
    "\n",
    "prc_rlnn=Bermudan_swaption_rlnn(lockout,maturity,sim_rates,strike,n_epochs,batch_size,learningrate)\n",
    "# 10k paths\n",
    "prc_rlnn_10k=Bermudan_swaption_rlnn(lockout,maturity,sim_rates_10k,strike,n_epochs,batch_size,learningrate)\n",
    "# 50k paths\n",
    "prc_rlnn_50k=Bermudan_swaption_rlnn(lockout,maturity,sim_rates_50k,strike,n_epochs,batch_size,learningrate)\n",
    "# 100k paths\n",
    "prc_rlnn_100k=Bermudan_swaption_rlnn(lockout,maturity,sim_rates_100k,strike,n_epochs,batch_size,learningrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_series=np.array([5000,10000,50000,100000])\n",
    "rlnn_series=np.array([prc_rlnn[1],prc_rlnn_10k[1],prc_rlnn_50k[1],prc_rlnn_100k[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c38eb9f908>]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(path_series,rlnn_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now the prc from RLNN is significantly lower than regress now approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2.plot(kind='line',y='Regress now',title='Price from Regress now')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(basis,cv,seed):\n",
    "    train_x=basis\n",
    "    train_y=cv\n",
    "# base model\n",
    "    model = xgboost.XGBRegressor(colsample_bytree=0.4,\n",
    "                 gamma=0,                 \n",
    "                 learning_rate=0.07,\n",
    "                 max_depth=3,\n",
    "                 min_child_weight=1.5,\n",
    "                 n_estimators=10,                                                                    \n",
    "                 reg_alpha=0.75,\n",
    "                 reg_lambda=0.45,\n",
    "                 subsample=0.6,\n",
    "                 seed=seed)\n",
    "# para range for search the optimal para\n",
    "    parameters_for_testing = {\n",
    "    'colsample_bytree':[0.4,0.6,0.8],\n",
    "    'gamma':[0,0.03,0.1,0.3],\n",
    "    'min_child_weight':[1.5,6,10],\n",
    "    'learning_rate':[0.001,0.005,0.01],\n",
    "    'max_depth':[3,5],\n",
    "    'n_estimators':[5,10],\n",
    "    'reg_alpha':[1e-5, 1e-2,  0.75],\n",
    "    'reg_lambda':[1e-5, 1e-2, 0.45],\n",
    "    'subsample':[0.6,0.95]}\n",
    "# searching     \n",
    "    gsearch1 = GridSearchCV(estimator = model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=10,scoring='neg_mean_squared_error')\n",
    "    gsearch1.fit(train_x,train_y)\n",
    "# get the best para\n",
    "    para=gsearch1.best_params_\n",
    "    \n",
    "    best_xgb_model=xgboost.XGBRegressor(colsample_bytree=para['colsample_bytree'],\n",
    "                 gamma=para['gamma'],                 \n",
    "                 learning_rate=para['learning_rate'],\n",
    "                 max_depth=para['max_depth'],\n",
    "                 min_child_weight=para['min_child_weight'],\n",
    "                 n_estimators=para['n_estimators'],                                                                    \n",
    "                 reg_alpha=para['reg_alpha'],\n",
    "                 reg_lambda=para['reg_lambda'],\n",
    "                 subsample=para[ 'subsample'],\n",
    "                 seed=seed)\n",
    "# fit the model\n",
    "    best_xgb_model.fit(train_x,train_y)\n",
    "    y_xgb=best_xgb_model.predict(train_x).reshape((-1,1))\n",
    "    return y_xgb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
